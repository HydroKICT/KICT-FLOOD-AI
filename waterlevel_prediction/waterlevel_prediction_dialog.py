# -*- coding: utf-8 -*-
"""
/***************************************************************************
 WaterlevelPredictionDialog
                                 A QGIS plugin
 This plugin is water level prediction.
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                             -------------------
        begin                : 2023-04-01
        git sha              : $Format:%H$
        copyright            : (C) GITech / Corp.
        email                : woonss@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

import os, sys, csv, shutil
import time

import qgis
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
import mariadb
import threading
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from random import *
from pickle import dump

from mpl_toolkits.mplot3d import Axes3D
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar

import matplotlib.ticker as ticker

from qgis.PyQt.QtGui import *
from qgis.PyQt import uic
from qgis.PyQt import *
from qgis.PyQt.QtWidgets import QDockWidget, QAction, QApplication, QWidget, QTableWidget, QTableWidgetItem, QFileDialog, QDialog, QPushButton, QDialogButtonBox, QLineEdit
from PyQt5.QtWidgets import QFileDialog, QTableWidgetItem, QMessageBox, QDialog
from PyQt5 import QtWidgets
from qgis.core import *
from qgis.utils import *
from qgis.core import QgsVectorLayer, QgsProject, QgsMarkerSymbol, QgsFillSymbol, QgsPalLayerSettings, QgsTextFormat, QgsVectorLayerSimpleLabeling, QgsTextBufferSettings

# open_api
import urllib.request
import time
from io import BytesIO
import requests
import json
from dateutil.relativedelta import relativedelta
import socket

from tqdm import tqdm

#from qgis.utils import reloadPlugin
#reloadPlugin('Waterlevel Prediction')

# This loads your .ui file so that PyQt can populate your plugin with the elements from Qt Designer
FORM_CLASS, _ = uic.loadUiType(os.path.join(os.path.dirname(__file__), 'waterlevel_prediction_dialog_base.ui'))

class WaterlevelPredictionDialog(QtWidgets.QDialog, FORM_CLASS):

    global arrDsHeader              # 그래프생성을 위한 데이터셋 헤더정보
    global arrDsData                # 그래프생성을 위한 데이터셋 자료정보
    global canvas                   # 데이터조회 차트정보
    global toolbar                  # 데이터조회 차트정보
    global fig                      # 데이터조회 차트정보
    global isMakeModelDataNull      # 모델생성 : 데이터Null여부
    global isPredictModelDataNull   # 예측수행 : 데이터Null여부

    def __init__(self, parent=None):
        """Constructor."""
        super(WaterlevelPredictionDialog, self).__init__(parent)
        # Set up the user interface from Designer through FORM_CLASS.
        # After self.setupUi() you can access any designer object by doing
        # self.<objectname>, and you can use autoconnect slots - see
        # http://qt-project.org/doc/qt-4.8/designer-using-a-ui-file.html
        # #widgets-and-dialogs-with-auto-connect
        self.setupUi(self)

        # basic control set ############################################################

        # Plugin 화면종료
        self.btn_dialogClose.clicked.connect(self.dialogCloseFunc)
        # PythonConsole 불러오기 Button
        self.btn_showPythonConsole.clicked.connect(self.load_pyConsole)
        # Control 초기화
        self.InitializeUiControls()

        # Plugin 초기화 #################################################################

        # init : PythonConsole 불러오기
        self.load_pyConsole()
        # init : Database 관측소 기간 가져오기
        self.init_databaseDate()
        # init : ShapeFILE 불러오기
        self.load_shapefiles()

        # [tab-데이터관리] ###############################################################

        # [데이터파일 불러오기] 파일불러오기(...) Button Event
        self.btn_data_loadDataFile.clicked.connect(self.LoadDataFile)
        # [데이터파일 불러오기] DB Import Button Event
        self.btn_dataImport.clicked.connect(self.ImportData)
        # [데이터파일 불러오기] 파일저장 Button Event
        self.btn_dataSaveFile.clicked.connect(self.SaveData_fileDQM)
        # [데이터파일 불러오기] 테이블선택 Combobox Event
        self.cb_dataTable.currentIndexChanged.connect(self.SetDataTableType)

        # [데이터조회] 관측소번호 Combobox Event
        self.cb_inputType.currentIndexChanged.connect(self.SetDataSearchInputType)
        # [데이터조회] 조회테이블 Combobox Event
        self.cb_searchTable.currentIndexChanged.connect(self.SetDataSearchTableData)
        # [데이터조회] 조회 Button Event
        self.btn_dataSearch.clicked.connect(self.SearchData)

        # [openAPI 불러오기] 관측소코드 Combobox Event
        self.cb_apiObsCodeType.currentIndexChanged.connect(self.SetOpenAPI_ObsCodeInputType)
        # [openAPI 불러오기] 자료종류 Combobox Event
        self.cb_apiObsType.currentIndexChanged.connect(self.SetOpenAPI_ObsType)
        # [openAPI 불러오기] 조회 Button Event
        self.btn_apiSearch.clicked.connect(self.Search_OpenAPIData)
        # [openAPI 불러오기] 파일저장 Button Event
        self.btn_apiSaveCSV.clicked.connect(self.Save_OpenAPIData)
        # [openAPI 불러오기] 조회기간 셋팅
        self.dt_apiStartDt.setDateTime(QtCore.QDateTime.currentDateTime())
        self.dt_apiEndDt.setDateTime(QtCore.QDateTime.currentDateTime())

        # tab [데이터셋생성] #############################################################

        # [데이터셋생성] QGIS에서 선택된 Feature 가져오기(+) Button Event
        self.btn_getSelectedTargetpoint.clicked.connect(self.btn_getSelectedFeatureTarget)
        self.btn_getSelectedWaterlevel.clicked.connect(self.btn_getSelectedFeatureWL)
        self.btn_getSelectedRainfall.clicked.connect(self.btn_getSelectedFeatureRF)
        self.btn_getSelectedDischarge.clicked.connect(self.btn_getSelectedFeatureDC)
        self.btn_getSelectedDaminlet.clicked.connect(self.btn_getSelectedFeatureDI)
        self.btn_getSelectedDamrelease.clicked.connect(self.btn_getSelectedFeatureDR)
        self.btn_getSelectedTidelevel.clicked.connect(self.btn_getSelectedFeatureTE)
        self.btn_getSelectedThiessen.clicked.connect(self.btn_getSelectedFeatureTS)
        # [데이터셋생성] Make Dataset Button Event
        self.btn_makeDataset.clicked.connect(self.MakeDataset)
        # [데이터셋생성] Save Dataset File Button Event
        self.btn_saveDataset.clicked.connect(self.btn_saveDatasetFunc)
        # [데이터셋생성] 기간선택 RadioButton Event
        self.rb_dataset_periodYear.clicked.connect(self.SetDatasetPeriodRadioGroup)
        self.rb_dataset_periodDate.clicked.connect(self.SetDatasetPeriodRadioGroup)
        # [데이터셋생성] 리드타임설정 Event
        self.rb_ds_leadtimeBasic.clicked.connect(self.SetDatasetLeadtimeRadioGroup)
        self.rb_ds_leadtimeTimeseries.clicked.connect(self.SetDatasetLeadtimeRadioGroup)
        self.cb_ds_leadtimeUnit.currentIndexChanged.connect(self.SetDatasetOptionLeadtime)
        # [데이터셋생성] 데이터전처리 Checkbox/Radiobutton Event
        self.sp_ds_preProcessing_noRainVal.clicked.connect(self.SetDatasetPreAccRain)
        self.ckb_ds_preProcessing_month.clicked.connect(self.SetDatasetPreMonth)
        self.rb_ds_preProcessing_month.clicked.connect(self.SetDatasetPreDateFiltering)
        self.rb_ds_preProcessing_date.clicked.connect(self.SetDatasetPreDateFiltering)
        # [데이터셋생성] 그래프보기 button
        self.btn_showDatasetGraph.clicked.connect(self.ShowDatasetGraph)

        ## tab [하천수위예측모형제작] #####################################################

        # [하천수위예측모형제작] dataset file load Button Event
        self.btn_param_datasetPath.clicked.connect(self.LoadMakeModelDataset)
        # [하천수위예측모형제작] 파라메터 불러오기 Button Event
        self.btn_dl_loadParameter.clicked.connect(self.LoadMakeModelParam)
        # [하천수위예측모형제작] Save path select Button Event
        self.btn_param_savePath.clicked.connect(self.SetMakeModelSavePath)
        # [하천수위예측모형제작] make model Button Event
        self.btn_makeModel.clicked.connect(self.MakeModel)

        # tab [예측수행및성능분석] #########################################################

        # [예측수행및성능분석] Select Dataset File Button Event
        self.btn_selectDataFile.clicked.connect(self.LoadPredictDataset)
        # [예측수행및성능분석] Select Model Directory Button Event
        self.btn_selectModelFile.clicked.connect(self.LoadModel)
        # [예측수행및성능분석] Save Model Path Button Event
        self.btn_saveModelPath.clicked.connect(self.SetPredictResultSavePath)
        # [예측수행및성능분석] Running Model Button Event
        self.btn_dl_reloadModel.clicked.connect(self.RunPredict)

        # tab [실시간예측] #########################################################

        # [실시간예측] QGIS에서 선택된 Feature 가져오기(+) Button
        self.btn_getSelectedRealtimeTargetpoint.clicked.connect(self.btn_getSelectedRealtimeFeatureTarget)
        self.btn_getSelectedRealtimeWaterlevel.clicked.connect(self.btn_getSelectedRealtimeFeatureWL)
        self.btn_getSelectedRealtimeRainfall.clicked.connect(self.btn_getSelectedRealtimeFeatureRF)
        self.btn_getSelectedRealtimeDischarge.clicked.connect(self.btn_getSelectedRealtimeFeatureDC)
        self.btn_getSelectedRealtimeDaminlet.clicked.connect(self.btn_getSelectedRealtimeFeatureDI)
        self.btn_getSelectedRealtimeDamrelease.clicked.connect(self.btn_getSelectedRealtimeFeatureDR)
        self.btn_getSelectedRealtimeTidelevel.clicked.connect(self.btn_getSelectedRealtimeFeatureTE)
        self.btn_getSelectedRealtimeThiessen.clicked.connect(self.btn_getSelectedRealtimeFeatureTS)
        # [실시간예측] Realtime Run Model button
        self.btn_realtimeModel.clicked.connect(self.RunRealtimeModel)
        # [실시간예측] Select Model Directory button
        self.btn_selectRealtimeModelFile.clicked.connect(self.LoadRealtimeModel)
        # [실시간예측] Save Model Path button
        self.btn_saveRealtimeModelPath.clicked.connect(self.SaveRealtimeModelPath)
        # [실시간예측] 시간세팅
        self.dt_rt_datetime.setDateTime(QtCore.QDateTime.currentDateTime())

        # [컨트롤 셋팅] #########################################################

        self.SetDataSearchInputType(1)
        self.SetDataSearchTableData(0)
        self.SetOpenAPI_ObsCodeInputType(1)
        self.SetOpenAPI_ObsType(0)
        self.SetDatasetPeriodRadioGroup()
        self.SetDatasetLeadtimeRadioGroup()
        self.SetDataTableType(0)

        # [데이터셋 Graph Dialog] 생성
        self.dialogDataset = QDialog()

    # init : Controls 초기화
    def InitializeUiControls(self):

        # 컨트롤 상태 초기화
        self.cb_dataset_startYear.setEnabled(False)
        self.cb_dataset_endYear.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.dt_dataset_startTime.setEnabled(False)
        self.dt_dataset_endTime.setEnabled(False)
        self.ckb_ds_leadtimeHarf.setEnabled(False)
        self.ckb_ds_leadtime1h.setEnabled(False)
        self.ckb_ds_leadtime2h.setEnabled(False)
        self.ckb_ds_leadtime3h.setEnabled(False)
        self.ckb_ds_leadtime4h.setEnabled(False)
        self.ckb_ds_leadtime5h.setEnabled(False)
        self.ckb_ds_leadtime6h.setEnabled(False)
        self.cb_ds_leadtimeTarget.setEnabled(False)
        self.cb_ds_leadtimeTerm.setEnabled(False)
        self.cb_ds_leadtimeUnit.setEnabled(False)
        self.txtBox_ds_preProcessing_accRainHour.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.rb_ds_preProcessing_month.setChecked(True)
        self.SetDatasetPreMonth()

        # 컨트롤 데이터초기화
        self.cb_ds_leadtimeTarget.clear()
        self.cb_ds_leadtimeTerm.clear()
        for i in range(1, 7, 1):
            self.cb_ds_leadtimeTarget.addItem(str(i))
            self.cb_ds_leadtimeTerm.addItem(str(i))

        self.cb_ds_leadtimeTarget.setCurrentIndex(0)
        self.cb_ds_leadtimeUnit.setCurrentIndex(0)
        self.cb_ds_leadtimeTerm.setCurrentIndex(0)
        self.cb_inputType.setCurrentIndex(0)

        # 그래프 초기화
        global canvas
        global toolbar
        global fig

        self.fig = plt.Figure()
        self.canvas = FigureCanvas(self.fig)
        self.toolbar = NavigationToolbar(self.canvas, self)
        self.verticalLayout.addWidget(self.toolbar)
        self.verticalLayout.addWidget(self.canvas)

        ax = self.fig.add_subplot(111)
        self.fig.tight_layout()
        self.canvas.draw()

    # Plugin 화면 종료
    def dialogCloseFunc(self):

        # 실시간예측 수행중일경우 종료하기
        if threading.active_count() > 1:
            myThread.cancel()
        # 화면종료
        self.close()

    # init : 데이터베이스 정보 가져오기
    def init_databaseDate(self):
        # 기간설정정보 가져오기
        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()

        # 데이터베이스 내 테이블 목록 가져오기
        select_query = "SHOW tables"
        cur.execute(select_query)
        resultset = cur.fetchall()
        self.cb_dataTable.clear()
        self.cb_searchTable.clear()
        for idx in range(len(resultset)):
            self.cb_dataTable.addItem(resultset[idx][0])
            self.cb_searchTable.addItem(resultset[idx][0])

        # 컨트롤 날짜데이터 셋팅
        self.cb_dataset_startYear.clear()
        self.cb_dataset_endYear.clear()
        self.sp_ds_preProcessing_startMonth.clear()
        self.sp_ds_preProcessing_endMonth.clear()
        getYear_query = "SELECT year(dt_date) FROM waterlevel A, (SELECT IDS FROM (SELECT (first_value(obs_id) OVER (ORDER BY obs_id)) AS IDS FROM waterlevel GROUP BY obs_id) MYTBL GROUP BY MYTBL.IDS) B WHERE A.OBS_ID = B.IDS GROUP BY year(dt_date)"
        cur.execute(getYear_query)
        resultdb = cur.fetchall()
        if (len(resultdb) > 0):
            for idx in range(len(resultdb)):
                self.cb_dataset_startYear.addItem(str(resultdb[idx][0]))
                self.cb_dataset_endYear.addItem(str(resultdb[idx][0]))

        getMonth_query = "SELECT month(dt_date) FROM waterlevel A, (SELECT IDS FROM (SELECT (first_value(obs_id) OVER (ORDER BY obs_id)) AS IDS FROM waterlevel GROUP BY obs_id) MYTBL GROUP BY MYTBL.IDS) B WHERE A.OBS_ID = B.IDS GROUP BY month(dt_date)"
        cur.execute(getMonth_query)
        resultdb = cur.fetchall()
        if (len(resultdb) > 0):
            for idx in range(len(resultdb)):
                self.sp_ds_preProcessing_startMonth.addItem(str(resultdb[idx][0]))
                self.sp_ds_preProcessing_endMonth.addItem(str(resultdb[idx][0]))

        cur.execute("SELECT MIN(dt_date), MAX(dt_date) FROM waterlevel A, (SELECT IDS FROM (SELECT (first_value(obs_id) OVER (ORDER BY obs_id)) AS IDS FROM waterlevel GROUP BY obs_id) MYTBL GROUP BY MYTBL.IDS) B WHERE A.OBS_ID = B.IDS GROUP BY OBS_ID")
        resultdb = cur.fetchall()
        if (len(resultdb) > 0):
            for idx in range(1):
                self.dt_dataset_startTime.setDateTime(resultdb[0][0])
                self.dt_dataset_endTime.setDateTime(resultdb[0][1])
                self.dt_data_startTime.setDateTime(resultdb[0][0])
                self.dt_data_endTime.setDateTime(resultdb[0][1])

        conn.close()

    # init : QGIS ShapeFILE 불러오기
    def load_shapefiles(self):

        pluginPath = os.path.dirname(__file__)

        urlThiessen = pluginPath + "/shp/Korea_watershed_EPSG5186.shp"     # 표준유역
        urlDischarge = pluginPath + "/shp/Korea_Discharge_EPSG5186.shp"         # 유량
        urlDaminlet = pluginPath + "/shp/Korea_point_IF_mywater_EPSG5186.shp"     # 댐유입량
        urlDamrelease = pluginPath + "/shp/Korea_point_OF_mywater_EPSG5186.shp"   # 댐방류량
        urlRainfall = pluginPath + "/shp/Korea_Rainfall_EPSG5186.shp"           # 강우
        urlTidelevel = pluginPath + "/shp/Korea_point_Tide_level_EPSG5186.shp"  # 조위
        urlWaterlevel = pluginPath + "/shp/Korea_Waterlevel_EPSG5186.shp"       # 수위
        urlRiverNetwork = pluginPath + "/shp/Korea_River_network_EPSG5186.shp"  # 하천

        # layer property (lyr_name, T, fill_color, obs_code, shapes_name)
        self.add_mapLayer(urlThiessen, "watershed", "ogr", 'transparent', 'sbsncd', '')
        self.add_mapLayer(urlRiverNetwork, "rivernetwork", "ogr", '#276bff', 'obs_code', '')
        self.add_mapLayer(urlDischarge, "discharge", "ogr", 'yellow', 'obs_code', 'star')
        self.add_mapLayer(urlDaminlet, "daminlet", "ogr", 'green', 'obs_code', 'square')
        self.add_mapLayer(urlDamrelease, "damrelease", "ogr", 'blue', 'obs_code', 'square')
        self.add_mapLayer(urlRainfall, "rainfall", "ogr", 'orange', 'obs_code', 'triangle')
        self.add_mapLayer(urlTidelevel, "tidelevel", "ogr", 'purple', 'obs_code', 'diamond')
        self.add_mapLayer(urlWaterlevel, "waterlevel", "ogr", 'red', 'obs_code', 'circle')

    # init : QGIS 레이어 추가
    def add_mapLayer(self, lyr, lyrName, etc, color, labelText, shapes):

        addLayer = QgsVectorLayer(lyr, lyrName, etc)
        if not addLayer.isValid():
            print ("Layer failed to load!")
        else:
            # 같은 레이어가 있다면 지우고 다시 추가한다.
            for layer in QgsProject.instance().mapLayers().values():
                if layer.name() == lyrName:
                    QgsProject.instance().removeMapLayers([layer.id()])

            # 레이어 타입(point, polygon)에 따라 렌더링
            layer_type = addLayer.geometryType()
            if layer_type  == QgsWkbTypes.PointGeometry:
                QgsProject.instance().addMapLayer(addLayer)
                # set labeling
                text_format = QgsTextFormat()
                buffer_settings = QgsTextBufferSettings()
                buffer_settings.setEnabled(True)
                buffer_settings.setSize(0.10)
                buffer_settings.setColor(QColor(color))
                text_format.setBuffer(buffer_settings)
                label = QgsPalLayerSettings()
                label.fieldName = labelText
                label.enabled = True
                label.setFormat(text_format)
                labeler = QgsVectorLayerSimpleLabeling(label)
                #addLayer.setLabelsEnabled(True)
                addLayer.setLabeling(labeler)
                # set symbol
                addLayer.renderer().symbol().symbolLayer(0).setSize(2)
                props = addLayer.renderer().symbol().symbolLayer(0).properties()
                props['color'] = color
                props['name'] = shapes
                addLayer.renderer().setSymbol(QgsMarkerSymbol.createSimple(props))
                # qgis symbol refresh
                iface.layerTreeView().refreshLayerSymbology(addLayer.id())
                # repaint
                addLayer.triggerRepaint()
                print(lyrName + " Point Layer was loaded successfully!")
            elif layer_type  == QgsWkbTypes.PolygonGeometry:
                QgsProject.instance().addMapLayer(addLayer)
                props = addLayer.renderer().symbol().symbolLayer(0).properties()
                props['color'] = color
                addLayer.renderer().setSymbol(QgsFillSymbol.createSimple(props))
                if (lyrName == 'rivernetwork'):
                    addLayer.setOpacity(0.8)
                # repaint
                iface.layerTreeView().refreshLayerSymbology(addLayer.id())
                addLayer.triggerRepaint()
                print(lyrName + " Polygon Layer was loaded successfully!")

            else:
                print(lyrName + " NoneType Layer was loaded successfully!")

    # init : PythonConsole 불러오기
    def load_pyConsole(self):
        pythonConsole = iface.mainWindow().findChild(QDockWidget, 'PythonConsole')
        if not pythonConsole or not pythonConsole.isVisible():
            iface.actionShowPythonDialog().trigger()

    # tab [데이터 관리] : [데이터파일 불러오기] 파일불러오기(...) Button Event
    def LoadDataFile(self):

        fileDatas, _ = QFileDialog.getOpenFileNames(self, 'Open file', '', 'csv file(*.csv)')
        
        # 선택된 파일이 없을 경우, 취소
        if len(fileDatas) == 0: return

        # set_tableWidget
        labels = ['File Name', 'File Path']
        self.tbl_showData.clearContents()
        nb_row = len(fileDatas)
        nb_col = len(labels)
        self.tbl_showData.setRowCount(nb_row)
        self.tbl_showData.setColumnCount(nb_col)
        self.tbl_showData.setHorizontalHeaderLabels(labels)

        fileNames = []
        for row in range(nb_row):
            dir, fileName = os.path.split(fileDatas[row])
            fileNames.append(fileName)
            item = QTableWidgetItem(fileName)
            self.tbl_showData.setItem(row, 0, item)
            item = QTableWidgetItem(dir)
            self.tbl_showData.setItem(row, 1, item)

        self.txtBox_data_loadDataFile.setText(str(fileNames))
        self.tbl_showData.resizeColumnsToContents()

    # tab [데이터 관리] : [데이터파일 불러오기] DB Import Button Event
    def ImportData(self):

        # openAPI를 통해 취득한 자료(*.csv)만 데이터베이스에 임포트(Import) 한다.
        # 입력가능한 파일명 : 관측소번호.csv
        # 입력가능한 파일 자료 포맷 : 날짜(예:202210102350), 데이터(숫자또는빈값)
        # 품질관리 옵션을 선택했을 경우, 해당 옵션을 처리하여 DB Import
        # 품질관리 옵션을 선택하지 않았을 경우, 원본 파일데이터로 동일하게 DB Import

        # 강우와 유역평균강우의 자료는 이상치제거와 결측치보정없이 DB에 임포트(Import)한다.
        # 강우는 원본파일에서 결측치보정한 파일을 저장한 후, 사용자가 수기로 이상치제거작업을 하여 임포트한다.
        # 유역평균강우는 품질관리를 위한 전처리 작업에 대한 자료가 불명확하여 사용자가 수기로 작업하여 임포트한다.

        # 1. 입력테이블명
        strTableNm = self.cb_dataTable.currentText()

        # 2. 선택된 파일이 있는지 확인한다. (없으면취소, 있으면데이터재확인)
        if (self.tbl_showData.rowCount() == 0):
            QMessageBox.warning(self, 'Error Message', "Import할 데이터가 없습니다.", QMessageBox.Ok)
            return
        else:
            strDataName = ""
            if (strTableNm == "waterlevel"):
                strDataName = "수위"
            elif (strTableNm == "discharge"):
                strDataName = "유량"
            elif (strTableNm == "rainfall"):
                strDataName = "강우"
            elif (strTableNm == "daminlet"):
                strDataName = "댐유입량"
            elif (strTableNm == "damrelease"):
                strDataName = "댐방류량"
            elif (strTableNm == "tidelevel"):
                strDataName = "조위"
            elif (strTableNm == "watershed"):
                strDataName = "유역평균강우"
            else:
                strDataName = "None"

            msgImport = "선택된 파일을 {0}테이블에 임포트(Import) 하시겠습니까?".format(strDataName)
            btnImportOK = QMessageBox.warning(self, 'Warning Message', msgImport,
                                              QMessageBox.Yes | QMessageBox.Cancel)
            if btnImportOK == QMessageBox.Cancel:
                QMessageBox.warning(self, 'Warning Message', "작업을 취소했습니다.", QMessageBox.Ok)
                return

        # 3. 중복데이터가 데이터베이스에 존재할 경우, 업데이트 여부를 선택한다.
        #    Yes-파일자료(또는품질관리자료)로 DB 데이터 수정, No-DB에 있는 데이터 그대로 사용, 취소-Import작업취소
        isUpdate = True
        buttonReply = QMessageBox.warning(self, 'Warning Message', "중복된 데이터가 있을 경우, 업데이트 하시겠습니까?",
                                          QMessageBox.Yes | QMessageBox.No  | QMessageBox.Cancel)
        if buttonReply == QMessageBox.No:
            isUpdate = False
        elif buttonReply == QMessageBox.Yes:
            isUpdate = True
        else:
            return

        # 4. 품질관리여부
        bRemoveOutlier = self.ckb_data_option1.isChecked()      #이상치제거
        bRemoveMissingVAL = self.ckb_data_option2.isChecked()   #결측치보정
        

        # 5. DB Import
        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()

        try:

            # 선택된 파일 하나씩 품질관리해서 Import 하기
            for row in range(self.tbl_showData.rowCount()):

                # file_path
                fileName = str(self.tbl_showData.item(row, 0).text())  # file_name
                filePath = str(self.tbl_showData.item(row, 1).text())  # file_directory
                fileData = "{0}\{1}".format(filePath, fileName)  # file_path

                # obs_num
                strObsId = os.path.splitext(os.path.basename(fileData))[0]

                # final_data
                pd_final = None

                if ((strTableNm=="rainfall") or (strTableNm=="watershed")):

                    # 데이터File
                    tmpDataFile = pd.read_csv(fileData, header=None)
                    pd_final = pd.DataFrame(tmpDataFile)

                    # 데이터Import
                    len_pd_final = pd_final.shape[0]
                    for i in range(len_pd_final):
                        rowdata = pd_final.iloc[i, :].values.tolist()

                        if (len(rowdata) == 4):
                            # 데이터 정보
                            dt_date = str(int(rowdata[0])).strip()
                            dt_data = str(rowdata[1]).strip()
                            mi_data = str(rowdata[2]).strip()
                            oi_data = str(rowdata[3]).strip()

                            if (dt_data == ''):
                                dt_data = "NULL"
                            if (mi_data == ''):
                                mi_data = "NULL"
                            if (oi_data == ''):
                                oi_data = "NULL"

                            # 데이터 DB Import
                            sql = ""
                            # 중복데이터가 있을경우, update
                            if (isUpdate == True):
                                sql = "INSERT INTO {0} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA) VALUE ('{1}', STR_TO_DATE('{2}', '%Y%m%d%H%i'), {3}, {4}, {5}) ON DUPLICATE KEY UPDATE DT_DATA = {6}, MI_DATA = {7}, OI_DATA = {8}".format(
                                    strTableNm, strObsId, dt_date, dt_data, mi_data, oi_data, dt_data, mi_data, oi_data)
                                cur.execute(sql)
                            # 중복데이터가 있을경우, ignore (update하지 않고 그대로 둠)
                            else:
                                sql = "INSERT IGNORE INTO {0} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA) VALUE ('{1}', STR_TO_DATE('{2}', '%Y%m%d%H%i'), {3}, {4}, {5})".format(
                                    strTableNm, strObsId, dt_date, dt_data, mi_data, oi_data)
                                cur.execute(sql)

                        else:
                            errMsg = "[{0}] 파일의 입력형식이 다릅니다.".format(fileName)
                            print (errMsg)
                            break

                else:

                    # 품질관리(openAPI를 통해 들어온 데이터에 일시누락없음)
                    if ((bRemoveOutlier==True) or (bRemoveMissingVAL==True)):

                        ### 데이터 품질관리 시작 #############################################

                        print ("--Start ", strObsId, " Data Quality Management--")
                        DATA_QM = DataQualityManagement(fileData)

                        # 데이터 시간표기변경 (2400 -> 0000)
                        pd_convertTimeEpr = DATA_QM.TIME_EXPRESSION_MODIFY()
                        print(strObsId, " TIME_EXPRESSION_MODIFY")

                        # 데이터 콤마제거
                        pd_removeComma = DATA_QM.REMOVE_COMMA(pd_convertTimeEpr)
                        print(strObsId, " REMOVE_COMMA")

                        # 데이터 날짜누락 보간 (사용X)
                        #pd_timeModify = DATA_QM.TIME_MODIFY(pd_removeComma)
                        #pd_timeModify = pd_removeComma

                        # 데이터 중복 제거
                        pd_removeDuplicate = DATA_QM.REMOVE_DUPLICATE(pd_removeComma)
                        print(strObsId, " REMOVE_DUPLICATE")

                        pd_nullToZero = None
                        pd_removeOutlier = None
                        # 수위데이터일경우, Null값에 대한 처리는 하지 않는다.
                        if (strTableNm == "waterlevel"):
                            # 3시간 선형보간
                            pd_3hrInterpolation = DATA_QM.THREEHR_INTERPOLATION(pd_removeDuplicate)
                            print(strObsId, " 3HR_INTERPOLATION")
                            # 이상치 보간
                            pd_removeOutlier = DATA_QM.REMOVE_OUTLIER(pd_3hrInterpolation)
                            print(strObsId, " REMOVE_OUTLIER")
                            # Null값을 처리안함 (pd_3hrInterpolation = mi_data)
                            pd_nullToZero = pd_3hrInterpolation
                        else:
                            # 마이너스값 0으로 변경 (수위제외, 유량/조위/댑유입량/댐방류량)
                            pd_minusToZero = DATA_QM.MINUS_TO_ZERO(pd_removeDuplicate)
                            print(strObsId, " MINUS_TO_ZERO")
                            # 3시간 선형보간
                            pd_3hrInterpolation = DATA_QM.THREEHR_INTERPOLATION(pd_minusToZero)
                            print(strObsId, " 3HR_INTERPOLATION")
                            # 이상치 보간
                            pd_removeOutlier = DATA_QM.REMOVE_OUTLIER(pd_3hrInterpolation)
                            print(strObsId, " REMOVE_OUTLIER")
                            # Null값을 0으로 (수위제외, 유량/조위/댑유입량/댐방류량)
                            pd_nullToZero = DATA_QM.NULL_TO_ZERO(pd_3hrInterpolation)
                            print(strObsId, " NULL_TO_ZERO")

                        # 최종 데이터 생성
                        pd_final = DATA_QM.COMBINE_DATA(pd_removeDuplicate, pd_nullToZero, pd_removeOutlier)
                        print("--End ", strObsId, " Data Quality Management--")

                    else:
                        csvFileData = pd.read_csv(fileData, header=None)
                        pd_final = pd.DataFrame(csvFileData)

                    # 데이터Import
                    len_pd_final = pd_final.shape[0]
                    for i in range(len_pd_final):

                        rowdata = pd_final.iloc[i, :].values.tolist()

                        dt_date = ''
                        dt_data = ''
                        mi_data = ''
                        oi_data = ''

                        # 품질관리를 선택하지 않았다면, 표준화자료를 결측치보정/이상치보정자료로 넣는다.
                        if (len(rowdata) == 2):

                            dt_date = str(int(rowdata[0])).strip()
                            dt_data = str(rowdata[1]).strip()
                            mi_data = dt_data
                            oi_data = dt_data

                            if (dt_data == ''):
                                dt_data = "NULL"
                            if (mi_data == ''):
                                mi_data = "NULL"
                            if (oi_data == ''):
                                oi_data = "NULL"

                        # 품질관리를 선택했다면, 선택항목에 따라 데이터를 넣고, 선택안한 데이터는 표준화자료를 넣는다.
                        elif (len(rowdata) == 4):

                            dt_date = str(int(rowdata[0])).strip()
                            dt_data = str(rowdata[1]).strip()
                            mi_data = str(rowdata[2]).strip()
                            oi_data = str(rowdata[3]).strip()

                            if (bRemoveOutlier == False):
                                oi_data = dt_data
                            if (bRemoveMissingVAL == False):
                                mi_data = dt_data

                            if (dt_data == ''):
                                dt_data = "NULL"
                            if (mi_data == ''):
                                mi_data = "NULL"
                            if (oi_data == ''):
                                oi_data = "NULL"
                        else:
                            break

                        # 데이터 Import
                        sql = ""
                        # 중복데이터가 있을경우, update
                        if (isUpdate == True):
                            sql = "INSERT INTO {0} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA) VALUE ('{1}', STR_TO_DATE('{2}', '%Y%m%d%H%i'), {3}, {4}, {5}) ON DUPLICATE KEY UPDATE DT_DATA = {6}, MI_DATA = {7}, OI_DATA = {8}".format(
                                strTableNm, strObsId, dt_date, dt_data, mi_data, oi_data, dt_data, mi_data, oi_data)
                            cur.execute(sql)
                        # 중복데이터가 있을경우, ignore (update하지 않고 그대로 둠)
                        else:
                            sql = "INSERT IGNORE INTO {0} (OBS_ID, DT_DATE, DT_DATA, MI_DATA, OI_DATA) VALUE ('{1}', STR_TO_DATE('{2}', '%Y%m%d%H%i'), {3}, {4}, {5})".format(
                                strTableNm, strObsId, dt_date, dt_data, mi_data, oi_data)
                            cur.execute(sql)

                conn.commit()

            conn.close()
            QMessageBox.information(self, 'Message', "작업을 완료했습니다.", QMessageBox.Ok)

        except:
            conn.commit()
            conn.close()


    # tab [데이터 관리] : [데이터파일 불러오기] 저장하기 Button Event
    def SaveData_fileDQM(self):

        # 1. 선택된 파일이 있는지 확인한다.
        if (self.tbl_showData.rowCount() == 0):
            QMessageBox.warning(self, 'Error Message', "Import할 데이터가 없습니다.", QMessageBox.Ok)
            return

        # 파일저장 폴더 선택
        dirPath = QFileDialog.getExistingDirectory(self)
        if (os.path.exists(dirPath)==False):
            QMessageBox.warning(self, 'Error Message', "선택한 폴더정보가 없습니다.", QMessageBox.Ok)
            return
        
        # 강우(rainfall) 테이블선택시에만 파일로 저장한다.
        strTableNm = self.cb_dataTable.currentText().strip()
        if (strTableNm == "rainfall"):

            # 선택된 파일 하나씩 품질관리(표준화데이터, 결측치보정)해서 Import 하기, 이상치제거-수기
            for row in range(self.tbl_showData.rowCount()):

                # file_path
                fileName = str(self.tbl_showData.item(row, 0).text())  # file_name
                filePath = str(self.tbl_showData.item(row, 1).text())  # file_directory
                fileData = "{0}\{1}".format(filePath, fileName)  # file_path

                # obs_num
                strObsId = os.path.splitext(os.path.basename(fileData))[0]

                # final_data
                pd_final = None

                ### 데이터 품질관리 시작 #############################################

                print("--Start ", strObsId, " Data Quality Management--")
                DATA_QM = DataQualityManagement(fileData)

                # 데이터 시간표기변경 (2400 -> 0000)
                pd_convertTimeEpr = DATA_QM.TIME_EXPRESSION_MODIFY()
                print(strObsId, " TIME_EXPRESSION_MODIFY")

                # 데이터 콤마제거
                pd_removeComma = DATA_QM.REMOVE_COMMA(pd_convertTimeEpr)
                print(strObsId, " REMOVE_COMMA")

                # 데이터 날짜누락 보간 (사용X - OpenAPI에서는 Fulltime으로 테이터가 제공됨.)
                # pd_timeModify = DATA_QM.TIME_MODIFY(pd_removeComma)
                # pd_timeModify = pd_removeComma

                # 데이터 중복 제거
                pd_removeDuplicate = DATA_QM.REMOVE_DUPLICATE(pd_removeComma)
                print(strObsId, " REMOVE_DUPLICATE")

                pd_nullToZero = None
                pd_removeOutlier = None

                # 마이너스값 0으로 변경 (수위제외, 유량/조위/댑유입량/댐방류량)
                pd_minusToZero = DATA_QM.MINUS_TO_ZERO(pd_removeDuplicate)
                print(strObsId, " MINUS_TO_ZERO")

                # 3시간 선형보간
                pd_3hrInterpolation = DATA_QM.THREEHR_INTERPOLATION(pd_minusToZero)
                print(strObsId, " 3HR_INTERPOLATION")

                # Null값을 0으로 (수위제외, 유량/조위/댑유입량/댐방류량)
                pd_nullToZero = DATA_QM.NULL_TO_ZERO(pd_3hrInterpolation)
                print(strObsId, " NULL_TO_ZERO")

                # 파일데이터생성 (date, dt_data, mi_data)
                dt_data = pd_removeDuplicate
                mi_dataTmp = pd_nullToZero
                mi_data = mi_dataTmp.iloc[:, 1]

                pd_file = pd.concat([dt_data, mi_data], axis=1)

                saveFilePath = "{0}\{1}".format(dirPath, fileName)
                pd.DataFrame(pd_file).to_csv((saveFilePath), header=False, index=False)

            QMessageBox.information(self, 'Message', "작업을 완료했습니다.", QMessageBox.Ok)

    # tab [데이터 관리] : [데이터파일 불러오기] 테이블선택 Combobox Event
    def SetDataTableType(self, index):
        # 이상치제거(ckb_data_option1), 결측치보정(ckb_data_option2)
        # 파일저장버튼(btn_dataSaveFile), 테이블선택콤보박스(cb_dataTable)
        strTableNm = self.cb_dataTable.currentText().strip()
        if (strTableNm == "rainfall"):
            # 강우일 경우는 결측치를 보정해 파일로 내리거나 모두 임포트만 가능
            self.ckb_data_option1.setEnabled(False)
            self.ckb_data_option2.setEnabled(False)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(True)
            self.btn_dataSaveFile.setEnabled(True)
        elif (strTableNm == "watershed"):
            # 유역평균강우는 모두 수기이므로 품질관리 비활성화, 모두 임포트만 가능
            self.ckb_data_option1.setEnabled(False)
            self.ckb_data_option2.setEnabled(False)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(False)
            self.btn_dataSaveFile.setEnabled(False)
        else:
            self.ckb_data_option1.setEnabled(True)
            self.ckb_data_option2.setEnabled(True)
            self.ckb_data_option1.setChecked(False)
            self.ckb_data_option2.setChecked(False)
            self.btn_dataSaveFile.setEnabled(False)

    # tab [데이터 관리] : [openAPI 불러오기] 조회 Button Event
    def Search_OpenAPIData(self):

        # 조회전, 입력값 체크
        if (self.CheckOpenAPI_SearchDataInputValue() == False):
            return

        self.tbl_apiData.clearContents()

        # 인터넷연결확인
        ipaddress = socket.gethostbyname(socket.gethostname())
        if ipaddress == "127.0.0.1":
            QMessageBox.warning(None, 'Error Message', "인터넷 연결이 올바르지 않습니다.", QMessageBox.Ok)
            return

        # openAPI 데이터 정보(테이블, 컬럼) 설정
        idxDataType = self.cb_apiObsType.currentIndex()
        strDataType = ''
        colName = ''
        if (idxDataType == 0):      # 수위(한강홍수통제소)
            strDataType = 'waterlevel'
            colName = 'wl'
        elif (idxDataType == 1):    # 유량(한강홍수통제소)
            strDataType = 'waterlevel'
            colName = 'fw'
        elif (idxDataType == 2):    # 강우(한강홍수통제소)
            strDataType = 'rainfall'
            colName = 'rf'
        elif (idxDataType == 3):    # 댐유입량(한강홍수통제소)
            strDataType = 'dam'
            colName = 'inf'
        elif (idxDataType == 4):    # 댐방류량(한강홍수통제소)
            strDataType = 'dam'
            colName = 'tototf'
        elif (idxDataType == 5):    # 조위(해양조사원)
            strDataType = 'tidelevel'
            colName = 'tide_level'
        else:
            return

        # 관측소번호 설정
        strObsId = ""
        if self.cb_apiObsCodeType.currentIndex() == 0:
            strObsId = self.txt_apiObsCode.text()
            if (idxDataType == 5):
                strObsId = strObsId.strip().upper()
        else:
            strObsId = self.cb_apiObsCode.currentText()

        # 조회기간 설정
        start = self.dt_apiStartDt.text()
        end = self.dt_apiEndDt.text()
        startDate = "{0}{1}{2}0000".format(start[0:4], start[5:7], start[8:10])
        endDate = "{0}{1}{2}2350".format(end[0:4], end[5:7], end[8:10])

        # openAPI 정보 설정

        # 환경부 한강홍수통제소 자료 (10분단위, 최대1개월까지 조회가능)
        # 낙동강, 금강, 영산강 권역의 자료는 한강 권역의 자료 보다 늦게 수집 됩니다.
        # 한강 권역 : 7~8분, 낙동강, 금강, 영산강 권역 : 11분 이상, 따라서 관측소별로 최종자료 시간이 다를 수 있습니다.
        # 수위/유량 데이터 url (wlobscd, ymdhm, wl, fw) - 관측소code, 년월일시분(yyyyMMddHHmm), 수위자료(m)(#), 유량자료(m3/s)(#)
        # url_waterlevel = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/waterlevel/list/10M/1001607/202108010000/202108012350.json'
        # 강우 url (rfobscd, ymdhm, rf) - 관측소code, 년월일시분(yyyyMMddHHmm), 강수량자료(mm)(#)
        # url_rainfall = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/rainfall/list/10M/10014010/202208090000/202208092350.json'
        # 댐유입/방류 데이터 url (dmobscd, ymdhm, swl, inf, sfw, ecpc, tototf) - 코드, 일시분, 현재수위, 유입량(#), 저수량, 공용량, 총방류량(#)
        # url_dam = 'https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/dam/list/10M/1001210/202308090000/202308101700.json'

        # 해양수산부 국립해양조사원 조위관측소 자료 (1분단위, 최대1일까지 조회가능)
        # 조위 url = https://www.khoa.go.kr/api/oceangrid/tideObs/search.do?ServiceKey=JuG/Up/1yV7/MD3MhQuduQ==&ObsCode=DT_0001&Date=20220809&ResultType=json

        url = ""        # openAPI service_url
        myKey = ""      # openAPI KEY (KEY정보 변경하기)
        url_data = ''
        if (idxDataType == 5):
            url = "https://www.khoa.go.kr/api/oceangrid/tideObs/search.do?ServiceKey={0}&ObsCode={1}&Date={2}&ResultType=json"
            myKey = "JuG/Up/1yV7/MD3MhQuduQ=="
            url_data = url.format(myKey, strObsId, startDate[0:8])
        else:
            url = "https://api.hrfco.go.kr/{0}/{1}/list/10M/{2}/{3}/{4}.json"
            myKey = "52832662-D130-4239-9C5F-730AD3BE6BC6"
            url_data = url.format(myKey, strDataType, strObsId, startDate, endDate)

        # openAPI 자료 가져오기
        response = requests.get(url_data)
        if response.status_code == 200:
            data = json.loads(response.text)
            if (idxDataType == 5):
                for errData in data['result'].keys():
                    if errData == "error":
                        self.tbl_apiData.setRowCount(0)
                        self.tbl_apiData.setColumnCount(0)
                        QMessageBox.warning(None, 'Error Message', data['result'][errData], QMessageBox.Ok)
                        return False

                df = pd.json_normalize(data['result']['data'])
                labels = ['record_time', colName]
                nb_row = len(df)
                nb_col = len(labels)
                self.tbl_apiData.setRowCount(nb_row)
                self.tbl_apiData.setColumnCount(nb_col)
                self.tbl_apiData.setHorizontalHeaderLabels(labels)
                idxTable = 0
                for row in range(len(df)):
                    Datetext = str(str(df.loc[row]['record_time']))
                    datetime_format = "%Y-%m-%d %H:%M:%S"
                    datetimeText = datetime.strptime(Datetext, datetime_format)
                    # 1분단위 데이터이므로 10분단위 측정자료만 가져옴
                    if datetimeText.minute % 10 == 0:
                        item = QTableWidgetItem(str(df.loc[row]['record_time']))
                        self.tbl_apiData.setItem(idxTable, 0, item)
                        item = QTableWidgetItem(str(df.loc[row][colName]))
                        self.tbl_apiData.setItem(idxTable, 1, item)
                        idxTable += 1
                self.tbl_apiData.resizeColumnsToContents()
                self.tbl_apiData.setRowCount(idxTable)

            else:
                for errData in data.keys():
                    if errData == "message":
                        self.tbl_apiData.setRowCount(0)
                        self.tbl_apiData.setColumnCount(0)
                        QMessageBox.warning(None, 'Error Message', data[errData], QMessageBox.Ok)
                        return False

                df = pd.json_normalize(data['content'])
                labels = ['ymdhm', colName]
                nb_row = len(df)
                nb_col = len(labels)
                self.tbl_apiData.setRowCount(nb_row)
                self.tbl_apiData.setColumnCount(nb_col)
                self.tbl_apiData.setHorizontalHeaderLabels(labels)
                for row in range(len(df)):
                    item = QTableWidgetItem(str(df.loc[nb_row - row - 1]['ymdhm']))
                    self.tbl_apiData.setItem(row, 0, item)
                    item = QTableWidgetItem(str(df.loc[nb_row - row - 1][colName]))
                    self.tbl_apiData.setItem(row, 1, item)

                self.tbl_apiData.resizeColumnsToContents()

            return True
        else:
            errMsg = str(response.status_code)
            QMessageBox.warning(None, 'Error Message', errMsg, QMessageBox.Ok)
            return False

    # tab [데이터 관리] : [openAPI 불러오기] 조회전, 입력값 체크
    def CheckOpenAPI_SearchDataInputValue(self):

        # 1.관측소번호를 입력했는지,
        strObsId = ""
        if self.cb_apiObsCodeType.currentIndex() == 0:
            strObsId = self.txt_apiObsCode.text()
        else:
            strObsId = self.cb_apiObsCode.currentText()
        if (strObsId == ""):
            QMessageBox.warning(None, 'Error Message', "조회할 관측소 번호를 입력해주세요.", QMessageBox.Ok)
            return False

        # 2. 조회기간이 올바른지(시작일이 종료일보다 크거나 같은지)
        if (self.dt_apiStartDt.date() > self.dt_apiEndDt.date()):
            QMessageBox.warning(None, 'Error Message', "조회 시작일이 종료일보다 클 수 없습니다.", QMessageBox.Ok)
            return False

        # 3. 조회기간이 한달 또는 하루(조위)를 넘어가지는 않는지,
        idxDataType = self.cb_apiObsType.currentIndex()
        start = self.dt_apiStartDt.text()
        end = self.dt_apiEndDt.text()
        dateMonth = datetime(int(start[0:4]), int(start[5:7]), int(start[8:10])) + relativedelta(months=1)
        dateEnd = datetime(int(end[0:4]), int(end[5:7]), int(end[8:10]))

        if (idxDataType == 5):
            if (start != end):
                QMessageBox.warning(None, 'Error Message', "조회 기간은 하루(1일)까지만 가능합니다.", QMessageBox.Ok)
                return False
        else:
            if (dateEnd.date() > dateMonth.date()):
                QMessageBox.warning(None, 'Error Message', "조회 기간은 1개월까지만 가능합니다.", QMessageBox.Ok)
                return False

        return True

    # tab [데이터 관리] : [openAPI 불러오기] 관측소코드 선택
    def SetOpenAPI_ObsCodeInputType(self, index):
        if (index == 0):    # 직접입력
            self.txt_apiObsCode.show()
            self.cb_apiObsCode.hide()
        elif (index == 1):  # 목록선택
            self.txt_apiObsCode.hide()
            self.cb_apiObsCode.show()
            self.SetOpenAPI_ObsCodeList()
        else:
            print("nothing")

    # tab [데이터 관리] : [openAPI 불러오기] 관측소목록 변경
    def SetOpenAPI_ObsType(self, index):
        self.SetOpenAPI_ObsCodeInputType(self.cb_apiObsCodeType.currentIndex())

    # tab [데이터 관리] : [openAPI 불러오기] 관측소목록 가져오기
    def SetOpenAPI_ObsCodeList(self):

        # 수위/유량관측소 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/waterlevel/info.json
        # 강우관측소 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/rainfall/info.json
        # 댐 제원정보
        # https://api.hrfco.go.kr/52832662-D130-4239-9C5F-730AD3BE6BC6/dam/info.json
        # 조위관측소 제원정보
        # http://www.khoa.go.kr/api/oceangrid/ObsServiceObj/search.do?ServiceKey=wldhxng34hkddbsgm81lwldhxng34hkddbsgm81l==&ResultType=json

        self.cb_apiObsCode.clear()

        # 인터넷연결확인
        ipaddress = socket.gethostbyname(socket.gethostname())
        if ipaddress == "127.0.0.1":
            return

        # 관측소 종류에 따라 조회자료, 기관, 컬럼명 변경
        url = "https://api.hrfco.go.kr/{0}/{1}/info.json"
        myKey = "52832662-D130-4239-9C5F-730AD3BE6BC6"
        strDataType = ''
        colName = ''
        url_obs = ''

        idxDataType = self.cb_apiObsType.currentIndex()
        if (idxDataType == 0):
            strDataType = 'waterlevel'
            colName = 'wlobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 1):
            strDataType = 'waterlevel'
            colName = 'wlobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 2):
            strDataType = 'rainfall'
            colName = 'rfobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 3):
            strDataType = 'dam'
            colName = 'dmobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 4):
            strDataType = 'dam'
            colName = 'dmobscd'
            url_obs = url.format(myKey, strDataType)
        elif (idxDataType == 5):
            url = "http://www.khoa.go.kr/api/oceangrid/ObsServiceObj/search.do?ServiceKey={0}&ResultType=json"
            myKey = "JuG/Up/1yV7/MD3MhQuduQ=="
            colName = 'obs_post_id'
            url_obs = url.format(myKey)
        else:
            return

        # openAPI 관측소 제원정보(관측소코드) 가져오기
        response = requests.get(url_obs)
        if response.status_code == 200:
            data = json.loads(response.text)
            if (idxDataType == 5): #조위일경우
                for datas in data['result']['data']:
                    if datas is not None:
                        codeNo = datas[colName]
                        if codeNo != None:
                            self.cb_apiObsCode.addItem(codeNo)
            else:
                for datas in data['content']:
                    if datas is not None:
                        codeNo = datas[colName]
                        if codeNo != None:
                            self.cb_apiObsCode.addItem(codeNo)
            return True
        else:
            errMsg = str(response.status_code)
            QMessageBox.warning(None, 'Error Message', errMsg, QMessageBox.Ok)
            return False

    # tab [데이터 관리] : [openAPI 불러오기] 파일저장
    def Save_OpenAPIData(self):

        # 저장할 내용이 없을경우, 취소
        if self.tbl_apiData.rowCount() == 0:
            QMessageBox.warning(None, 'Error Message', "저장할 데이터가 없습니다.", QMessageBox.Ok)
            return

        idxDataType = self.cb_apiObsType.currentIndex()

        # obsNo
        strObsId = ""
        if self.cb_apiObsCodeType.currentIndex() == 0:
            strObsId = self.txt_apiObsCode.text()
            if (idxDataType == 5):
                strObsId = strObsId.strip().upper()
        else:
            strObsId = self.cb_apiObsCode.currentText()

        # 조위일경우 날짜형식을 변경하여 저장
        bChangeDateType = False
        if self.cb_apiObsType.currentIndex() == 5:
            bChangeDateType = True

        # 파일 정보 설정
        file = QFileDialog.getSaveFileName(self, "Save file", strObsId, "*.csv")
        # 저장경로가 없을때 리턴
        if file[0] == '':
            return
        # 저장경로 정보 설정
        saveFilePath = file[0]

        # 파일저장
        saveFile = open(saveFilePath, 'w', newline='')
        wr = csv.writer(saveFile)
        for row in range(self.tbl_apiData.rowCount()):
            rowdata = []
            for col in range(self.tbl_apiData.columnCount()):
                itemText = str(self.tbl_apiData.item(row, col).text())
                if ((col == 0) and (bChangeDateType == True)):
                    itemText = "{0}{1}{2}{3}{4}".format(itemText[0:4],itemText[5:7],itemText[8:10], itemText[11:13],itemText[14:16])
                rowdata.append(itemText)
            wr.writerow(rowdata)
        saveFile.close()

        QMessageBox.information(self, 'Message', "작업을 완료했습니다.", QMessageBox.Ok)

    # tab [데이터 관리] : [데이터조회] 관측소번호선택방법 Combobox 설정
    def SetDataSearchInputType(self, index):
        if (index == 0):  # 직접입력
            self.txtBox_inputUser.show()
            self.cb_inputSelect.hide()
        elif (index == 1):  # 목록선택
            self.txtBox_inputUser.hide()
            self.cb_inputSelect.show()
            self.SearchTableObsIdList()
        else:
            print("nothing")

    # tab [데이터 관리] : [데이터조회] 관측소종류에 따른 목록변경
    def SetDataSearchTableData(self, index):
        self.SetDataSearchInputType(self.cb_inputType.currentIndex())

    # tab [데이터 관리] : [데이터조회] 관측소목록 Combobox 설정
    def SearchTableObsIdList(self):
        # 데이터조회
        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()

        # 데이터관리 - 데이터베이스 내 관측소별 관측소코드 목록 가져오기
        strTblNm = self.cb_searchTable.currentText()
        select_query = "SELECT OBS_ID FROM {0} GROUP BY OBS_ID".format(strTblNm)

        self.cb_inputSelect.clear()
        cur.execute(select_query)
        resultset = cur.fetchall()
        for idx in range(len(resultset)):
            self.cb_inputSelect.addItem(resultset[idx][0])

        conn.close()

    # tab [데이터 관리] : [데이터조회] 조회전, 입력값 체크
    def CheckSearchDataInputValue(self):

        # 1.관측소번호를 입력했는지,
        strObsId = ""
        if self.cb_inputType.currentIndex() == 0:
            strObsId = self.txtBox_inputUser.text()
        else:
            strObsId = self.cb_inputSelect.currentText()
        if (strObsId == ""):
            QMessageBox.warning(None, 'Error Message', "조회할 관측소 번호를 입력해주세요.", QMessageBox.Ok)
            return False

        # 2. 조회기간이 올바른지(시작일이 종료일보다 크거나 같은지)
        if (self.dt_data_startTime.date() > self.dt_data_endTime.date()):
            QMessageBox.warning(None, 'Error Message', "조회 시작일이 종료일보다 클 수 없습니다.", QMessageBox.Ok)
            return False

        return True

    # tab [데이터 관리] : [데이터조회] 조회 Button Event
    def SearchData(self):
        # 조회전, 입력값 체크하기
        if (self.CheckSearchDataInputValue() == False):
            return

        # 관측소종류
        strTblNm = self.cb_searchTable.currentText()

        # 관측소코드
        strObsId = ""
        if self.cb_inputType.currentIndex() == 0:
            strObsId = self.txtBox_inputUser.text()
        else:
            strObsId = self.cb_inputSelect.currentText()

        # 자료종류 (0-표준화자료, 1-결측치보정자료, 2-이상치제거자료)
        strDataCol = ""
        if (self.cb_dataCol.currentIndex() == 1):
            strDataCol = "MI_DATA"
        elif (self.cb_dataCol.currentIndex() == 2):
            strDataCol = "OI_DATA"
        else:
            strDataCol = "DT_DATA"

        # 조회기간 설정
        start = self.dt_data_startTime.text()
        end = self.dt_data_endTime.text()
        sql_date = "date_format(DT_DATE, '%Y-%m-%d') between '{0}' and '{1}'".format(start, end)

        # 데이터 조회
        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()
        select_all_query = "select OBS_ID, DT_DATE, {0} from {1} where OBS_ID = '{2}' and ({3}) ORDER BY DT_DATE".format(strDataCol, strTblNm, strObsId, sql_date)
        cur.execute(select_all_query)
        resultset = cur.fetchall()

        conn.close()

        # 그래프 그리기
        global canvas
        global toolbar
        global fig

        self.fig.clf()
        ax = self.fig.add_subplot(111)

        if len(resultset) == 0:
            QMessageBox.warning(self, 'Error Message', "조회된 데이터가 없습니다.", QMessageBox.Ok)
        else:
            x_temp = [i[1] for i in resultset]
            y_temp = [self.convert_data_nullToNan(i[2]) for i in resultset]
            strTitle = "{0}({1}) {2}~{3}".format(strTblNm, strObsId, str(x_temp[0])[0:16], str(x_temp[len(x_temp)-1])[0:16])
            ax.set_title(strTitle)
            ax.plot(x_temp, y_temp)

        self.fig.tight_layout()
        self.canvas.draw()

    # tab [데이터 관리] : [데이터조회] 조회자료가 NULL값일 경우 처리
    def convert_data_nullToNan(self, data):
        if str(data) == 'None':
            return np.NAN
        else:
            return float(data)

    # tab [데이터셋 생성]: [1단계-지점정보] TargetPoint (+) Button
    def btn_getSelectedFeatureTarget(self):
        self.cb_dsRef_targetPoint_id.clear()
        lyrName = "waterlevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) == 1:
            for f in selectLyr:
                self.cb_dsRef_targetPoint_id.addItem(str(f['obs_code']), f)
        if (len(selectLyr) > 1):
            QMessageBox.warning(None, 'Error Message', "Target Point는 한개만 선택되어야 합니다.", QMessageBox.Ok)

    # tab [데이터셋 생성]: [1단계-지점정보]  Waterlevel (+) Button
    def btn_getSelectedFeatureWL(self):
        self.cb_dsRef_waterLevel_id.clear()
        self.lbl_refWaterlevelCount.setText('(0)')
        lyrName = "waterlevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_waterLevel_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refWaterlevelCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]: [1단계-지점정보] Rainfall (+) Button
    def btn_getSelectedFeatureRF(self):
        self.cb_dsRef_rainfall_id.clear()
        self.lbl_refRainfallCount.setText('(0)')
        lyrName = "rainfall"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_rainfall_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refRainfallCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]: [1단계-지점정보] Discharge (+) Button
    def btn_getSelectedFeatureDC(self):
        self.cb_dsRef_flowrate_id.clear()
        self.lbl_refDischargeCount.setText('(0)')
        lyrName = "discharge"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_flowrate_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refDischargeCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]: [1단계-지점정보] Daminlet (+) Button
    def btn_getSelectedFeatureDI(self):
        self.cb_dsRef_damInlet_id.clear()
        self.lbl_refDaminletCount.setText('(0)')
        lyrName = "daminlet"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_damInlet_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refDaminletCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]:[1단계-지점정보] Damrelease (+) Button
    def btn_getSelectedFeatureDR(self):
        self.cb_dsRef_damRelease_id.clear()
        self.lbl_refDamreleaseCount.setText('(0)')
        lyrName = "damrelease"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_damRelease_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refDamreleaseCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]:[1단계-지점정보] Tidelevel (+) Button
    def btn_getSelectedFeatureTE(self):
        self.cb_dsRef_elevation_id.clear()
        self.lbl_refTidelevelCount.setText('(0)')
        lyrName = "tidelevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_elevation_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_refTidelevelCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]:[1단계-지점정보] Watershed (+) Button
    def btn_getSelectedFeatureTS(self):
        self.cb_dsRef_thiessen_id.clear()
        self.lbl_refThiessenCount.setText('(0)')
        lyrName = "watershed"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_dsRef_thiessen_id.addItem(str(f['sbsncd']), f)
                fCount = fCount + 1
            self.lbl_refThiessenCount.setText("("+str(fCount)+")")

    # tab [데이터셋 생성]: [2단계:기간선택] 선택 Event
    def SetDatasetPeriodRadioGroup(self):
        # control initialize
        self.cb_dataset_startYear.setEnabled(False)
        self.cb_dataset_endYear.setEnabled(False)
        self.dt_dataset_startTime.setEnabled(False)
        self.dt_dataset_endTime.setEnabled(False)
        self.cb_dataset_startYear.setEnabled(self.rb_dataset_periodYear.isChecked())
        self.cb_dataset_endYear.setEnabled(self.rb_dataset_periodYear.isChecked())
        self.dt_dataset_startTime.setEnabled(self.rb_dataset_periodDate.isChecked())
        self.dt_dataset_endTime.setEnabled(self.rb_dataset_periodDate.isChecked())

    # tab [데이터셋 생성]: [2단계:리드타임설정] 선택 Event
    def SetDatasetLeadtimeRadioGroup(self):
        # control initialize
        self.ckb_ds_leadtimeHarf.setEnabled(False)
        self.ckb_ds_leadtime1h.setEnabled(False)
        self.ckb_ds_leadtime2h.setEnabled(False)
        self.ckb_ds_leadtime3h.setEnabled(False)
        self.ckb_ds_leadtime4h.setEnabled(False)
        self.ckb_ds_leadtime5h.setEnabled(False)
        self.ckb_ds_leadtime6h.setEnabled(False)
        self.cb_ds_leadtimeTarget.setEnabled(False)
        self.cb_ds_leadtimeTerm.setEnabled(False)
        self.cb_ds_leadtimeUnit.setEnabled(False)
        self.ckb_ds_leadtimeHarf.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime1h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime2h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime3h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime4h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime5h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.ckb_ds_leadtime6h.setEnabled(self.rb_ds_leadtimeBasic.isChecked())
        self.cb_ds_leadtimeTarget.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())
        self.cb_ds_leadtimeTerm.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())
        self.cb_ds_leadtimeUnit.setEnabled(self.rb_ds_leadtimeTimeseries.isChecked())

    # tab [데이터셋 생성]: [2단계:리드타임설정] 시간단위선택 Combobox Event
    def SetDatasetOptionLeadtime(self, index):
        self.cb_ds_leadtimeTerm.clear()
        if (index == 0):
            for i in range(1, 7, 1):
                self.cb_ds_leadtimeTerm.addItem(str(i))
            self.lbl_ds_leadtimeTerm.setText("시간간격")
        elif (index == 1):
            for i in range(1, 7, 1):
                self.cb_ds_leadtimeTerm.addItem(str(i * 10))
            self.lbl_ds_leadtimeTerm.setText("분간격")
        else:
            self.cb_ds_leadtimeTerm.clear()
            self.lbl_ds_leadtimeTerm.setText("")

    # tab [데이터셋 생성]: [전처리옵션:기간필터링] 기간필터링 Checkbox Event
    def SetDatasetPreMonth(self):
        self.rb_ds_preProcessing_month.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.rb_ds_preProcessing_date.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startMonth.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endMonth.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startDate.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endDate.setEnabled(self.ckb_ds_preProcessing_month.isChecked())
        if (self.ckb_ds_preProcessing_month.isChecked()):
            self.SetDatasetPreDateFiltering()

    # tab [데이터셋 생성]: [전처리옵션:누적강우생성] 누적강우생성 Checkbox Event
    def SetDatasetPreAccRain(self):
        self.txtBox_ds_preProcessing_accRainHour.setEnabled(self.sp_ds_preProcessing_noRainVal.isChecked())

    # tab [데이터셋 생성]: [전처리옵션:기간필터링] 기간필터링 Radiobutton Event
    def SetDatasetPreDateFiltering(self):
        # control initialize
        self.sp_ds_preProcessing_startMonth.setEnabled(False)
        self.sp_ds_preProcessing_endMonth.setEnabled(False)
        self.sp_ds_preProcessing_startDate.setEnabled(False)
        self.sp_ds_preProcessing_endDate.setEnabled(False)
        self.sp_ds_preProcessing_startMonth.setEnabled(self.rb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_endMonth.setEnabled(self.rb_ds_preProcessing_month.isChecked())
        self.sp_ds_preProcessing_startDate.setEnabled(self.rb_ds_preProcessing_date.isChecked())
        self.sp_ds_preProcessing_endDate.setEnabled(self.rb_ds_preProcessing_date.isChecked())

    # tab [데이터셋 생성]:[1단계-지점정보] 레이어정보
    def getSeletedFeature(self, lyrName):
        selectFeatures = []
        for lyr in QgsProject.instance().mapLayers().values():
            gislyrName = lyr.name()
            if (lyrName in gislyrName.lower()) == True:
                selectFeatures = lyr.selectedFeatures()

        if len(selectFeatures) == 0:
            QMessageBox.warning(None, 'Error Message', "선택된 객체가 없습니다.", QMessageBox.Ok)

        return selectFeatures

    # tab [데이터셋 생성]: 데이터셋생성전, 입력정보 체크
    def CheckDatasetInfo(self):

        # 1.Target 지점선택 되었는지
        isSelectPoint = False
        # target
        if self.cb_dsRef_targetPoint_id.currentText() != '':
            isSelectPoint = True
        if isSelectPoint == False:
            QMessageBox.warning(None, 'Error Message', "조회할 Target 지점 정보를 설정해주세요.", QMessageBox.Ok)
            return False

        # 2. Reference 지점선택 되었는지
        nRefCount = 0
        nRefCount += self.cb_dsRef_waterLevel_id.count()
        nRefCount += self.cb_dsRef_rainfall_id.count()
        nRefCount += self.cb_dsRef_flowrate_id.count()
        nRefCount += self.cb_dsRef_damInlet_id.count()
        nRefCount += self.cb_dsRef_damRelease_id.count()
        nRefCount += self.cb_dsRef_elevation_id.count()
        nRefCount += self.cb_dsRef_thiessen_id.count()
        if nRefCount == 0:
            QMessageBox.warning(None, 'Error Message', "조회할 Reference 지점 정보를 설정해주세요.", QMessageBox.Ok)
            return False

        # 3.기간선택 되었는지
        isPeriod = False
        if self.rb_dataset_periodYear.isChecked():
            startYear = int(self.cb_dataset_startYear.currentText())
            endYear = int(self.cb_dataset_endYear.currentText())
            startMonth = 1
            endMonth = 12
            if ((startYear == endYear) and startMonth <= endMonth) or (
                    ((startYear < endYear) and ((startMonth <= endMonth))) or (
                    (startYear < endYear) and ((startMonth > endMonth)))):
                isPeriod = True
        if self.rb_dataset_periodDate.isChecked():
            start = self.dt_dataset_startTime.dateTime()
            end = self.dt_dataset_endTime.dateTime()
            if start <= end:
                isPeriod = True
        if isPeriod == False:
            QMessageBox.warning(None, 'Error Message', "조회할 기간 정보를 설정해주세요.", QMessageBox.Ok)
            return False

        # 4. 전처리옵션 설정체크
        if (self.sp_ds_preProcessing_noRainVal.isChecked()):
            if (self.txtBox_ds_preProcessing_accRainHour.text().strip()==''):
                QMessageBox.warning(None, 'Error Message', "전처리옵션 누적강우 생성정보를 다시 확인해주세요.", QMessageBox.Ok)
                return False
            else:
                tmpAccRainTerm = self.txtBox_ds_preProcessing_accRainHour.text().split(',')
                for tmpNumber in tmpAccRainTerm:
                    try:
                        intValues = int(tmpNumber.strip())
                    except ValueError:
                        QMessageBox.warning(None, 'Error Message', "전처리옵션 누적강우 입력정보를 다시 확인해주세요.\n(예시 - 6시간,8시간일 경우 6,8 로 표기)", QMessageBox.Ok)
                        return False

        if (self.ckb_ds_preProcessing_month.isChecked()):
            if (self.rb_ds_preProcessing_month.isChecked()):
                stdMonth = self.sp_ds_preProcessing_startMonth.currentText()
                endMonth = self.sp_ds_preProcessing_endMonth.currentText()
                if int(stdMonth) > int(endMonth):
                    QMessageBox.warning(None, 'Error Message', "전처리옵션 기간필터링 정보를 다시 확인해주세요.", QMessageBox.Ok)
                    return False
            if (self.rb_ds_preProcessing_date.isChecked()):
                stdDate = self.sp_ds_preProcessing_startDate.text()
                endDate = self.sp_ds_preProcessing_endDate.text()
                stdDay = stdDate[0:2] + stdDate[3:5]
                endDay = endDate[0:2] + endDate[3:5]
                if int(stdDay) > int(endDay):
                    QMessageBox.warning(None, 'Error Message', "전처리옵션 기간필터링 정보를 다시 확인해주세요.", QMessageBox.Ok)
                    return False

        # 5.리드타임설정 되었는지
        isLeadtime = False
        if self.rb_ds_leadtimeBasic.isChecked():
            if self.ckb_ds_leadtimeHarf.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime1h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime2h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime3h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime4h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime5h.isChecked():
                isLeadtime = True
            if self.ckb_ds_leadtime6h.isChecked():
                isLeadtime = True
        if self.rb_ds_leadtimeTimeseries.isChecked():
            isLeadtime = True
        if isLeadtime == False:
            QMessageBox.warning(None, 'Error Message', "조회할 리드타임 정보를 설정해주세요.", QMessageBox.Ok)
            return False

        return True

    # tab [데이터셋생성] Make Dataset button
    def MakeDataset(self):

        if (self.CheckDatasetInfo() == False):
            return

        self.tbl_makeDataset.clearContents()
        self.tbl_preProcessing_makeDataset.clearContents()

        # column header setting
        columnHeader = []
        columnHeader.append("DATE")

        resultset_now = []
        resultset_after = []

        # 1. 지점정보
        targetText = self.cb_dsRef_targetPoint_id.currentText()
        dataWaterlevel = [self.cb_dsRef_waterLevel_id.itemText(i) for i in range(self.cb_dsRef_waterLevel_id.count())]
        dataRainfall = [self.cb_dsRef_rainfall_id.itemText(i) for i in range(self.cb_dsRef_rainfall_id.count())]
        dataDaminlet = [self.cb_dsRef_damInlet_id.itemText(i) for i in range(self.cb_dsRef_damInlet_id.count())]
        dataDamrelease = [self.cb_dsRef_damRelease_id.itemText(i) for i in range(self.cb_dsRef_damRelease_id.count())]
        dataDischarge = [self.cb_dsRef_flowrate_id.itemText(i) for i in range(self.cb_dsRef_flowrate_id.count())]
        dataTidelevel = [self.cb_dsRef_elevation_id.itemText(i) for i in range(self.cb_dsRef_elevation_id.count())]
        dataWatershed = [self.cb_dsRef_thiessen_id.itemText(i) for i in range(self.cb_dsRef_thiessen_id.count())]

        # 2. 자료정보(컬럼, 표준화자료/결측치보정자료/이상치보정자료)
        arrDataCol = ['DT_DATA', 'MI_DATA', 'OI_DATA']
        target_col = arrDataCol[self.cb_dsCol_target.currentIndex()]
        waterlevel_col = arrDataCol[self.cb_dsCol_waterlevel.currentIndex()]
        rainfall_col = arrDataCol[self.cb_dsCol_rainfall.currentIndex()]
        discharge_col = arrDataCol[self.cb_dsCol_discharge.currentIndex()]
        daminlet_col = arrDataCol[self.cb_dsCol_daminlet.currentIndex()]
        damrelease_col = arrDataCol[self.cb_dsCol_damrelease.currentIndex()]
        tidelevel_col = arrDataCol[self.cb_dsCol_tidelevel.currentIndex()]
        watershed_col = arrDataCol[self.cb_dsCol_watershed.currentIndex()]

        # 3. 기간정보
        star = ''
        end = ''
        sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'"
        # 월별조회하기
        if self.rb_dataset_periodYear.isChecked():
            startYear = int(self.cb_dataset_startYear.currentText())
            endYear = int(self.cb_dataset_endYear.currentText())
            startMonth = 1
            endMonth = 12

            sql_date = "(YEAR(DT_DATE) BETWEEN '{0}' AND '{1}') AND (MONTH(DT_DATE) BETWEEN '{2}' AND '{3}')"
            sql_date = sql_date.format(startYear, endYear, startMonth, endMonth)
        # 상세기간별조회하기
        if self.rb_dataset_periodDate.isChecked():
            start = self.dt_dataset_startTime.text()
            end = self.dt_dataset_endTime.text()
            sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'".format(start, end)

        # 데이터조회 #########################################################################################

        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()

        # 데이터조회 - 지점데이터조회

        # 1. get Target Data
        if targetText != "":
            columnHeader.append('Target_' + targetText)
            select_all_query = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                target_col, targetText, sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 2. get Waterlevel Data
        for obs_row in range(len(dataWaterlevel)):
            if (dataWaterlevel[obs_row].strip() == ''): break
            columnHeader.append('WL_' + dataWaterlevel[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                waterlevel_col, dataWaterlevel[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 3. get Rainfall Data
        for obs_row in range(len(dataRainfall)):
            if (dataRainfall[obs_row].strip() == ''): break
            columnHeader.append('RF_' + dataRainfall[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from rainfall where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                rainfall_col, dataRainfall[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 4. get DamInlet Data
        for obs_row in range(len(dataDaminlet)):
            if (dataDaminlet[obs_row].strip() == ''): break
            columnHeader.append('DI_' + dataDaminlet[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from daminlet where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                daminlet_col, dataDaminlet[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 5. get DamRelease Data
        for obs_row in range(len(dataDamrelease)):
            if (dataDamrelease[obs_row].strip() == ''): break
            columnHeader.append('DR_' + dataDamrelease[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from damrelease where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                damrelease_col, dataDamrelease[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 6. get Flowarate Data
        for obs_row in range(len(dataDischarge)):
            if (dataDischarge[obs_row].strip() == ''): break
            columnHeader.append('DC_' + dataDischarge[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from discharge where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                discharge_col, dataDischarge[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 7. get Elevation Data
        for obs_row in range(len(dataTidelevel)):
            if (dataTidelevel[obs_row].strip() == ''): break
            columnHeader.append('TE_' + dataTidelevel[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from tidelevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                tidelevel_col, dataTidelevel[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 8. get Thiessen Data
        for obs_row in range(len(dataWatershed)):
            if (dataWatershed[obs_row].strip() == ''): break
            columnHeader.append('WS_' + dataWatershed[obs_row].strip())
            select_all_query = "select OBS_ID, DT_DATE, {0} from watershed where OBS_ID = '{1}' and {2} ORDER BY DT_DATE".format(
                watershed_col, dataWatershed[obs_row].strip(), sql_date)
            cur.execute(select_all_query)
            resultset = cur.fetchall()
            resultset_now.append(resultset)

        # 3. 리드타임 자료조회
        leadTexts = []
        leadControlText = []
        termUnitText = "H"
        if self.rb_ds_leadtimeBasic.isChecked():
            if self.ckb_ds_leadtimeHarf.isChecked():
                columnHeader.append('Lead_0.5H')
                leadTexts.append(30)
                leadControlText.append(0.5)
            if self.ckb_ds_leadtime1h.isChecked():
                columnHeader.append('Lead_1H')
                leadTexts.append(60)
                leadControlText.append(1)
            if self.ckb_ds_leadtime2h.isChecked():
                columnHeader.append('Lead_2H')
                leadTexts.append(120)
                leadControlText.append(2)
            if self.ckb_ds_leadtime3h.isChecked():
                columnHeader.append('Lead_3H')
                leadTexts.append(180)
                leadControlText.append(3)
            if self.ckb_ds_leadtime4h.isChecked():
                columnHeader.append('Lead_4H')
                leadTexts.append(240)
                leadControlText.append(4)
            if self.ckb_ds_leadtime5h.isChecked():
                columnHeader.append('Lead_5H')
                leadTexts.append(300)
                leadControlText.append(5)
            if self.ckb_ds_leadtime6h.isChecked():
                columnHeader.append('Lead_6H')
                leadTexts.append(360)
                leadControlText.append(6)
        if self.rb_ds_leadtimeTimeseries.isChecked():
            targetTime = int(self.cb_ds_leadtimeTarget.currentText())
            termTime = int(self.cb_ds_leadtimeTerm.currentText())
            termUnit = 0
            termUnitText = "H"

            if (self.cb_ds_leadtimeUnit.currentIndex() == 0):
                termUnit = 60
                termUnitText = "H"
            elif (self.cb_ds_leadtimeUnit.currentIndex() == 1):
                termUnit = termTime
                termUnitText = "M"
            else:
                termUnit = 0
                termUnitText = "H"

            for dataTime in range(int((60 * targetTime) / termUnit)):
                leadtimeData = 0
                if (self.cb_ds_leadtimeUnit.currentIndex() == 0):  # 시간
                    leadtimeData = int(60 * (dataTime + 1) / 60)
                    columnHeader.append('Lead_' + str(leadtimeData) + termUnitText)
                    leadControlText.append((dataTime + 1))
                elif (self.cb_ds_leadtimeUnit.currentIndex() == 1):  # 분
                    leadtimeData = termUnit * (dataTime + 1)
                    columnHeader.append('Lead_' + str(leadtimeData) + termUnitText)
                    leadControlText.append(termUnit * (dataTime + 1))
                else:
                    leadtimeData = 0
                    termUnitText = "H"

                leadTexts.append(termUnit * (dataTime + 1))

        # 리드타임 조회
        for leads in range(len(leadTexts)):
            lead_text = str(leadTexts[leads])
            if self.rb_dataset_periodYear.isChecked():
                startYear = int(self.cb_dataset_startYear.currentText())
                endYear = int(self.cb_dataset_endYear.currentText())
                startMonth = 1
                endMonth = 12

                sql_query = "SELECT obs_id, dt_date, {0}  FROM (SELECT obs_id AS oid, dt_date AS odate, {1} AS odata FROM waterlevel WHERE obs_id='{2}' and {3}) AS sel_data, waterlevel WHERE OBS_ID='{4}' and DATE_ADD(sel_data.odate, INTERVAL {5} MINUTE) = dt_date ORDER BY DT_DATE"
                select_all_query_after = sql_query.format(target_col, target_col, targetText, sql_date, targetText, leadTexts[leads])
                cur.execute(select_all_query_after)
            elif self.rb_dataset_periodDate.isChecked():
                sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between DATE_FORMAT(DATE_ADD('{0}', INTERVAL {1} MINUTE), '%Y-%m-%d %H:%i') and DATE_FORMAT(DATE_ADD('{2}', INTERVAL {3} MINUTE), '%Y-%m-%d %H:%i')"
                select_all_query_after = "select OBS_ID, DT_DATE, {0} from waterlevel where OBS_ID = '{1}' and {2} ORDER BY DT_DATE"
                sql_date = sql_date.format(start, leadTexts[leads], end, leadTexts[leads])
                select_all_query_after = select_all_query_after.format(target_col, targetText, sql_date)
                cur.execute(select_all_query_after)
            else:
                print("no data")

            resultset = cur.fetchall()
            resultset_after.append(resultset)

        conn.close()

        # 결과확인 - 1. 조회결과가 없으면 리턴
        if len(resultset_now) == 0:
            QMessageBox.warning(None, 'Error Message', "조회된 데이터가 없습니다.", QMessageBox.Ok)
            return

        # 결과확인 - 2. 관측소별 조회데이터 갯수가 다를 경우 관측소별 데이터정보 출력 후, 리턴
        isDataSame = True
        isFirstValue = 0
        isDataResultOK = True
        isDataResultText = []
        for idxs in range(len(resultset_now)):
            if idxs == 0:
                isFirstValue = len(resultset_now[idxs])
            else:
                isValue = len(resultset_now[idxs])
                if isFirstValue != isValue:
                    self.tbl_makeDataset.clear()
                    self.tbl_makeDataset.setRowCount(0)
                    self.tbl_makeDataset.setColumnCount(0)
                    self.tbl_preProcessing_makeDataset.clear()
                    self.tbl_preProcessing_makeDataset.setRowCount(0)
                    self.tbl_preProcessing_makeDataset.setColumnCount(0)
                    isDataResultOK = False
                    break
        if (isDataResultOK == False):
            txtDataInfo = ""
            for i in range(0, len(resultset_now), 1):
                txtDataType = columnHeader[i+1]
                txtEachData = ""
                if (len(resultset_now[i])>0):
                    txtEachData = "{0} ~ {1}".format(str(resultset_now[i][0][1]), str(resultset_now[i][len(resultset_now[i])-1][1]))
                else:
                    txtEachData = "None"
                txtDataInfo += txtDataType + " : " + txtEachData + "\n"

            QMessageBox.warning(None, 'Error Message', "데이터의 갯수가 관측소별로 다릅니다.\n\n" + txtDataInfo, QMessageBox.Ok)
            return

        # 결과확인 - 3. 타겟관측소의 자료와 lead_time의 갯수가 다를 경우 관측소별 데이터정보 출력 후, 리턴
        isLeadResultOK = True
        isLeadResultText = []
        for idxs in range(len(resultset_after)):
            if isFirstValue != len(resultset_after[idxs]):
                self.tbl_makeDataset.clear()
                self.tbl_makeDataset.setRowCount(0)
                self.tbl_makeDataset.setColumnCount(0)
                self.tbl_preProcessing_makeDataset.clear()
                self.tbl_preProcessing_makeDataset.setRowCount(0)
                self.tbl_preProcessing_makeDataset.setColumnCount(0)
                isLeadResultOK = False
                break
        if (isLeadResultOK == False):
            txtDataInfo = ""
            
            # Target관측소의 자료정보
            txtDataType = columnHeader[1]
            txtEachData = "{0} ~ {1}".format(str(resultset_now[0][0][1]), str(resultset_now[0][len(resultset_now[0]) - 1][1]))
            txtDataInfo += txtDataType + " : " + txtEachData + "\n"
            # 리드타임 자료정보
            nLeadColumnIdx = len(columnHeader) - len(leadTexts)
            nTargetCount = len(resultset_now[0])
            txtErrLeadData = ""
            for i in range(0, len(resultset_after), 1):
                txtLeadType = columnHeader[nLeadColumnIdx+i]
                nLeadCount = len(resultset_after[i])
                if nTargetCount !=  nLeadCount:
                    txtErrLeadData += txtLeadType + " "

            txtDataInfo += txtErrLeadData + "를 가져올 수 없습니다.\n"
            QMessageBox.warning(None, 'Error Message', "Target 관측소의 자료 갯수와 Leadtime 갯수가 다릅니다.\n\n" + txtDataInfo, QMessageBox.Ok)
            return

        # 데이터셋 생성 결과 표시
        nb_row = len(resultset_now[0])
        nb_col = len(columnHeader)
        self.tbl_makeDataset.setRowCount(nb_row)
        self.tbl_makeDataset.setColumnCount(nb_col)
        self.tbl_makeDataset.setHorizontalHeaderLabels(columnHeader)

        # [전처리옵션] ##########################################################################################

        columnPreHeader = columnHeader.copy()

        # 강우컬럼찾기
        find_rain = 'RF_'
        # 강우관측소번호리스트
        rainList = [i - 1 for i in range(len(columnPreHeader)) if find_rain in columnPreHeader[i]]

        # 누적강우생성시 정보 설정
        bAccRainDelete = self.sp_ds_preProcessing_noRainVal.isChecked()
        lstAccRainTerm = [] # 누적강우시간
        lstAccRange = []    # 누적강우범위(시간*한시간6개data)
        if (bAccRainDelete):
            tmpAccRainTerm = self.txtBox_ds_preProcessing_accRainHour.text().split(',')
            for tmpNumber in tmpAccRainTerm:
                try:
                    lstAccRange.append(int(tmpNumber.strip())*6)
                    lstAccRainTerm.append(str(tmpNumber).strip())
                except ValueError:
                    pass
        arrAccRain = []
        if len(rainList) > 0:
            for i in range(len(rainList)):
                newList = [j[2] for j in resultset_now[rainList[i]]]
                arrAccRain.append(newList)

        # 무강우사상삭제시 정보 설정
        arrNoRainIdx = []
        rainSum = 0.0
        bNoRainDelete = self.ckb_ds_preProcessing_noRain.isChecked()
        nDayRange = 6 * 8  # 한시간6개 데이터 * 전후8시간 (8시간 무강우사상 데이터범위)
        nRainIndex = 0

        # 무강우사상삭제시, 전처리시트도 컬럼에 변화없음
        if (bNoRainDelete == True):
            self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
            self.tbl_preProcessing_makeDataset.setColumnCount(nb_col)
            self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnHeader)

        # 누적강우표시시, 누적강우컬럼이 (강우관측소지점*누적강우갯수) 만큼 추가됨
        if (bAccRainDelete == True):
            nb_col_acc = nb_col + (len(rainList)*len(lstAccRainTerm))
            startraincol = len(columnPreHeader) - len(leadTexts)  # 리드타임컬럼시작인덱스
            # nb_col = nb_col + len(rainList)
            for i in range(len(rainList) - 1, -1, -1):
                idxRF = rainList[i] + 1
                for j in range(len(lstAccRainTerm) - 1, -1, -1):
                    strRfName = "ACC_" + str(lstAccRainTerm[j]) + "h_" + columnPreHeader[idxRF]
                    columnPreHeader.insert(startraincol, strRfName)

            # 전후8시간 무강우사상 삭제할 경우는 데이터만 삭제
            self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
            self.tbl_preProcessing_makeDataset.setColumnCount(nb_col_acc)
            self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnPreHeader)

        # 기간필터링하기, 컬럼에 변화없음
        bShowMonth = self.ckb_ds_preProcessing_month.isChecked()  
        if (bNoRainDelete == False) and (bAccRainDelete == False) and bShowMonth:
            self.tbl_preProcessing_makeDataset.setRowCount(nb_row)
            self.tbl_preProcessing_makeDataset.setColumnCount(nb_col)
            self.tbl_preProcessing_makeDataset.setHorizontalHeaderLabels(columnHeader)

        # 테이블에 데이터 표출
        row_preset = 0
        for row in range(nb_row):
            # now data
            for obs in range(len(resultset_now)):

                # 전후8시간 무강우사상 삭제할 경우,
                if ((bNoRainDelete==True) and (obs in rainList)):
                    rainSum = 0.0
                    # 무강우사상 체크하기(계산)
                    if (row < nDayRange):
                        lstSum = arrAccRain[rainList.index(obs)][row - row:row + nDayRange + 1]
                        rainSum = sum(filter(None, lstSum))
                    elif (row + nDayRange > len(resultset_now[0]) - 1):                        
                        lstSum = arrAccRain[rainList.index(obs)][row - nDayRange:len(resultset_now[0])]
                        rainSum = sum(filter(None, lstSum))
                    else:
                        lstSum = arrAccRain[rainList.index(obs)][row - nDayRange:row + nDayRange + 1]
                        rainSum = sum(filter(None, lstSum))
                    # 무강우사상이 아닐경우, arrNoRainIdx 배열에 index를 추가함.(테이블위젯표출 때 해당idx제외하고 삭제하기)
                    if (rainSum > 0.0) and ((row in arrNoRainIdx) == False):
                        arrNoRainIdx.append(row)

                # 누적강우를 선택했을경우, 이전부터 현재까지 누적시키기.
                lstRainAcc = []
                if ((bAccRainDelete==True) and (obs in rainList)):
                    arrAccIdx = rainList.index(obs)
                    # 누적강우 체크하기(계산) - 누적강우시간리스트만큼(6,9,12 등)
                    for nAccRange in lstAccRange:
                        if (row < nAccRange):
                            lstSum = arrAccRain[rainList.index(obs)][row - row: row+1]
                            rainAcc = sum(filter(None, lstSum))
                        else:
                            lstSum = arrAccRain[rainList.index(obs)][row - nAccRange: row + 1]
                            rainAcc = sum(filter(None, lstSum))
                        lstRainAcc.append(rainAcc)

                # 원래데이터 출력
                if obs == 0:  # 날짜,데이터
                    item = QTableWidgetItem(str(resultset_now[obs][row][1]))
                    self.tbl_makeDataset.setItem(row, obs, item)
                    item = QTableWidgetItem(str(resultset_now[obs][row][1]))
                    self.tbl_preProcessing_makeDataset.setItem(row_preset, obs, item)

                    itemText = str(resultset_now[obs][row][2])
                    if (itemText == 'None'):
                        itemText = ''

                    item = QTableWidgetItem(itemText)
                    self.tbl_makeDataset.setItem(row, obs + 1, item)
                    item = QTableWidgetItem(itemText)
                    self.tbl_preProcessing_makeDataset.setItem(row_preset, obs + 1, item)

                    # (전처리옵션)누적강우가 선택되었다면,
                    if (bAccRainDelete==True) and (obs in rainList):
                        startAccCol = len(columnPreHeader) - len(leadTexts) - (len(arrAccRain)*len(lstAccRainTerm))
                        for idxAcc in range(len(lstRainAcc)):
                            itemData = str(lstRainAcc[idxAcc])
                            if (itemData == 'None'):
                                itemData = ''
                            item = QTableWidgetItem(itemData)
                            self.tbl_preProcessing_makeDataset.setItem(row_preset, startAccCol + ((rainList.index(obs)*len(lstAccRainTerm))+idxAcc), item)

                else:  # 데이터
                    itemText = str(resultset_now[obs][row][2])
                    if (itemText == 'None'):
                        itemText = ''

                    item = QTableWidgetItem(itemText)
                    self.tbl_makeDataset.setItem(row, obs + 1, item)
                    item = QTableWidgetItem(itemText)
                    self.tbl_preProcessing_makeDataset.setItem(row_preset, obs + 1, item)

                    # (전처리옵션)누적강우가 선택되었다면,
                    if (bAccRainDelete==True) and (obs in rainList):
                        startAccCol = len(columnPreHeader) - len(leadTexts) - (len(arrAccRain) * len(lstAccRainTerm))
                        for idxAcc in range(len(lstRainAcc)):
                            itemData = str(lstRainAcc[idxAcc])
                            if (itemData == 'None'):
                                itemData = ''
                            item = QTableWidgetItem(itemData)
                            self.tbl_preProcessing_makeDataset.setItem(row_preset,startAccCol + ((rainList.index(obs)*len(lstAccRainTerm)) + idxAcc),item)

            # leadtime data
            startleadcol = len(columnHeader) - len(leadTexts)
            startPreleadCol = len(columnPreHeader) - len(leadTexts)
            for leads in range(len(leadTexts)):
                itemText = str(resultset_after[leads][row][2])
                if (itemText == 'None'):
                    itemText = ''

                item = QTableWidgetItem(itemText)
                self.tbl_makeDataset.setItem(row, startleadcol + leads, item)
                item = QTableWidgetItem(itemText)
                self.tbl_preProcessing_makeDataset.setItem(row_preset, startPreleadCol + leads, item)

            # 무강우나 월별데이터일경우 전처리시트에서 삭제하기
            # (전처리옵션)8시간무강우사상이 선택되었다면, 무강우일경우는 삭제, 아니면 출력
            if ((bNoRainDelete == True) and (rainSum <= 0)) :
                self.tbl_preProcessing_makeDataset.removeRow(row_preset)
            # (전처리옵션)월별데이터 조회일경우, 해당 월이 아니면 삭제, index 다시 원래대로!
            elif ((bShowMonth == True) and (self.tbl_preProcessing_makeDataset.rowCount() > 0)):
                Datetext = str(self.tbl_preProcessing_makeDataset.item(row_preset, 0).text())
                datetime_format = "%Y-%m-%d %H:%M:%S"
                datetimeText = datetime.strptime(Datetext, datetime_format)
                dayText = Datetext[5:7] + Datetext[8:10]
                stdMonth = "01"
                endMonth = "12"
                stdDay = "01"
                endDay = "31"
                if (self.rb_ds_preProcessing_month.isChecked()):
                    stdMonth = self.sp_ds_preProcessing_startMonth.currentText()
                    endMonth = self.sp_ds_preProcessing_endMonth.currentText()
                if (self.rb_ds_preProcessing_date.isChecked()):
                    stdDate = self.sp_ds_preProcessing_startDate.text()
                    endDate = self.sp_ds_preProcessing_endDate.text()
                    stdDay = stdDate[0:2] + stdDate[3:5]
                    endDay = endDate[0:2] + endDate[3:5]

                if (self.rb_ds_preProcessing_month.isChecked()):
                    if (int(stdMonth) > datetimeText.month) or (int(endMonth) < datetimeText.month):
                        self.tbl_preProcessing_makeDataset.removeRow(row_preset)
                    else:
                        row_preset = row_preset + 1
                if(self.rb_ds_preProcessing_date.isChecked()):
                    if (int(stdDay) > int(dayText)) or (int(endDay) < int(dayText)):
                        self.tbl_preProcessing_makeDataset.removeRow(row_preset)
                    else:
                        row_preset = row_preset + 1
            # 전처리옵션으로 삭제된 경우가 아니라면, 행 증가시키기!
            else:
                row_preset = row_preset + 1

        self.tbl_makeDataset.resizeColumnsToContents()
        self.tbl_preProcessing_makeDataset.resizeColumnsToContents()

        # 데이터셋 그래프생성을 위한 정보 설정
        global arrDsHeader
        global arrDsData
        arrDsHeader = columnHeader
        arrDsData = resultset_now

        QMessageBox.information(self, 'Message', "데이터셋 생성을 완료했습니다.", QMessageBox.Ok)

    # tab [데이터셋생성] Save Dataset File Button
    def btn_saveDatasetFunc(self):

        # 데이터셋원본/전처리본 선택해서 저장하기 (tab_ds_result)
        if self.tab_ds_result.currentIndex() == 0:  # 데이터셋원본

            # 저장할 내용이 없을때 리턴
            if self.tbl_makeDataset.rowCount() == 0:
                QMessageBox.warning(None, 'Error Message', "저장할 데이터가 없습니다.", QMessageBox.Ok)
                return

            # Null값을 빼고 저장할지 확인 후 저장
            buttonReply = QMessageBox.warning(None, 'Warning Message',
                                              "NULL값을 제외하고 저장하시겠습니까?\n(Yes-Null값 제외하고 저장, No-모두저장)",
                                              QMessageBox.Yes | QMessageBox.No | QMessageBox.Cancel)
            isNullOK = False
            if buttonReply == QMessageBox.No:
                isNullOK = True
            elif buttonReply == QMessageBox.Yes:
                isNullOK = False
            else:
                return

            file = QFileDialog.getSaveFileName(self, "Save file", "", "*.csv")
            # 저장경로가 없을때 리턴
            if file[0] == '':
                return
            # 저장경로 정보 설정
            saveFilePath = file[0]

            saveFile = open(saveFilePath, 'w', newline='')
            wr = csv.writer(saveFile)

            # 데이터셋 컬럼정보 저장
            columnHeaders = []
            for j in range(self.tbl_makeDataset.columnCount()):
                columnHeaders.append(self.tbl_makeDataset.horizontalHeaderItem(j).text())
            wr.writerow(columnHeaders)

            if (isNullOK == True):
                # 데이터셋 자료정보 저장
                for row in range(self.tbl_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_makeDataset.columnCount()):
                        text = str(self.tbl_makeDataset.item(row, col).text())
                        rowdata.append(text)
                    wr.writerow(rowdata)
            else:
                # 데이터셋 자료정보 저장 (Null값 제외하고 저장)
                for row in range(self.tbl_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_makeDataset.columnCount()):
                        text = str(self.tbl_makeDataset.item(row, col).text())
                        rowdata.append(text)

                    if '' not in rowdata:
                        wr.writerow(rowdata)

            # 파일 저장
            saveFile.close()

            msgQuit = QMessageBox.information(self, 'Message', "데이터셋 파일저장을 완료했습니다. 파일을 확인하시겠습니까?",
                                              QMessageBox.Yes | QMessageBox.No)
            if msgQuit == QMessageBox.Yes:
                # 저장된 파일경로 열기(결과확인)
                saveFolderPath = os.path.dirname(saveFilePath)
                os.startfile(saveFolderPath)

        else:  # 데이터셋전처리본

            # 저장할 내용이 없을때 리턴
            if self.tbl_preProcessing_makeDataset.rowCount() == 0:
                QMessageBox.warning(None, 'Error Message', "저장할 데이터가 없습니다.", QMessageBox.Ok)
                return

            # Null값을 빼고 저장할지 확인 후 저장
            buttonReply = QMessageBox.warning(None, 'Warning Message',
                                              "NULL값을 제외하고 저장하시겠습니까?\n(Yes-Null값 제외하고 저장, No-모두저장)",
                                              QMessageBox.Yes | QMessageBox.No | QMessageBox.Cancel)
            isNullOK = False
            if buttonReply == QMessageBox.No:
                isNullOK = True
            elif buttonReply == QMessageBox.Yes:
                isNullOK = False
            else:
                return


            file = QFileDialog.getSaveFileName(self, "Save file", "", "*.csv")
            # 저장경로가 없을때 리턴
            if file[0] == '':
                return
            # 저장경로 정보 설정
            saveFilePath = file[0]

            saveFile = open(saveFilePath, 'w', newline='')
            wr = csv.writer(saveFile)

            # 데이터셋 컬럼정보 저장
            columnHeaders = []
            for j in range(self.tbl_preProcessing_makeDataset.columnCount()):
                columnHeaders.append(self.tbl_preProcessing_makeDataset.horizontalHeaderItem(j).text())
            wr.writerow(columnHeaders)

            # 데이터셋 자료정보 저장
            if (isNullOK == True):
                # 데이터셋 자료정보 저장
                for row in range(self.tbl_preProcessing_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_preProcessing_makeDataset.columnCount()):
                        text = str(self.tbl_preProcessing_makeDataset.item(row, col).text())
                        rowdata.append(text)
                    wr.writerow(rowdata)
            else:
                # 데이터셋 자료정보 저장 (Null값 제외하고 저장)
                for row in range(self.tbl_preProcessing_makeDataset.rowCount()):
                    rowdata = []
                    for col in range(self.tbl_preProcessing_makeDataset.columnCount()):
                        text = str(self.tbl_preProcessing_makeDataset.item(row, col).text())
                        rowdata.append(text)

                    if '' not in rowdata:
                        wr.writerow(rowdata)

            # 파일 저장
            saveFile.close()

            msgQuit = QMessageBox.information(self, 'Message', "데이터셋 파일저장을 완료했습니다. 파일을 확인하시겠습니까?",
                                              QMessageBox.Yes | QMessageBox.No)
            if msgQuit == QMessageBox.Yes:
                # 저장된 파일경로 열기(결과확인)
                saveFolderPath = os.path.dirname(saveFilePath)
                os.startfile(saveFolderPath)


    # tab [데이터셋생성] 그래프보기 버튼
    def ShowDatasetGraph(self):
        global arrDsHeader  # 데이터셋 관측소정보
        global arrDsData    # 데이터셋 자료정보

        # 조회할 내용이 없을때 리턴
        if self.tbl_makeDataset.rowCount() == 0:
            QMessageBox.warning(self, 'Error Message', "조회할 데이터가 없습니다.", QMessageBox.Ok)
            return

        newdlg = PyWPdsGraph(self.dialogDataset)
        newdlg.InitData(newdlg, arrDsHeader, arrDsData)
        self.dialogDataset.exec_()

    # tab [하천수위예측 모형제작] call:파라메터 초기화
    def init_makemodelParam(self):
        self.sp_dl_dropOutRate.setValue(0)
        self.sp_dl_sequenceLength.setValue(0)
        self.sp_dl_hiddenDim.setValue(0)
        self.sp_dl_sizeOfBatch.setValue(0)
        self.sp_dl_learningRate.setValue(0)
        self.sp_dl_interation.setValue(0)
        self.sp_dl_valudatuinSplit.setValue(0)
        self.sp_dl_trainingRate.setValue(0.8)
        self.sp_dl_hiddenLayer.setValue(0)
        self.txtBox_dl_units.clear()
        self.cb_dl_activationFunc.setCurrentText("relu")
        self.cb_dl_optimizeFunc.setCurrentText("adam")
        self.cb_dl_lossFunc.setCurrentText("mean_squared_error")

    # tab [하천수위예측 모형제작] 파라메터(modelParam.txt) 불러오기 Button
    def LoadMakeModelParam(self):

        fileData, _ = QFileDialog.getOpenFileName(None, 'Open ModelParam file', '', 'txt file(modelParam.txt)')
        # 선택된 파일이 없을때 리턴
        if fileData == '': return

        # control 초기화
        self.init_makemodelParam()

        data = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                data.append(rowdata)

        paramHeader = ['data_path', 'save_path', 'random_number', 'model_name', 'drop_out_rate',
                       'seq_length', 'hidden_dim', 'size_of_batch', 'learning_rate', 'iterations',
                       'patience_num', 'training_rate', 'train_size', 'test_size',
                       'Data_X_Column', 'X_data_training_column_list', 'Data_Y_Column',
                       'Y_data_training_column_list',
                       'data_dim', 'output_dim', 'lead_time', 'Predict_time_index', 'Predict_time_leadtime',
                       'validation_rate', 'hidden_layer_unit', 'hidden_layer', 'activation_func',
                       'optimize_func', 'loss_func', 'Elapsed_time(sec)']

        nb_row = len(data)
        for row in range(nb_row):
            col_text = str(data[row][0])
            if col_text == paramHeader[4]: self.sp_dl_dropOutRate.setValue(float(data[row][1]))
            if col_text == paramHeader[5]: self.sp_dl_sequenceLength.setValue(int(data[row][1]))
            if col_text == paramHeader[6]: self.sp_dl_hiddenDim.setValue(int(data[row][1]))
            if col_text == paramHeader[7]: self.sp_dl_sizeOfBatch.setValue(int(data[row][1]))
            if col_text == paramHeader[8]: self.sp_dl_learningRate.setValue(float(data[row][1]))
            if col_text == paramHeader[9]: self.sp_dl_interation.setValue(int(data[row][1]))
            if col_text == paramHeader[10]: self.sb_dl_patienceNum.setValue(int(data[row][1]))
            if col_text == paramHeader[23]: self.sp_dl_valudatuinSplit.setValue(float(data[row][1]))
            if col_text == paramHeader[11]: self.sp_dl_trainingRate.setValue(float(data[row][1]))
            if col_text == paramHeader[25]: self.sp_dl_hiddenLayer.setValue(int(data[row][1]))
            if col_text == paramHeader[24]:
                strUnit = ""
                for inIdx in range(len(data[row]) - 1):
                    row_text = data[row][inIdx + 1].strip().replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    strUnit += row_text.strip() + ","
                setText = strUnit.rstrip(',')
                self.txtBox_dl_units.setPlainText(setText)
            if col_text == paramHeader[26]: self.cb_dl_activationFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[27]: self.cb_dl_optimizeFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[28]: self.cb_dl_lossFunc.setCurrentText(str(data[row][1]))

    # tab [하천수위예측 모형제작] Save Path 설정 Button
    def SetMakeModelSavePath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_dl_saveParamPath.setText(path)

    # tab [하천수위예측 모형제작] call:모형제작에 필요한 입력자료 확인
    def checkInputParameter(self):

        # 1.데이터셋 파일이 설정되었는지,
        datafilepath = self.txtBox_dl_datasetFile.text()
        if datafilepath == "":
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일을 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 1-1. 데이터셋에 Null값이 포함되었는지,
        global isMakeModelDataNull
        if isMakeModelDataNull == True:
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일에 NULL값이 포함되어 있습니다.", QMessageBox.Ok)
            return "None"

        # 2.모형제작 저장경로(폴더) 설정되었는지,
        modelpath = self.txtBox_dl_saveParamPath.text()
        if modelpath == "":
            QMessageBox.warning(None, 'Error Message', "모형을 저장할 폴더 경로를 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 3.모형제작 모델명 설정되었는지,
        modelname = self.txtBox_dl_modelName.text()
        if modelname == "":
            QMessageBox.warning(None, 'Error Message', "모델명을 입력해 주세요.", QMessageBox.Ok)
            return "None"

        # 4.Hidden Layer 입력항목이 제대로 작성되었는지,
        tmpHiddenUnits = self.txtBox_dl_units.toPlainText().split(',')
        for tmpNumber in tmpHiddenUnits:
            try:
                intValues = int(tmpNumber.strip())
            except ValueError:
                QMessageBox.warning(self, 'Error Message', "Hidden Layer 입력정보를 다시 확인해주세요.\n(예시 - 32,64,32 등으로 표기)",
                                    QMessageBox.Ok)
                return "None"

        # 5.Hidden Layer갯수에 따라 HiddenLayerUnit이 동일갯수로 입력되었는지,
        hiddenlayerunit = self.txtBox_dl_units.toPlainText().split(',')
        if (len(hiddenlayerunit) > 0 and hiddenlayerunit[0] != '' and int(hiddenlayerunit[0]) > 0):
            hidden_layer_unit = [int(i) for i in hiddenlayerunit]
            hiddenlayercount = self.sp_dl_hiddenLayer.value()
            if hiddenlayercount != len(hidden_layer_unit):
                QMessageBox.warning(None, 'Error Message', "Hidden Layer 갯수에 맞게 입력해 주세요.", QMessageBox.Ok)
                return "None"
        else:
            QMessageBox.warning(None, 'Error Message', "Hidden Layer 갯수에 맞게 입력해 주세요.", QMessageBox.Ok)
            return "None"

        # 6.사용할 컬럼이 선택되었는지 체크하기!
        useCol_checked = False
        model_col = self.tbl_modelDatasetColumn.model()
        for mIdx in range(model_col.rowCount() - 1):
            item = model_col.item(mIdx + 1)
            if item.checkState():
                useCol_checked = True
                break
        if useCol_checked == False:
            QMessageBox.warning(None, 'Error Message', "모형제작에 사용할 데이터 컬럼을 선택해주세요.", QMessageBox.Ok)
            return "None"

        # 7.사용할 leadtime이 설정되었는지,
        leadtime_checked = False
        model_lead = self.tbl_modelDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                leadtime_checked = True
        if leadtime_checked == False:
            QMessageBox.warning(None, 'Error Message', "모형제작에 사용할 리드타임 컬럼을 선택해주세요.", QMessageBox.Ok)
            return "None"

    # tab [하천수위예측 모형제작] 모형제작(Make Model) button
    def MakeModel(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 모형제작에 필요한 입력자료 체크
        if self.checkInputParameter() == "None": return

        # 모형제작 경로 설정
        datafilepath = self.txtBox_dl_datasetFile.text()
        modelpath = self.txtBox_dl_saveParamPath.text()
        modelname = self.txtBox_dl_modelName.text()

        save_path = modelpath + "/"
        model_name = modelname
        saveModelName = save_path + model_name
        saveReportPath = saveModelName + "/"

        if not os.path.exists(saveReportPath):
            os.makedirs(saveReportPath)
        else:
            buttonReply = QMessageBox.warning(self, 'Error Message', "이미 존재하는 폴더입니다. 덮어쓰시겠습니까?",
                                              QMessageBox.Yes | QMessageBox.No)
            if buttonReply == QMessageBox.No:
                return
            elif buttonReply == QMessageBox.Yes:
                shutil.rmtree(saveReportPath)
                os.makedirs(saveReportPath)
            else:
                return

        # 선택된 데이터셋 파일 읽어오기
        data = pd.read_csv(datafilepath, date_parser=True)

        # 선택된 데이터셋 파일에서 설정자료 확인
        Data_X_Column = []  # data_col - data_column_index
        Data_Y_Column = []  # leadtime - data_column_index

        # 리드타임정보 확인
        lead_time = "timeseries"
        Predict_time_index = []  # leadtime - text
        Predict_time_leadtime = []  # leadtime - time

        model_col = self.tbl_modelDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            if item.checkState():
                Data_X_Column.append(mIdx + 1)

        model_lead = self.tbl_modelDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                Data_Y_Column.append((model_col.rowCount() + mIdx + 1))
                leadtimeNm = item.text().strip().strip("Lead_")
                if ((leadtimeNm.find("H") > 0) or (leadtimeNm.find("M") > 0)):
                    leadtimeText = leadtimeNm.strip().strip("H""M")
                    Predict_time_index.append(leadtimeNm)
                    if (leadtimeText == "0.5"):
                         Predict_time_leadtime.append(30)
                    else:
                         Predict_time_leadtime.append(int(leadtimeText) * 60)
                else:
                    leadtimeText = leadtimeNm.strip().strip("H""M")
                    Predict_time_index.append(leadtimeNm)
                    Predict_time_leadtime.append(int(leadtimeText))

        data_dim = len(Data_X_Column)

        # Training parameter
        save_path = modelpath + "/"
        model_name = modelname
        patience_num = self.sb_dl_patienceNum.value()
        # save the start time
        start = time.time()
        # make a random number
        random_number = randrange(1, 1000)

        # dim : keras레이어에서 텐서의 차원수를 나타냄
        seq_length = self.sp_dl_sequenceLength.value()  # sequence length range : (10분~12시간 : 1~72)
        hidden_dim = self.sp_dl_hiddenDim.value()  # range : 1~256
        # data_dim : 학습 입력변수의 갯수 <- 선택된관측소에따라 자동입력(Target+Ref)
        # size_of_batch : 한번에 학습시킬 자료의 단위
        size_of_batch = self.sp_dl_sizeOfBatch.value()
        # output_dim : 예측 출력변수의 갯수 <- 관측소선택에따라 자동입력(타켓관측소)
        learning_rate = self.sp_dl_learningRate.value()  # 0.0004
        # iterations - epochs :재학습(학습데이터를 한번씩 모두 학습시킨 횟수, 10이라면 학습데이터를 총 10번 학습시켰음을 의미)
        iterations = self.sp_dl_interation.value()
        # Validation(검증)
        validation_rate = self.sp_dl_valudatuinSplit.value()  # 0.2  # 학습자료 중 validation에 활용하는 자료 비율
        # Dropout : 과적합방지용(Dropout(rate=0.2)라면 인풋데이터의 20%의 노드들을 무작위로 0으로 만드는 드롭아웃을 적용)
        drop_out_rate = self.sp_dl_dropOutRate.value()

        # activation_func : 활성화함수
        # linear-기본값으로 가중치결과값이 출력그대로 나옴
        # relu-ReLU함수, 은닉층에서 주로사용
        # sigmoid-주로 출력층에서 사용
        # softmax-출력값들의 합이 1.0이 되도록 하는함수로 보통 출력층에서 사용
        activation_func = self.cb_dl_activationFunc.currentText()  # 학습 모델의 activation function
        optimize_func = self.cb_dl_optimizeFunc.currentText()  # 학습 모델의 optimize function
        loss_func = self.cb_dl_lossFunc.currentText()  # 학습 모델의 loss function

        # traing hidden layer
        # hidden layer 갯수 = hidden layer unit 갯수
        hidden_layer = self.sp_dl_hiddenLayer.value()
        hidden_layer_unit = self.getHiddenLayerUnits(self.txtBox_dl_units.toPlainText())

        # rate of training data size
        inputTrainsize = self.sp_dl_trainingRate.value()
        train_size = int(len(data) * inputTrainsize)

        # make data of training and test data
        data_training = data[:train_size]
        data_test = data[train_size - seq_length:]
        test_size = len(data) - train_size

        # check the length of data
        print('Total = ', len(data))
        print('Train = ', len(data_training))
        print('Test = ', len(data_test))

        print("ok make model start")

        # setting the random number with reproductive
        tf.random.set_seed(random_number)

        data['DATE'] = pd.to_datetime(data['DATE'])

        # make_model (lead_time)
        for leadIdx in range(len(Data_Y_Column)):

            leadtimeIndex = Data_Y_Column[leadIdx]

            lstLeadtimeIndex = []
            lstLeadtimeIndex.append(leadtimeIndex)
            lstLeadtimeValue = []
            lstLeadtimeValue.append(Predict_time_leadtime[leadIdx])
            output_dim = len(lstLeadtimeIndex)

            saveModelName = save_path + model_name + "/" + Predict_time_index[leadIdx]
            saveReportPath = saveModelName + "/"

            # Unless save_path folder exist, make the save_path folder
            if not os.path.exists(saveReportPath):
                os.makedirs(saveReportPath)

            X_data_training_drop = data_training.iloc[:, Data_X_Column]
            Y_data_training_drop = data_training.iloc[:, lstLeadtimeIndex]

            X_data_test_drop = data_test.iloc[:, Data_X_Column]
            Y_data_test_drop = data_test.iloc[:, lstLeadtimeIndex]

            # time slicing

            Current_time_test = data_test.iloc[seq_length:, [0]]
            Current_time_test = Current_time_test.reset_index(drop=True)


            # Make a prediction time for each leadtime
            Predict_time = pd.DataFrame()
            Predict_time[Predict_time_index[leadIdx]] = pd.DatetimeIndex(Current_time_test['DATE']) + timedelta(
                minutes=Predict_time_leadtime[leadIdx])

            # extraction the header of X_data
            X_data_training_column = pd.DataFrame({"header": X_data_training_drop.columns})
            X_data_training_column_list = list(X_data_training_column["header"])

            # extraction the header of XYdata
            Y_data_training_column = pd.DataFrame({"header": Y_data_training_drop.columns})
            Y_data_training_column_list = list(Y_data_training_column["header"])

            # data normalize of training data
            X_scaler = MinMaxScaler()
            Y_scaler = MinMaxScaler()

            X_data_training_scale = X_scaler.fit_transform(X_data_training_drop)
            Y_data_training_scale = Y_scaler.fit_transform(Y_data_training_drop)


            # make the input data of training model

            X_train = []
            Y_train = []

            for i in range(seq_length, X_data_training_scale.shape[0]):
                X_train.append(X_data_training_scale[i - seq_length:i, :])
                Y_train.append(Y_data_training_scale[i, :])

            X_train, Y_train = np.array(X_train), np.array(Y_train)

            # Training process

            from tensorflow.keras import Sequential
            from tensorflow.keras.layers import Dense, LSTM, Dropout
            from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

            regressior = Sequential()

            # activate the Early stop and checkpoint (.h5 -> .tf 로 변경 : qgis 오류)
            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience_num)
            mc = ModelCheckpoint(saveReportPath + 'best_model.tf', monitor='val_loss', mode='min', save_best_only=True)

            regressior.add(LSTM(units=hidden_dim, activation=activation_func, return_sequences=True,
                                input_shape=(X_train.shape[1], data_dim)))
            regressior.add(Dropout(drop_out_rate))  # prevent overfitting

            # add hidden layers
            for i in range(0, hidden_layer):
                regressior.add(LSTM(units=hidden_layer_unit[i], activation=activation_func, return_sequences=True))
                regressior.add(Dropout(drop_out_rate))  # prevent overfitting

            regressior.add(LSTM(units=hidden_dim, activation=activation_func))
            regressior.add(Dropout(drop_out_rate))  # prevent overfitting

            regressior.add(Dense(units=output_dim))

            regressior.summary()

            regressior.compile(optimizer=optimize_func, loss=loss_func, metrics=['acc'])

            history = regressior.fit(X_train, Y_train, epochs=iterations, batch_size=size_of_batch,
                                     validation_split=validation_rate, callbacks=[es, mc])

            history.history.keys()

            his_dict = history.history

            loss = his_dict['loss']
            val_loss = his_dict['val_loss']

            # display the elapsed time of training
            Elapsed_time = int(time.time() - start)
            print("Elapsed time :" + str(Elapsed_time) + "sec")

            regressior.save(saveModelName)

            # make the loss result file
            result = pd.DataFrame({"loss": loss[:], "val_loss": val_loss[:]})
            result.to_csv(
                saveReportPath + 'predict_result_' + Predict_time_index[leadIdx] + '_drop-out_' + str(
                    drop_out_rate) + "_seq_length_" + str(
                    seq_length) + '_loss_data.csv', index=False)

            epochs = range(1, len(loss) + 1)
            fig = plt.figure(figsize=(10, 5))

            ax1 = fig.add_subplot(1, 2, 1)
            ax1.plot(epochs, loss, color='blue', label='train_loss')
            ax1.plot(epochs, val_loss, color='orange', label='val_loss')
            ax1.set_title('train and val loss')
            ax1.set_xlabel('epochs')
            ax1.set_ylabel('loss')
            ax1.legend()

            acc = his_dict['acc']
            val_acc = his_dict['val_acc']

            ax2 = fig.add_subplot(1, 2, 2)
            ax2.plot(epochs, acc, color='blue', label='train_acc')
            ax2.plot(epochs, val_acc, color='orange', label='val_acc')
            ax2.set_title('train and val acc')
            ax2.set_xlabel('epochs')
            ax2.set_ylabel('acc')
            ax2.legend()

            plt.savefig(
                saveReportPath + 'training_loss_acc_' + Predict_time_index[leadIdx] + '_drop-out_' + str(
                    drop_out_rate) + "_seq_length_" + str(
                    seq_length) + '.png')
            plt.close()

            # save the scaler
            dump(X_scaler, open(saveReportPath + 'X_scaler.pkl', 'wb'))
            dump(Y_scaler, open(saveReportPath + 'Y_scaler.pkl', 'wb'))
            dump(X_scaler, open(saveReportPath + 'best_model.tf\X_scaler.pkl', 'wb'))
            dump(Y_scaler, open(saveReportPath + 'best_model.tf\Y_scaler.pkl', 'wb'))

            # save the model parameter
            modelParam_file = open(saveReportPath + "modelParam.txt", "w", encoding="utf8")
            print("data_path," + datafilepath, file=modelParam_file)
            print("save_path," + saveModelName, file=modelParam_file)  # saveModelName
            print("random_number," + str(random_number), file=modelParam_file)
            print("model_name," + model_name, file=modelParam_file)
            print("drop_out_rate," + str(drop_out_rate), file=modelParam_file)
            print("seq_length," + str(seq_length), file=modelParam_file)
            print("hidden_dim," + str(hidden_dim), file=modelParam_file)
            print("size_of_batch," + str(size_of_batch), file=modelParam_file)
            print("learning_rate," + str(learning_rate), file=modelParam_file)
            print("iterations," + str(iterations), file=modelParam_file)
            print("patience_num," + str(patience_num), file=modelParam_file)
            print("training_rate," + str(inputTrainsize), file=modelParam_file)
            print("train_size," + str(train_size), file=modelParam_file)
            print("test_size," + str(test_size), file=modelParam_file)
            print("Data_X_Column," + str(Data_X_Column), file=modelParam_file)
            print("X_data_training_column_list," + str(X_data_training_column_list), file=modelParam_file)
            print("Data_Y_Column," + str(leadtimeIndex), file=modelParam_file)
            print("Y_data_training_column_list," + str(Y_data_training_column_list), file=modelParam_file)
            print("data_dim," + str(data_dim), file=modelParam_file)
            print("output_dim," + str(output_dim), file=modelParam_file)
            print("lead_time," + lead_time, file=modelParam_file)
            print("Predict_time_index," + str(lstLeadtimeIndex), file=modelParam_file)
            print("Predict_time_leadtime," + str(lstLeadtimeValue), file=modelParam_file)
            print("validation_rate," + str(validation_rate), file=modelParam_file)
            print("hidden_layer_unit," + str(hidden_layer_unit), file=modelParam_file)
            print("hidden_layer," + str(hidden_layer), file=modelParam_file)
            print("activation_func," + activation_func, file=modelParam_file)
            print("optimize_func," + optimize_func, file=modelParam_file)
            print("loss_func," + loss_func, file=modelParam_file)
            print("Elapsed_time(sec)," + str(Elapsed_time), file=modelParam_file)

            modelParam_file.close()
            shutil.copyfile(saveReportPath + "modelParam.txt", saveReportPath + "best_model.tf\modelParam.txt")

            # test process
            X_df = X_data_test_drop
            Y_df = Y_data_test_drop

            # data normalize of test data
            X_inputs = X_scaler.transform(X_df)
            Y_inputs = Y_scaler.transform(Y_df)

            X_test = []
            Y_test = []

            # make dataset of test
            for i in range(seq_length, X_inputs.shape[0]):
                X_test.append(X_inputs[i - seq_length:i, :])
                Y_test.append(Y_inputs[i, :])

            X_test, Y_test = np.array(X_test), np.array(Y_test)

            # calculate predict Y
            Y_pred = regressior.predict(X_test)

            # conversion to original scale
            Y_pred = Y_pred * Y_scaler.data_range_[-1] + Y_scaler.data_min_[-1]
            Y_test = Y_test * Y_scaler.data_range_[-1] + Y_scaler.data_min_[-1]

            # Evaluating process
            import math

            # Define average function
            def average(values):
                if len(values) == 0:
                    return None
                return sum(values, 0.0) / len(values)

            obs_avg = average(Y_test)  # calculate average

            # Define NSE(nash-sutcliffe efficiency)function
            def nse(obs_values, sim_values):
                e1 = list()
                e2 = list()
                for i in range(0, len(obs_values)):
                    e1.append((obs_values[i] - sim_values[i]) ** 2)
                    e2.append((obs_values[i] - obs_avg) ** 2)
                sum_e1 = sum(e1)
                sum_e2 = sum(e2)

                nse = 1 - sum_e1 / sum_e2
                return nse

            nse = nse(Y_test, Y_pred)  # calculate NSE

            # print evaluation factor
            print("Average of Obs. data=", obs_avg)
            print("NSE=", nse)

            # make the result file
            result_all = pd.DataFrame()
            result_all = pd.concat([Current_time_test], axis=1)

            result_tmp = pd.DataFrame({"Y_true_" + Predict_time_index[leadIdx]: Y_test[:, 0], "Y_pred_" + Predict_time_index[leadIdx]: Y_pred[:, 0]})

            Predict_time_tmp = Predict_time.iloc[:, [0]]
            result_all = pd.concat([result_all, Predict_time_tmp, result_tmp], axis=1)

            result_all.to_csv(saveReportPath + 'predict_result_' + Predict_time_index[leadIdx] + '_timeseries_drop-out_' + str(
                drop_out_rate) + "_seq_length_" + str(seq_length) + '.csv', index=False)

            # Visualising the results
            plt.figure(figsize=(14, 5))
            plt.plot(Y_test[:, 0], color='red', label='Observed Water Level')
            plt.plot(Y_pred[:, 0], color='blue', label='Predicted Water Level')
            plt.title('Water Level Prediction (NSE=' + str(nse[0]) + ')')
            plt.xlabel('Time')
            plt.ylabel('Water Level')
            plt.legend()
            plt.savefig(
                saveReportPath + 'prediction_result_' + Predict_time_index[leadIdx] + '_after_' + Predict_time_index[
                    leadIdx] + '_drop-out_' + str(
                    drop_out_rate) + "_seq_length_" + str(seq_length) + '.png')
            plt.close()

        msgQuit = QMessageBox.information(self, 'Message', "하천수위예측모형 제작을 완료했습니다. 결과를 확인하시겠습니까?",
                                          QMessageBox.Yes | QMessageBox.No)
        if msgQuit == QMessageBox.Yes:
            # 모형제작 결과를 확인한다.
            os.startfile(save_path + model_name)

    # tab [하천수위예측 모형제작/예측수행및성능분석] call:입력파라메터 중 hidden layer unit 자료 가져오기
    def getHiddenLayerUnits(self, inputData):
        data = inputData.split(',')
        datas = []
        if len(data) == 0:
            return 0
        else:
            for idx in range(len(data)):
                datas.append(int(data[idx]))
            return datas

    # tab [하천수위예측 모형제작] 데이터셋 파일 불러오기 Button
    def LoadMakeModelDataset(self):

        # 데이터셋파일에 null값이 존재하는지 확인
        global isMakeModelDataNull
        isMakeModelDataNull = False

        fileData, _ = QFileDialog.getOpenFileName(self, 'Open file', '', 'csv file(*.csv)')
        # 선택된 파일없을때 리턴
        if fileData == '': return
        # 데이터셋파일이 아닐경우 리턴
        fileinfo, fileext = os.path.splitext(fileData)
        if fileext != '.csv': return

        self.txtBox_dl_datasetFile.setText(fileData)
        self.tbl_readCsvFile.clearContents()

        # 선택된 dataset file 내용 표기 ######################################
        datas = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                datas.append(rowdata)
        labels = datas[0]
        nb_row = len(datas)
        nb_col = len(datas[0])
        self.tbl_readCsvFile.setRowCount(nb_row - 1)
        self.tbl_readCsvFile.setColumnCount(nb_col)
        self.tbl_readCsvFile.setHorizontalHeaderLabels(labels)

        for row in range(nb_row - 1):
            for col in range(nb_col):
                # tbl_readCsvFile
                if ((isMakeModelDataNull == False) and (str(datas[row + 1][col]) == '')):
                    isMakeModelDataNull = True
                item = QTableWidgetItem(str(datas[row + 1][col]))
                self.tbl_readCsvFile.setItem(row, col, item)

        self.tbl_readCsvFile.resizeColumnsToContents()

        # dataset file 토대로 datacolumn, leadtime 설정 (datadim, outputdim은 선택에따라서)
        colList = datas[0]
        self.model_col = qgis.PyQt.QtGui.QStandardItemModel()
        self.model_lead = qgis.PyQt.QtGui.QStandardItemModel()
        for idx in range(len(colList) - 1):
            itemData = colList[idx + 1]
            item = qgis.PyQt.QtGui.QStandardItem(itemData)
            item.setCheckable(True)
            if ('Lead_' in itemData):
                self.model_lead.appendRow(item)
            else:
                if ('Target_' in itemData):
                    item.setCheckable(False)
                    item.setCheckState(True)
                self.model_col.appendRow(item)
        self.tbl_modelDatasetColumn.setModel(self.model_col)
        self.tbl_modelDatasetLeadtime.setModel(self.model_lead)

    # tab [예측수행및성능분석] Select Dataset File button
    def LoadPredictDataset(self):

        # 선택한 데이터셋 파일에 NUll값이 존재하는지 확인
        global isPredictModelDataNull
        isPredictModelDataNull = False

        fileData, _ = QFileDialog.getOpenFileName(self, 'Open file', '', 'csv file(*.csv)')
        # 선택된 파일없을때 리턴
        if fileData == '': return
        # 데이터셋파일이 아닐경우 리턴
        fileinfo, fileext = os.path.splitext(fileData)
        if fileext != '.csv': return

        self.txtBox_pathSelectDataset.setText(fileData)
        self.tbl_selectCsvFile.clearContents()

        # 선택된 dataset file 내용 표기 ######################################
        datas = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                datas.append(rowdata)
        labels = datas[0]
        nb_row = len(datas)
        nb_col = len(datas[0])
        self.tbl_selectCsvFile.setRowCount(nb_row - 1)
        self.tbl_selectCsvFile.setColumnCount(nb_col)
        self.tbl_selectCsvFile.setHorizontalHeaderLabels(labels)

        for row in range(nb_row - 1):
            for col in range(nb_col):
                if ((isPredictModelDataNull == False) and (str(datas[row + 1][col]) == '')):
                    isPredictModelDataNull = True
                item = QTableWidgetItem(str(datas[row + 1][col]))
                self.tbl_selectCsvFile.setItem(row, col, item)
        self.tbl_selectCsvFile.resizeColumnsToContents()

        # dataset file 토대로 datacolumn, leadtime 설정 (datadim, outputdim은 선택에따라서)
        colList = datas[0]
        self.model_col = QtGui.QStandardItemModel()
        self.model_lead = QtGui.QStandardItemModel()
        for idx in range(len(colList) - 1):
            itemData = colList[idx + 1]
            item = QtGui.QStandardItem(itemData)
            item.setCheckable(True)
            if ('Lead_' in itemData):
                self.model_lead.appendRow(item)
            else:
                if ('Target_' in itemData):
                    item.setCheckable(False)
                    item.setCheckState(True)
                self.model_col.appendRow(item)
        self.tbl_predictDatasetColumn.setModel(self.model_col)
        self.tbl_predictDatasetLeadtime.setModel(self.model_lead)

    # tab [예측수행및성능분석] 생성한 모형 불러오기(폴더선택) Button
    def LoadModel(self):
        path = QFileDialog.getExistingDirectory(self, 'Open file')
        if os.path.exists(path):
            modelName = path + "/modelParam.txt"
            self.txtBox_pathSelectModel.setText(path)
            self.load_modelParamFunc(path, modelName)

    # tab [예측수행및성능분석] 예측수행결과 저장경로 선택 Button
    def SetPredictResultSavePath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_saveModelPath.setText(path)

    # tab [예측수행및성능분석] call:예측수행 전 입력값 체크
    def checkModelParam_load(self):

        # 1.데이터셋 파일이 선택되었는지,
        datafilepath = self.txtBox_pathSelectDataset.text()
        if datafilepath == "":
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일을 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 1-1. 데이터셋에 Null값이 포함되었는지,
        global isPredictModelDataNull
        if isPredictModelDataNull == True:
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일에 NULL값이 포함되어 있습니다.", QMessageBox.Ok)
            return "None"

        # 2.예측수행할 모델이 선택되었는지(폴더),
        selectmodelpath = self.txtBox_pathSelectModel.text()
        if selectmodelpath == "":
            QMessageBox.warning(None, 'Error Message', "모형 폴더 경로를 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 3.예측수행결과를 저장할 경로가 선택되었는지(폴더),
        modelpath = self.txtBox_saveModelPath.text()
        if modelpath == "":
            QMessageBox.warning(None, 'Error Message', "예측수행결과를 저장할 폴더 경로를 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 4.예측수행결과 폴더명을 입력하였는지,
        modelname = self.txtBox_saveModelName.text()
        if modelname == "":
            QMessageBox.warning(None, 'Error Message', "예측수행결과명을 입력해 주세요.", QMessageBox.Ok)
            return "None"

        # 5. 데이터컬럼정보를 선택했는지,
        sel_col = []
        sel_status = False
        model_col = self.tbl_predictDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            if item.checkState():
                if mIdx > 0:
                    sel_status = True
                itemData = item.text()
                sel_col.append(itemData[0:itemData.find('_', 0)])
        if sel_status == False:
            QMessageBox.warning(None, 'Error Message', "예측수행에 사용할 데이터를 선택해주세요.", QMessageBox.Ok)
            return "None"

        # 6. 데이터컬럼정보와 모델의 데이터컬럼정보의 갯수가 일치하는지,
        md_col = self.txtBox_load_dl_datainfo.text().split(',')
        if (len(sel_col) != len(md_col)):
            QMessageBox.warning(None, 'Error Message', "모델에 사용된 데이터와 예측수행에 사용할 데이터의 갯수가 다릅니다.", QMessageBox.Ok)
            return "None"

        # 7. 데이터컬럼정보가 모델의 데이터컬럼정보와 일치하는지,
        collectData_flag = True
        for cIdx in range(len(md_col)):
            if (sel_col[cIdx] != md_col[cIdx]):
                collectData_flag = False
                break
        if collectData_flag == False:
            QMessageBox.warning(None, 'Error Message', "모델에 사용된 데이터와 예측수행에 사용할 데이터의 종류가 다릅니다.", QMessageBox.Ok)
            return "None"

        # 8. 리드타임정보를 선택했는지,
        lead_col = []
        lead_status = False
        model_lead = self.tbl_predictDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                lead_status = True
                itemData = item.text()
                itemData = itemData[itemData.find('_', 0) + 1:]
                lead_col.append(itemData)
        if lead_status == False:
            QMessageBox.warning(None, 'Error Message', "예측수행에 사용할 리드타임을 선택해주세요.", QMessageBox.Ok)
            return "None"

        # 9. 선택한리드타임과 모델에서 사용한 리드타임이 같은지,
        md_lead = self.txtBox_load_dl_leadtimeinfo.text().split(',')
        if (len(lead_col) != len(md_lead)):
            QMessageBox.warning(None, 'Error Message', "모델에 사용된 리드타임과 예측수행에 사용할 리드타임의 갯수가 다릅니다.", QMessageBox.Ok)
            return "None"

        # 10. 리드타임컬럼정보가 모델의 리드타임컬럼정보와 일치하는지,
        collectData_flag = True
        for cIdx in range(len(md_lead)):
            # model의 leadtime 단위통일
            model_txt = md_lead[cIdx].strip().strip("Lead_")
            model_time = -1
            if (model_txt.find("H") > 0):
                leadtimeText = model_txt.strip().strip("H""M")
                if (leadtimeText == "0.5"):
                    model_time = 30
                else:
                    model_time = int(leadtimeText) * 60
            else:
                leadtimeText = model_txt.strip().strip("H""M")
                model_time = int(leadtimeText)
            # dataset의 leadtime 단위통일
            dataset_txt = lead_col[cIdx].strip().strip("Lead_")
            dataset_time = -1
            if (dataset_txt.find("H") > 0):
                leadtimeText = dataset_txt.strip().strip("H""M")
                dataset_time = int(leadtimeText) * 60
            else:
                leadtimeText = dataset_txt.strip().strip("H""M")
                dataset_time = int(leadtimeText)
            # leadtime 비교
            if (model_time != dataset_time):
                collectData_flag = False
                break
        if collectData_flag == False:
            QMessageBox.warning(None, 'Error Message', "모델에 사용된 리드타임과 예측수행에 사용할 리드타임의 종류가 다릅니다.", QMessageBox.Ok)
            return "None"

    # tab [예측수행및성능분석] call:예측수행및성능분석에서 모델선택전 파라메터정보 초기화
    def init_modelParamFunc(self):
        self.txtBox_load_dl_modelName.clear()
        self.sp_load_dl_dropOutRate.setValue(0)
        self.sp_load_dl_sequenceLength.setValue(0)
        self.sp_load_dl_hiddenDim.setValue(0)
        self.sp_load_dl_sizeOfBatch.setValue(0)
        self.sb_load_dl_dataDim.setValue(0)
        self.sp_load_dl_outputDim.setValue(0)
        self.sp_load_dl_learningRate.setValue(0)
        self.sp_load_dl_interation.setValue(0)
        self.sp_load_dl_valudatuinSplit.setValue(0)
        self.sp_load_dl_trainingRate.setValue(0)
        self.sp_load_dl_hiddenLayer.setValue(0)
        self.txtBox_load_dl_units.clear()
        self.cb_load_dl_activationFunc.setCurrentText("relu")
        self.cb_load_dl_optimizeFunc.setCurrentText("adam")
        self.cb_load_dl_lossFunc.setCurrentText("mean_squared_error")
        self.txtBox_load_dl_datainfo.clear()
        self.txtBox_load_dl_leadtimeinfo.clear()

    # tab [예측수행및성능분석] call:모형 선택 Button
    def load_modelParamFunc(self, modelPath, modelName):

        # python console활성화
        self.load_pyConsole()

        # control 초기화
        self.init_modelParamFunc()

        # model file check
        if os.path.isfile(modelName) == False: return

        # load model
        fileData = modelName

        data = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                data.append(rowdata)

        paramHeader = ['data_path', 'save_path', 'random_number', 'model_name', 'drop_out_rate',
                       'seq_length', 'hidden_dim', 'size_of_batch', 'learning_rate', 'iterations',
                       'patience_num', 'training_rate', 'train_size', 'test_size',
                       'Data_X_Column', 'X_data_training_column_list', 'Data_Y_Column',
                       'Y_data_training_column_list',
                       'data_dim', 'output_dim', 'lead_time', 'Predict_time_index', 'Predict_time_leadtime',
                       'validation_rate', 'hidden_layer_unit', 'hidden_layer', 'activation_func',
                       'optimize_func', 'loss_func', 'Elapsed_time(sec)']

        nb_row = len(data)
        for row in range(nb_row):
            col_text = str(data[row][0])
            if col_text == paramHeader[2]: self.sb_dl_randomNum_2.setValue(int(data[row][1]))
            if col_text == paramHeader[3]: self.txtBox_load_dl_modelName.setText(str(data[row][1]))
            if col_text == paramHeader[4]: self.sp_load_dl_dropOutRate.setValue(float(data[row][1]))
            if col_text == paramHeader[5]: self.sp_load_dl_sequenceLength.setValue(int(data[row][1]))
            if col_text == paramHeader[6]: self.sp_load_dl_hiddenDim.setValue(int(data[row][1]))
            if col_text == paramHeader[7]: self.sp_load_dl_sizeOfBatch.setValue(int(data[row][1]))
            if col_text == paramHeader[18]: self.sb_load_dl_dataDim.setValue(int(data[row][1]))
            if col_text == paramHeader[19]: self.sp_load_dl_outputDim.setValue(int(data[row][1]))
            if col_text == paramHeader[8]: self.sp_load_dl_learningRate.setValue(float(data[row][1]))
            if col_text == paramHeader[9]: self.sp_load_dl_interation.setValue(int(data[row][1]))
            if col_text == paramHeader[10]: self.sb_dl_patienceNum_2.setValue(int(data[row][1]))
            if col_text == paramHeader[23]: self.sp_load_dl_valudatuinSplit.setValue(float(data[row][1]))
            if col_text == paramHeader[11]: self.sp_load_dl_trainingRate.setValue(float(data[row][1]))
            if col_text == paramHeader[25]: self.sp_load_dl_hiddenLayer.setValue(int(data[row][1]))
            if col_text == paramHeader[24]:
                strUnit = ""
                for inIdx in range(len(data[row]) - 1):
                    row_text = data[row][inIdx + 1].strip().replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    strUnit += row_text.strip() + ","
                setText = strUnit.rstrip(',')
                self.txtBox_load_dl_units.setPlainText(setText)
            if col_text == paramHeader[26]: self.cb_load_dl_activationFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[27]: self.cb_load_dl_optimizeFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[28]: self.cb_load_dl_lossFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[15]:
                data_text = str(data[row]).replace('\"', "")
                tempdatalist = data_text.split(',')
                tempList = []
                strDataInfo = ""
                for obsIdx in range(len(tempdatalist) - 1):
                    obsData = tempdatalist[obsIdx + 1]
                    row_text = obsData[1:obsData.find('_', 0)].replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    strDataInfo += row_text.strip() + ","
                setText = strDataInfo.rstrip(',')
                self.txtBox_load_dl_datainfo.setText(setText)
            if col_text == paramHeader[17]:
                data_text = str(data[row]).replace('\"', "")
                tempdatalist = data_text.split(',')
                tempList = []
                strDataInfo = ""
                for obsIdx in range(len(tempdatalist) - 1):
                    obsData = tempdatalist[obsIdx + 1].strip()
                    row_text = obsData.replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    row_text = row_text.strip().replace("Lead_", "")
                    strDataInfo += row_text.strip() + ","
                setText = strDataInfo.rstrip(',')
                self.txtBox_load_dl_leadtimeinfo.setText(setText)

        # model info 출력
        modelInfo = tf.keras.models.load_model(modelPath)
        modelInfo.summary()

    # tab [예측수행및성능분석] 예측수행(Running Model) Button
    def RunPredict(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 예측수행 전, 입력값 체크
        if self.checkModelParam_load() == "None": return

        # 예측수행 결과를 저장할 폴더 정보를 확인
        datafilepath = self.txtBox_pathSelectDataset.text()
        dataModelpath = self.txtBox_pathSelectModel.text()
        modelpath = self.txtBox_saveModelPath.text()
        modelName = self.txtBox_saveModelName.text()
        saveModelpath = modelpath + "/"
        saveReportPath = saveModelpath + modelName + "/"
        saveResultPath = saveModelpath + modelName

        if not os.path.exists(saveResultPath):
            os.makedirs(saveResultPath)
        else:
            buttonReply = QMessageBox.warning(None, 'Error Message', "이미 존재하는 폴더입니다. 덮어쓰시겠습니까?",
                                              QMessageBox.Yes | QMessageBox.No)
            if buttonReply == QMessageBox.No:
                return
            elif buttonReply == QMessageBox.Yes:
                shutil.rmtree(saveReportPath)
                os.makedirs(saveReportPath)
            else:
                return

        random_number = self.sb_dl_randomNum_2.value()
        tf.random.set_seed(random_number)  # for reproducibility

        seq_length = self.sp_load_dl_sequenceLength.value()
        drop_out_rate = self.sp_load_dl_dropOutRate.value()

        # 데이터셋 파일 정보확인
        data = pd.read_csv(datafilepath, date_parser=True)

        # 데이터셋 헤더정보 확인
        header = data.columns.values

        # make data of training and test data
        data_test = data

        # get data & leadtime
        Data_X_Column = []  # data_col - data_column_index
        Data_Y_Column = []  # leadtime - data_column_index
        Predict_time_index = []  # leadtime - text
        Predict_time_leadtime = []  # leadtime - time

        model_col = self.tbl_predictDatasetColumn.model()
        for mIdx in range(model_col.rowCount()):
            item = model_col.item(mIdx)
            if item.checkState():
                Data_X_Column.append(mIdx + 1)

        model_lead = self.tbl_predictDatasetLeadtime.model()
        for mIdx in range(model_lead.rowCount()):
            item = model_lead.item(mIdx)
            if item.checkState():
                Data_Y_Column.append((model_col.rowCount() + mIdx + 1))
                leadtimeNm = item.text().strip().strip("Lead_")
                if (leadtimeNm.find("H") > 0):
                    leadtimeText = leadtimeNm.strip().strip("H""M")
                    Predict_time_index.append(leadtimeNm)
                    if (leadtimeText == "0.5"):
                         Predict_time_leadtime.append(30)
                    else:
                         Predict_time_leadtime.append(int(leadtimeText) * 60)
                else:
                    leadtimeText = leadtimeNm.strip().strip("H""M")
                    Predict_time_index.append(leadtimeNm)
                    Predict_time_leadtime.append(int(leadtimeText))

        # check the length of data
        print('Total = ', len(data))
        print('Test = ', len(data_test))

        # make dataset of test
        X_data_test_drop = data_test.iloc[:, Data_X_Column]
        Y_data_test_drop = data_test.iloc[:, Data_Y_Column]
        output_dim = len(Data_Y_Column)

        Current_time_test = data_test.iloc[seq_length:, [0]]
        Current_time_test = Current_time_test.reset_index(drop=True)

        # Make a prediction time for each leadtime
        Predict_time = pd.DataFrame()
        for i in range(0, len(Predict_time_leadtime)):
            Predict_time[Predict_time_index[i]] = pd.DatetimeIndex(Current_time_test['DATE']) + timedelta(
                minutes=Predict_time_leadtime[i])

        # load x, y scaler
        from pickle import load

        X_scaler = load(open(dataModelpath + '/X_scaler.pkl', 'rb'))
        Y_scaler = load(open(dataModelpath + '/Y_scaler.pkl', 'rb'))

        # load model
        regressior = tf.keras.models.load_model(dataModelpath)

        from tensorflow.keras import Sequential
        from tensorflow.keras.layers import Dense, LSTM, Dropout

        # test process
        X_df = X_data_test_drop
        Y_df = Y_data_test_drop

        # data normalize of test data
        X_inputs = X_scaler.transform(X_df)
        Y_inputs = Y_scaler.transform(Y_df)

        X_test = []
        Y_test = []

        # make dataset of test
        for i in range(seq_length, X_inputs.shape[0]):
            X_test.append(X_inputs[i - seq_length:i, :])
            Y_test.append(Y_inputs[i, :])

        X_test, Y_test = np.array(X_test), np.array(Y_test)

        # calculate predict Y
        Y_pred = regressior.predict(X_test)

        # conversion to original scale
        Y_pred = Y_pred * Y_scaler.data_range_[-1] + Y_scaler.data_min_[-1]
        Y_test = Y_test * Y_scaler.data_range_[-1] + Y_scaler.data_min_[-1]

        # Evaluating process
        import math

        # Define average function
        def average(values):
            if len(values) == 0:
                return None
            return sum(values, 0.0) / len(values)

        obs_avg = average(Y_test)  # calculate average

        # Define NSE(nash-sutcliffe efficiency)function
        def nse(obs_values, sim_values):
            e1 = list()
            e2 = list()
            for i in range(0, len(obs_values)):
                e1.append((obs_values[i] - sim_values[i]) ** 2)
                e2.append((obs_values[i] - obs_avg) ** 2)
            sum_e1 = sum(e1)
            sum_e2 = sum(e2)

            nse = 1 - sum_e1 / sum_e2
            return nse

        nse = nse(Y_test, Y_pred)  # calculate NSE

        # print evaluation factor
        print("Average of Obs. data=", obs_avg)
        print("NSE=", nse)

        # make the result file
        result_all = pd.DataFrame()
        result_all = pd.concat([Current_time_test], axis=1)

        for i in range(0, output_dim):
            result_tmp = pd.DataFrame(
                {"Y_true_" + Predict_time_index[i]: Y_test[:, i], "Y_pred_" + Predict_time_index[i]: Y_pred[:, i]})
            Predict_time_tmp = Predict_time.iloc[:, [i]]
            result_all = pd.concat([result_all, Predict_time_tmp, result_tmp], axis=1)

        result_all.to_csv(saveReportPath + 'predict_result_' + modelName + '_timeseries_drop-out_' + str(
            drop_out_rate) + "_seq_length_" + str(seq_length) + '.csv', index=False)


        # Visualising the results
        for i in range(0, len(Predict_time_index)):
            plt.figure(figsize=(14, 5))
            plt.plot(Y_test[:, i], color='red', label='Observed Water Level')
            plt.plot(Y_pred[:, i], color='blue', label='Predicted Water Level')
            plt.title('Water Level Prediction (NSE=' + str(nse[i]) + ')')
            plt.xlabel('Time')
            plt.ylabel('Water Level')
            plt.legend()
            plt.savefig(
                saveReportPath + 'prediction_result_' + modelName + '_after_' + Predict_time_index[
                    i] + '_drop-out_' + str(drop_out_rate) + "_seq_length_" + str(seq_length) + '.png')
            plt.close()

        msgQuit = QMessageBox.information(self, 'Message', "예측수행작업을 완료했습니다. 결과를 확인하시겠습니까?",
                                          QMessageBox.Yes | QMessageBox.No)
        if msgQuit == QMessageBox.Yes:
            # show result
            os.startfile(saveResultPath)

    # tab [실시간예측] : [1단계:지점선택] TargetPoint (+) Button
    def btn_getSelectedRealtimeFeatureTarget(self):

        self.cb_rt_targetPoint_id.clear()
        lyrName = "waterlevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) == 1:
            for f in selectLyr:
                self.cb_rt_targetPoint_id.addItem(str(f['obs_code']), f)  #obs_code ->  코드
        elif (len(selectLyr) > 1):
            QMessageBox.warning(None, 'Error Message', "Target Point는 한개만 선택되어야 합니다.", QMessageBox.Ok)
        elif (len(selectLyr) == 0):
            QMessageBox.warning(None, 'Error Message', "Target Point가 선택되지 않았습니다.", QMessageBox.Ok)
        else:
            QMessageBox.warning(None, 'Error Message', "Target Point가 선택되지 않았습니다.", QMessageBox.Ok)

    # tab [실시간예측] : [1단계:지점선택] Waterlevel (+) Button
    def btn_getSelectedRealtimeFeatureWL(self):

        self.cb_rt_waterLevel_id.clear()
        self.lbl_rtWaterlevelCount.setText('(0)')
        lyrName = "waterlevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_waterLevel_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtWaterlevelCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Rainfall (+) Button
    def btn_getSelectedRealtimeFeatureRF(self):

        self.cb_rt_rainfall_id.clear()
        self.lbl_rtRainfallCount.setText('(0)')
        lyrName = "rainfall"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_rainfall_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtRainfallCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Discharge (+) Button
    def btn_getSelectedRealtimeFeatureDC(self):

        self.cb_rt_flowrate_id.clear()
        self.lbl_rtDischargeCount.setText('(0)')
        lyrName = "discharge"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_flowrate_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtDischargeCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Daminlet (+) Button
    def btn_getSelectedRealtimeFeatureDI(self):

        self.cb_rt_damInlet_id.clear()
        self.lbl_rtDaminletCount.setText('(0)')
        lyrName = "daminlet"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_damInlet_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtDaminletCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Damrelease (+) Button
    def btn_getSelectedRealtimeFeatureDR(self):

        self.cb_rt_damRelease_id.clear()
        self.lbl_rtDamreleaseCount.setText('(0)')
        lyrName = "damrelease"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_damRelease_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtDamreleaseCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Tidelevel (+) Button
    def btn_getSelectedRealtimeFeatureTE(self):

        self.cb_rt_elevation_id.clear()
        self.lbl_rtTidelevelCount.setText('(0)')
        lyrName = "tidelevel"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_elevation_id.addItem(str(f['obs_code']), f)
                fCount = fCount + 1
            self.lbl_rtTidelevelCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [1단계:지점선택] Thiessen (+) Button
    def btn_getSelectedRealtimeFeatureTS(self):

        self.cb_rt_thiessen_id.clear()
        self.lbl_rtThiessenCount.setText('(0)')
        lyrName = "watershed"
        selectLyr = self.getSeletedFeature(lyrName)
        if len(selectLyr) > 0:
            fCount = 0
            for f in selectLyr:
                self.cb_rt_thiessen_id.addItem(str(f['sbsncd']), f)
                fCount = fCount + 1
            self.lbl_rtThiessenCount.setText("(" + str(fCount) + ")")

    # tab [실시간예측] : [2단계:모델선택] Select Model Directory button
    def LoadRealtimeModel(self):
        path = QFileDialog.getExistingDirectory(self, 'Open file')
        if os.path.exists(path):
            modelName = path + "/modelParam.txt"
            self.txtBox_pathSelectRealtimeModel.setText(path)
            self.load_realtimeModelParamFunc(path, modelName)

    # tab [실시간예측] : [2단계:모델선택] call:모형 선택 Button
    def load_realtimeModelParamFunc(self, modelPath, modelName):

        # python console활성화
        self.load_pyConsole()

        # control 초기화
        self.init_realtimeModelParamFunc()

        # model file check
        if os.path.isfile(modelName) == False: return

        # load model
        fileData = modelName

        data = []
        with open(fileData, 'r') as stream:
            for rowdata in csv.reader(stream):
                data.append(rowdata)

        paramHeader = ['data_path', 'save_path', 'random_number', 'model_name', 'drop_out_rate',
			   'seq_length', 'hidden_dim', 'size_of_batch', 'learning_rate', 'iterations',
			   'patience_num', 'training_rate', 'train_size', 'test_size',
			   'Data_X_Column', 'X_data_training_column_list', 'Data_Y_Column',
			   'Y_data_training_column_list',
			   'data_dim', 'output_dim', 'lead_time', 'Predict_time_index', 'Predict_time_leadtime',
			   'validation_rate', 'hidden_layer_unit', 'hidden_layer', 'activation_func',
			   'optimize_func', 'loss_func', 'Elapsed_time(sec)']

        nb_row = len(data)
        for row in range(nb_row):
            col_text = str(data[row][0])
            if col_text == paramHeader[2]: self.sb_rt_randomNum.setValue(int(data[row][1]))
            if col_text == paramHeader[3]: self.txtBox_load_rt_modelName.setText(str(data[row][1]))
            if col_text == paramHeader[4]: self.sp_load_rt_dropOutRate.setValue(float(data[row][1]))
            if col_text == paramHeader[5]: self.sp_load_rt_sequenceLength.setValue(int(data[row][1]))
            if col_text == paramHeader[6]: self.sp_load_rt_hiddenDim.setValue(int(data[row][1]))
            if col_text == paramHeader[7]: self.sp_load_rt_sizeOfBatch.setValue(int(data[row][1]))
            if col_text == paramHeader[18]: self.sb_load_rt_dataDim.setValue(int(data[row][1]))
            if col_text == paramHeader[19]: self.sp_load_rt_outputDim.setValue(int(data[row][1]))
            if col_text == paramHeader[8]: self.sp_load_rt_learningRate.setValue(float(data[row][1]))
            if col_text == paramHeader[9]: self.sp_load_rt_interation.setValue(int(data[row][1]))
            if col_text == paramHeader[10]: self.sb_rt_patienceNum.setValue(int(data[row][1]))
            if col_text == paramHeader[23]: self.sp_load_rt_valudatuinSplit.setValue(float(data[row][1]))
            if col_text == paramHeader[11]: self.sp_load_rt_trainingRate.setValue(float(data[row][1]))
            if col_text == paramHeader[25]: self.sp_load_rt_hiddenLayer.setValue(int(data[row][1]))
            if col_text == paramHeader[24]:
                strUnit = ""
                for inIdx in range(len(data[row]) - 1):
                    row_text = data[row][inIdx + 1].strip().replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    strUnit += row_text.strip() + ","
                setText = strUnit.rstrip(',')
                self.txtBox_load_rt_units.setPlainText(setText)
            if col_text == paramHeader[26]: self.cb_load_rt_activationFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[27]: self.cb_load_rt_optimizeFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[28]: self.cb_load_rt_lossFunc.setCurrentText(str(data[row][1]))
            if col_text == paramHeader[15]:
                data_text = str(data[row]).replace('\"', "")
                tempdatalist = data_text.split(',')
                tempList = []
                strDataInfo = ""
                for obsIdx in range(len(tempdatalist) - 1):
                    obsData = tempdatalist[obsIdx + 1]
                    row_text = obsData[1:obsData.find('_', 0)].replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    strDataInfo += row_text.strip() + ","
                setText = strDataInfo.rstrip(',')
                self.txtBox_load_rt_datainfo.setText(setText)
            if col_text == paramHeader[17]:
                data_text = str(data[row]).replace('\"', "")
                tempdatalist = data_text.split(',')
                tempList = []
                strDataInfo = ""
                for obsIdx in range(len(tempdatalist) - 1):
                    obsData = tempdatalist[obsIdx + 1].strip()
                    row_text = obsData.replace('[', "")
                    row_text = row_text.replace(']', "")
                    row_text = row_text.replace('\'', "")
                    row_text = row_text.replace('\"', "")
                    row_text = row_text.strip().replace("Lead_", "")
                    strDataInfo += row_text.strip() + ","
                setText = strDataInfo.rstrip(',')
                self.txtBox_load_rt_leadtimeinfo.setText(setText)

        # model info 출력
        modelInfo = tf.keras.models.load_model(modelPath)
        modelInfo.summary()

    # tab [실시간예측] : [2단계:모델선택] call:예측수행및성능분석에서 모델선택전 파라메터정보 초기화
    def init_realtimeModelParamFunc(self):
        self.txtBox_load_rt_modelName.clear()
        self.sp_load_rt_dropOutRate.setValue(0)
        self.sp_load_rt_sequenceLength.setValue(0)
        self.sp_load_rt_hiddenDim.setValue(0)
        self.sp_load_rt_sizeOfBatch.setValue(0)
        self.sb_load_rt_dataDim.setValue(0)
        self.sp_load_rt_outputDim.setValue(0)
        self.sp_load_rt_learningRate.setValue(0)
        self.sp_load_rt_interation.setValue(0)
        self.sp_load_rt_valudatuinSplit.setValue(0)
        self.sp_load_rt_trainingRate.setValue(0)
        self.sp_load_rt_hiddenLayer.setValue(0)
        self.txtBox_load_rt_units.clear()
        self.cb_load_rt_activationFunc.setCurrentText("relu")
        self.cb_load_rt_optimizeFunc.setCurrentText("adam")
        self.cb_load_rt_lossFunc.setCurrentText("mean_squared_error")
        self.txtBox_load_rt_datainfo.clear()
        self.txtBox_load_rt_leadtimeinfo.clear()

    # tab [실시간예측] : [3단계] 저장경로 선택 Button
    def SaveRealtimeModelPath(self):
        path = QFileDialog.getExistingDirectory(self)
        if os.path.exists(path):
            self.txtBox_saveRealtimeModelPath.setText(path)

    # tab [실시간예측] : [3단계] call:실시간예측수행 전 입력값 체크
    def checkRealtimeModelParam(self, stdTime):

        # 1.실시간예측수행할 모델이 선택되었는지(폴더),
        selectmodelpath = self.txtBox_pathSelectRealtimeModel.text()
        if selectmodelpath == "":
            QMessageBox.warning(None, 'Error Message', "실시간예측에 사용할 예측모형을 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 2.실시간예측수행결과를 저장할 경로가 선택되었는지(폴더),
        modelpath = self.txtBox_saveRealtimeModelPath.text()
        if modelpath == "":
            QMessageBox.warning(None, 'Error Message', "실시간예측 수행결과를 저장할 폴더 경로를 선택해 주세요.", QMessageBox.Ok)
            return "None"

        # 3.실시간예측을 수행할 데이터와 모델의 데이터종류가 일치하는지,
        dsDatadim = self.sb_load_rt_dataDim.value()
        dsOutputdim = self.sp_load_rt_outputDim.value()

        # 입력파일의 헤더정보 및 갯수 확인
        data = self.get_realtimeDataset(stdTime)
        header = data.columns.values
        datadim_count = 0  # target+ref
        outputdim_count = 0  # targer
        dataSearchHeader = []
        for idx in range(len(header)):
            if ('Target_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('Target')
            if ('WL_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('WL')
            if ('RF_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('RF')
            if ('DI_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('DI')
            if ('DR_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('DR')
            if ('DC_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('DC')
            if ('TE_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('TE')
            if ('WS_' in header[idx]) == True:
                datadim_count = datadim_count + 1
                dataSearchHeader.append('WS')
            if ('Target_' in header[idx]) == True:
                outputdim_count = outputdim_count + 1

        # 6.dataset의 data 종류가 selectmodel의 data종류와 갯수가 같아야 한다.
        strModelData = self.txtBox_load_rt_datainfo.text().split(',')
        strDatasetData = str(dataSearchHeader)

        if str(strModelData) != strDatasetData:
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일과 모델에서 사용하는 데이터의 종류가 다릅니다.", QMessageBox.Ok)            
            return "None"

        # 7. datadim, outputdim의 갯수가 같아야 한다.
        if (dsDatadim == datadim_count) and (dsOutputdim == outputdim_count):
            return "ok"
        else:
            QMessageBox.warning(None, 'Error Message', "데이터셋 파일과 모델에서 사용하는 데이터의 갯수가 다릅니다.", QMessageBox.Ok)
            return "None"

    # tab [실시간예측] : [3단계] call:실시간예측을 위한 데이터조회 (LeadTime은 고려하지않는다)
    def get_realtimeDataset(self, stdTime):

        # 조회기간(설정시간기준 sequence_length(분)만큼의 이전데이터) (1(10분)~72(12시간))
        sequenceLength = self.sp_load_rt_sequenceLength.value() * 10
        endDatetime = stdTime
        startTime = endDatetime - timedelta(minutes=sequenceLength)
        start = str(startTime.strftime("%Y-%m-%d %H:%M"))
        end = stdTime

        targetText = self.cb_rt_targetPoint_id.currentText()
        if targetText != "":
            dataTarget = targetText

        dataWaterlevel = [self.cb_rt_waterLevel_id.itemText(i) for i in range(self.cb_rt_waterLevel_id.count())]
        dataRainfall = [self.cb_rt_rainfall_id.itemText(i) for i in range(self.cb_rt_rainfall_id.count())]
        dataDaminlet = [self.cb_rt_damInlet_id.itemText(i) for i in range(self.cb_rt_damInlet_id.count())]
        dataDamrelease = [self.cb_rt_damRelease_id.itemText(i) for i in range(self.cb_rt_damRelease_id.count())]
        dataFlowrate = [self.cb_rt_flowrate_id.itemText(i) for i in range(self.cb_rt_flowrate_id.count())]
        dataElevation = [self.cb_rt_elevation_id.itemText(i) for i in range(self.cb_rt_elevation_id.count())]
        dataThiessen = [self.cb_rt_thiessen_id.itemText(i) for i in range(self.cb_rt_thiessen_id.count())]

        # 데이터조회
        conn = mariadb.connect(user="root", password="admin", host="localhost", port=3306, database="wpdb")
        cur = conn.cursor()

        # column header setting
        columnHeader = []
        resultset_now = []

        # 날짜정보
        sql_date = "date_format(DT_DATE, '%Y-%m-%d %H:%i') between '{0}' and '{1}'".format(start, end)

        # 1. get Target Data
        if targetText != "":
            columnHeader.append("DATE")
            select_all_query = "select DT_DATE from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                targetText, sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

            columnHeader.append('Target_' + targetText)
            select_all_query = "select DT_DATA from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                targetText, sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 2. get Waterlevel Data
        for obs_row in range(len(dataWaterlevel)):
            columnHeader.append('WL_' + dataWaterlevel[obs_row])
            select_all_query = "select DT_DATA from waterlevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataWaterlevel[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])

            resultset_now.append(resultset)

        # 3. get Rainfall Data
        for obs_row in range(len(dataRainfall)):
            columnHeader.append('RF_' + dataRainfall[obs_row])
            select_all_query = "select DT_DATA from rainfall where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataRainfall[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 4. get DamInlet Data
        for obs_row in range(len(dataDaminlet)):
            columnHeader.append('DI_' + dataDaminlet[obs_row])
            select_all_query = "select DT_DATA from daminlet where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataDaminlet[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 5. get DamRelease Data
        for obs_row in range(len(dataDamrelease)):
            columnHeader.append('DR_' + dataDamrelease[obs_row])
            select_all_query = "select DT_DATA from damrelease where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataDamrelease[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 6. get Flowarate Data
        for obs_row in range(len(dataFlowrate)):
            columnHeader.append('DC_' + dataFlowrate[obs_row])
            select_all_query = "select DT_DATA from discharge where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataFlowrate[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 7. get Elevation Data
        for obs_row in range(len(dataElevation)):
            columnHeader.append('TE_' + dataElevation[obs_row])
            select_all_query = "select DT_DATA from tidelevel where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataElevation[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        # 8. get Thiessen Data
        for obs_row in range(len(dataThiessen)):
            columnHeader.append('WS_' + dataThiessen[obs_row])
            select_all_query = "select DT_DATA from watershed where OBS_ID = '{0}' and {1} ORDER BY DT_DATE".format(
                dataThiessen[obs_row], sql_date)
            cur.execute(select_all_query)
            resultsetData = cur.fetchall()
            resultset = []
            for idx in range(len(resultsetData)):
                resultset.append(resultsetData[idx][0])
            resultset_now.append(resultset)

        conn.close()

        # 조회결과가 없으면 리턴
        if len(resultset_now) == 0:
            QMessageBox.warning(None, 'Information Message', "조회된 데이터가 없습니다.", QMessageBox.Ok)
            return "None"

        # 관측소별 조회데이터 갯수가 다르면 리턴
        isDataSame = True
        isFirstValue = 0
        for idxs in range(len(resultset_now)):
            if idxs == 0:
                isFirstValue = len(resultset_now[idxs])
            else:
                isValue = len(resultset_now[idxs])
                if isFirstValue != isValue:
                    QMessageBox.warning(None, 'Information Message', "데이터의 갯수가 관측소별로 다릅니다.", QMessageBox.Ok)
                    return "None"

        # 조회된데이터 pd형태로 return
        df = pd.DataFrame(index=range(0, len(resultset_now[0])), columns=columnHeader)
        for pdIdx in range(len(resultset_now)):
            df[columnHeader[pdIdx]] = resultset_now[pdIdx]
        return df

    # tab [실시간예측] : [3단계] Realtime Run Model button
    def RunRealtimeModel(self):

        # PythonConsole이 있는지 확인
        self.load_pyConsole()

        # 실시간예측 기준시간 (10분단위로 분석)
        selectTime = self.dt_rt_datetime.text()
        interval_min = 10
        timTmp = datetime.strptime(selectTime, "%Y-%m-%d %H:%M")
        selectTime = timTmp.replace(minute=timTmp.minute - timTmp.minute % interval_min, second=0, microsecond=0)
        stdTime = selectTime

        # 예측수행 전, 입력값 체크
        if self.checkRealtimeModelParam(stdTime) == "None": return

        # 예측수행 결과를 저장할 폴더 정보를 확인
        dataModelpath = self.txtBox_pathSelectRealtimeModel.text()
        modelpath = self.txtBox_saveRealtimeModelPath.text()
        saveModelpath = modelpath + "/"
        saveReportPath = modelpath + "/"
        saveResultPath = modelpath

        if not os.path.exists(saveResultPath):
            os.makedirs(saveResultPath)

        # 실시간예측
        if self.btn_realtimeModel.text() == "실시간예측 On":
            timer = 0
            self.btn_realtimeModel.setText("실시간예측 Off")
            self.txtBox_logRealtime.clear()
            self.realtimeModel(dataModelpath, saveModelpath, saveReportPath, timer, stdTime)
        else:
            # 실시간예측 종료하기
            if threading.active_count() > 1:
                myThread.cancel()
            self.btn_realtimeModel.setText("실시간예측 On")

    # tab [실시간예측] : [3단계] call:Realtime Run Model
    def realtimeModel(self, dataModelpath, saveModelpath, saveReportMainPath, timer, stdTime):

        saveReportPath = saveReportMainPath

        if not os.path.exists(saveReportPath):
            os.makedirs(saveReportPath)

        # pythonconsole clear
        pythonConsole = iface.mainWindow().findChild(QDockWidget, 'PythonConsole')
        if (pythonConsole or pythonConsole.isVisible()) and (timer%5==0):
            pythonConsole.console.shellOut.clearConsole()

        # 시간체크(10분씩 분석)
        startTime = stdTime + timedelta(minutes=10)
        nextTime = startTime

        # 실시간예측(10분=600초)
        global myThread
        myThread = threading.Timer(interval=600, function=self.realtimeModel, args=(dataModelpath, saveModelpath, saveReportMainPath, timer + 1, nextTime))
        myThread.start()

        random_number = self.sb_rt_randomNum.value()
        tf.random.set_seed(random_number)  # for reproducibility

        # 선택된 모델의 lead_time 체크
        lead_time = self.txtBox_load_rt_leadtimeinfo.text()

        # write log
        logfilePath = saveReportMainPath + "logfile.txt"

        seq_length = self.sp_load_rt_sequenceLength.value()
        data_dim = self.sb_load_rt_dataDim.value()
        drop_out_rate = self.sp_load_rt_dropOutRate.value()

        resultFileName = saveReportPath + "predict_result_" + lead_time + "_drop-out_" + str(drop_out_rate) + "_seq_length_" + str(seq_length) + ".csv"

        # 데이터셋 파일 정보확인
        data = self.get_realtimeDataset(stdTime)

        if (len(data) == self.sp_load_rt_sequenceLength.value()+1):
            # 데이터셋 헤더정보 확인
            header = data.columns.values
            datadim_count = 0  # target+ref
            outputdim_count = 0  # targer
            for idx in range(len(header)):
                # data_dim index = target+ref
                if ('Target_' in header[idx] or 'WL_' in header[idx] or 'RF_' in header[idx] or 'DI_' in header[
                    idx] or 'DR_' in header[idx] or 'DC_' in header[idx] or 'TE_' in header[idx] or 'WS_' in header[
                        idx]) == True:
                    datadim_count = datadim_count + 1
                # output_dim index = target
                if ('Target_' in header[idx]) == True:
                    outputdim_count = outputdim_count + 1

            # make data of training and test data
            data_test = data

            # check the length of data
            print('Total = ', len(data))
            print('Test = ', len(data_test))

            # make dataset of test
            data_test_drop = data_test.iloc[:, np.r_[1:datadim_count + 1]]

            Current_time_test = data_test.iloc[:, [0]]
            Current_time_test = Current_time_test.reset_index(drop=True)

            # Make a prediction time for each leadtime
            Predict_time_leadtime = 0
            leadtimeNm = lead_time
            if (leadtimeNm.find("H") > 0):
                leadtimeText = leadtimeNm.strip().strip("H""M")
                if (leadtimeText == "0.5"):
                    Predict_time_leadtime = 30
                else:
                    Predict_time_leadtime = int(leadtimeText) * 60
            else:
                leadtimeText = leadtimeNm.strip().strip("H""M")
                Predict_time_leadtime=int(leadtimeText)
            Predict_time = stdTime + timedelta(minutes=Predict_time_leadtime)

            # load x, y scaler
            from pickle import load

            # data normalize of test data
            scaler = load(open(dataModelpath + '/X_scaler.pkl', 'rb'))  # MinMaxScaler()
            Y_scaler = load(open(dataModelpath + '/Y_scaler.pkl', 'rb'))

            # load_model
            savedModel = tf.keras.models.load_model(dataModelpath)

            # Training process
            from tensorflow.keras import Sequential
            from tensorflow.keras.layers import Dense, LSTM, Dropout

            # test process
            df = data_test_drop

            # load scaler
            inputs = scaler.transform(df)

            X_test = []

            # make dataset of test
            for i in range(seq_length, inputs.shape[0]):
                X_test.append(inputs[i - seq_length:i, 0:data_dim])

            # data normalize of test data
            X_test = np.array(X_test)

            # calculate predict Y
            y_pred = savedModel.predict(X_test)

            # conversion to original scale
            y_pred = y_pred * Y_scaler.data_range_[-1] + Y_scaler.data_min_[-1]

            # make the result file
            result = pd.DataFrame({"date_time": str(stdTime), "y_date" : Predict_time, "y_pred": y_pred[:, 0]})
            if not os.path.isfile(resultFileName):
                result.to_csv(resultFileName, index=False)
            else:
                result.to_csv(resultFileName, mode='a', index=False, header=False)

            self.txtBox_logRealtime.appendPlainText(str(stdTime) + "_predict")

        else:
            if not os.path.isfile(logfilePath):
                logFile = open(logfilePath, 'w')
            else:
                logFile = open(logfilePath, 'a')

            self.txtBox_logRealtime.appendPlainText(str(stdTime) + "_error")
            logFile.write(str(stdTime) + "_error\n")
            logFile.close()

# 데이터셋 그래프 화면
class PyWPdsGraph():

    global arrHeader
    global arrDatas
    global canvas
    global ax
    global fig
    global toolbar
    global x_date

    def __init__(self, PyWPdsGraph):
        self.setupUi(PyWPdsGraph)
        self.setupFunction(PyWPdsGraph)

    def setupUi(self, PyWPdsGraph):
        PyWPdsGraph.setObjectName("PyWPdsGraph")
        PyWPdsGraph.resize(1044, 666)
        self.verticalLayoutWidget = QtWidgets.QWidget(PyWPdsGraph)
        self.verticalLayoutWidget.setGeometry(QtCore.QRect(190, 90, 841, 561))
        self.verticalLayoutWidget.setObjectName("verticalLayoutWidget")
        self.verticalLayout = QtWidgets.QVBoxLayout(self.verticalLayoutWidget)
        self.verticalLayout.setContentsMargins(0, 0, 0, 0)
        self.verticalLayout.setObjectName("verticalLayout")
        self.groupBox = QtWidgets.QGroupBox(PyWPdsGraph)
        self.groupBox.setGeometry(QtCore.QRect(20, 20, 1011, 61))
        self.groupBox.setTitle("")
        self.groupBox.setObjectName("groupBox")
        self.lbl_title = QtWidgets.QLabel(self.groupBox)
        self.lbl_title.setGeometry(QtCore.QRect(19, 22, 611, 16))
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.lbl_title.setFont(font)
        self.lbl_title.setObjectName("lbl_title")
        self.btn_reDraw = QtWidgets.QPushButton(self.groupBox)
        self.btn_reDraw.setGeometry(QtCore.QRect(912, 15, 81, 31))
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.btn_reDraw.setFont(font)
        self.btn_reDraw.setObjectName("btn_reDraw")
        self.lbl_date = QtWidgets.QLabel(self.groupBox)
        self.lbl_date.setGeometry(QtCore.QRect(635, 20, 61, 20))
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.lbl_date.setFont(font)
        self.lbl_date.setObjectName("lbl_date")
        self.dt_data_startTime = QtWidgets.QDateTimeEdit(self.groupBox)
        self.dt_data_startTime.setGeometry(QtCore.QRect(705, 20, 86, 22))
        font = QtGui.QFont()
        font.setFamily("굴림")
        font.setPointSize(9)
        font.setBold(False)
        font.setWeight(50)
        self.dt_data_startTime.setFont(font)
        self.dt_data_startTime.setDate(QtCore.QDate(2016, 9, 16))
        self.dt_data_startTime.setTime(QtCore.QTime(0, 0, 0))
        self.dt_data_startTime.setObjectName("dt_data_startTime")
        self.lbl_date_2 = QtWidgets.QLabel(self.groupBox)
        self.lbl_date_2.setGeometry(QtCore.QRect(795, 20, 12, 20))
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.lbl_date_2.setFont(font)
        self.lbl_date_2.setObjectName("lbl_date_2")
        self.dt_data_endTime = QtWidgets.QDateTimeEdit(self.groupBox)
        self.dt_data_endTime.setGeometry(QtCore.QRect(810, 20, 86, 22))
        font = QtGui.QFont()
        font.setFamily("굴림")
        font.setPointSize(9)
        font.setBold(False)
        font.setWeight(50)
        self.dt_data_endTime.setFont(font)
        self.dt_data_endTime.setDateTime(QtCore.QDateTime(QtCore.QDate(2016, 9, 18), QtCore.QTime(0, 0, 0)))
        self.dt_data_endTime.setDate(QtCore.QDate(2016, 9, 18))
        self.dt_data_endTime.setTime(QtCore.QTime(0, 0, 0))
        self.dt_data_endTime.setObjectName("dt_data_endTime")
        self.tbl_dataList = QtWidgets.QListView(PyWPdsGraph)
        self.tbl_dataList.setGeometry(QtCore.QRect(20, 90, 161, 561))
        font = QtGui.QFont()
        font.setBold(False)
        font.setWeight(50)
        self.tbl_dataList.setFont(font)
        self.tbl_dataList.setObjectName("tbl_dataList")

        self.retranslateUi(PyWPdsGraph)
        QtCore.QMetaObject.connectSlotsByName(PyWPdsGraph)
        PyWPdsGraph.setTabOrder(self.dt_data_startTime, self.dt_data_endTime)
        PyWPdsGraph.setTabOrder(self.dt_data_endTime, self.btn_reDraw)
        PyWPdsGraph.setTabOrder(self.btn_reDraw, self.tbl_dataList)

    def retranslateUi(self, PyWPdsGraph):
        _translate = QtCore.QCoreApplication.translate
        PyWPdsGraph.setWindowTitle(_translate("PyWPdsGraph", "Dataset Graph"))
        self.lbl_title.setText(_translate("PyWPdsGraph", "TextLabel"))
        self.btn_reDraw.setText(_translate("PyWPdsGraph", "조회하기"))
        self.lbl_date.setText(_translate("PyWPdsGraph", "조회기간 :"))
        self.dt_data_startTime.setDisplayFormat(_translate("PyWPdsGraph", "yyyy-MM-dd"))
        self.lbl_date_2.setText(_translate("PyWPdsGraph", "~"))
        self.dt_data_endTime.setDisplayFormat(_translate("PyWPdsGraph", "yyyy-MM-dd"))

    def setupFunction(self, PyWPdsGraph):
        self.btn_reDraw.clicked.connect(self.RedrawGraph)
        self.tbl_dataList.clicked.connect(self.RedrawCheckbox)

    # 데이터초기화 (컨트롤 값, 배열분할)
    def InitData(self, PyWPdsGraph, dataHeader, dataOriginal):

        global arrHeader
        global arrDatas
        global toolbar
        global canvas
        global ax
        global fig
        global x_date

        # 데이터셋 그래프 자료 셋팅하기
        arrHeader = dataHeader
        arrDatas = dataOriginal

        # graph_data_set
        x_date = [i[1] for i in arrDatas[0]]

        # 조회기간 설정
        self.dt_data_startTime.setDateTime(arrDatas[0][0][1])
        self.dt_data_endTime.setDateTime(arrDatas[0][len(arrDatas[0])-1][1])

        strLblText = "[원본 데이터셋 기간정보] - {0} ~ {1}".format(arrDatas[0][0][1], arrDatas[0][len(arrDatas[0])-1][1])

        # init_title
        self.lbl_title.setText(strLblText)

        # 그래프 초기화
        self.fig = plt.Figure()
        self.canvas = FigureCanvas(self.fig)
        self.toolbar = NavigationToolbar(self.canvas, None)

        # widget_setting
        self.verticalLayout.addWidget(self.toolbar)
        self.verticalLayout.addWidget(self.canvas)
        ax = self.fig.add_subplot(111)

        # 데이터셋 데이터종류(table) 셋팅하기
        nb_row = len(arrHeader) - 1
        nb_col = 1
        self.model_col = QtGui.QStandardItemModel()
        for idx in range(len(dataOriginal)):
            itemData = arrHeader[idx + 1]
            if ('Lead_' in itemData) == False:
                item = QtGui.QStandardItem(itemData)
                item.setCheckable(True)
                item.setCheckState(QtCore.Qt.Checked)
                self.model_col.appendRow(item)
        self.tbl_dataList.setModel(self.model_col)

        # 그래프그리기
        self.drawGraph()

    # draw graph
    def drawGraph(self):

        global arrHeader
        global arrDatas
        global canvas
        global ax
        global fig
        global x_date

        # matplot_color
        line_colors = ['darkblue','darkcyan',
                    'darkgoldenrod','darkgray','darkgreen','darkkhaki','darkmagenta',
                    'darkolivegreen','darkorange','darkorchid','darkred','darksalmon',
                    'darkseagreen','darkslateblue','darkslategray','darkturquoise','darkviolet',
                    'deeppink','deepskyblue','dimgray','dodgerblue','firebrick','floralwhite',
                    'forestgreen','fuchsia','gainsboro','ghostwhite','gold','goldenrod','gray',
                    'green','greenyellow','honeydew','hotpink','indianred','indigo','ivory',
                    'khaki','lavender','lavenderblush','lawngreen','lemonchiffon','lightblue','lightcoral',
                    'lightcyan','lightgoldenrodyellow','lightgreen','lightgray',
                    'lightpink','lightsalmon','lightseagreen','lightskyblue','lightslategray',
                    'lightsteelblue','lightyellow','lime','limegreen','linen',
                    'magenta','maroon','mediumaquamarine','aliceblue', 'antiquewhite','aqua','aquamarine','azure',
                    'beige','bisque','black','blanchedalmond','blue',
                    'blueviolet','brown','burlywood','cadetblue','chartreuse','chocolate',
                    'coral','cornflowerblue','cornsilk','crimson','cyan', 'mediumblue','mediumorchid',
                    'mediumpurple','mediumseagreen',
                    'mediumslateblue','mediumspringgreen','mediumturquoise','mediumvioletred',
                    'midnightblue','mintcream','mistyrose',
                    'moccasin','navajowhite','navy','oldlace','olive','olivedrab','orange',
                    'orangered','orchid','palegoldenrod','palegreen',
                    'paleturquoise','palevioletred','papayawhip','peachpuff',
                    'peru','pink','plum','powderblue','purple','red','rosybrown',
                    'royalblue','saddlebrown','salmon',
                    'sandybrown','seagreen','seashell','sienna','silver','skyblue',
                    'slateblue','slategray','snow','springgreen',
                    'steelblue','tan','teal','thistle','tomato','turquoise',
                    'violet','wheat','white','whitesmoke','yellow', 'yellowgreen']

        # 그래프 초기화
        self.fig.clf()
        ax = self.fig.add_subplot(111)

        strStartDate = self.dt_data_startTime.text()
        strEndDate = self.dt_data_endTime.text()

        strTitle = "{0} ~ {1}".format(strStartDate, strEndDate)

        # 데이터셋 그래프그리기

        # date
        x_dateMonth = [str(i)[0:10] for i in x_date]
        startIdx = x_dateMonth.index(strStartDate)
        x_dateMonth.reverse()
        endIdx = len(x_dateMonth) - x_dateMonth.index(strEndDate) - 1

        # data
        x_plot_date = x_date[startIdx : endIdx + 1]
        arr_ydata = []
        for idx in range(len(arrDatas)):
            y_temp = [self.convert_data_nullToNan(i[2]) for i in arrDatas[idx][startIdx : endIdx + 1]]
            arr_ydata.append(y_temp)

        data_col = self.tbl_dataList.model()
        for idx in range(data_col.rowCount()):
            item = data_col.item(idx)
            if item.checkState():
                ax.plot(x_plot_date, arr_ydata[idx], color=line_colors[idx], label=arrHeader[idx + 1])

        ax.legend()
        ax.set_title(strTitle)
        self.fig.autofmt_xdate()
        self.fig.tight_layout()
        self.canvas.draw()

    def RedrawGraph(self):

        # 조회기간이 올바른지(시작일이 종료일보다 크거나 같은지)
        if (self.dt_data_startTime.date() > self.dt_data_endTime.date()):
            QMessageBox.warning(None, 'Error Message', "조회 시작일이 종료일보다 클 수 없습니다.", QMessageBox.Ok)
            return 

        # check_date
        strStartDate = self.dt_data_startTime.text()
        strEndDate = self.dt_data_endTime.text()

        #global arrDatas
        global x_date
        x_dateMonth = [str(i)[0:10] for i in x_date]
        startIdx = x_dateMonth.index(strStartDate) if strStartDate in x_dateMonth else -1
        errMsg = "조회기간을 다시 설정해주세요.\n조회가능기간 : {0} ~ {1}".format(x_dateMonth[0], x_dateMonth[len(x_dateMonth)-1])
        if startIdx == -1:
            QMessageBox.warning(None, 'Error Message', errMsg, QMessageBox.Ok)
            return

        x_dateMonth.reverse()
        endIndex = x_dateMonth.index(strEndDate) if strEndDate in x_dateMonth else -1
        if endIndex == -1:
            QMessageBox.warning(None, 'Error Message', errMsg, QMessageBox.Ok)
            return

        # draw_graph
        self.drawGraph()

    # 데이터 조회 시, NULL 값 체크해서 변환하는 함수
    def convert_data_nullToNan(self, data):
        if str(data) == 'None':
            return np.NAN
        else:
            return float(data)

    def RedrawCheckbox(self):
        self.drawGraph()

# 품질관리
class DataQualityManagement():

    global origin_file

    def __init__(self, datafile):
        self.origin_file = datafile

    # RAW DATA 날짜형식 변경 (api data - 사용안함)
    def DATE_CONTROL(self):
        print("convert raw_data - data format and date format")

        file_folder = r"M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\01_DAM_RAW_DATA_MODIFY"
        new_file_folder = r'M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\02_DAM_DATE_CONTROL'

        for dd in os.listdir(file_folder):  # 폴더 접근
            print('sub_folder_name:   ', file_folder, dd)  # 서브폴더 이름 출력
            Old_Full_path = os.path.join(file_folder, dd)
            print(Old_Full_path)  # 서브폴더까지 접근

            for ss in os.listdir(Old_Full_path):
                full_path = (os.path.join(Old_Full_path, ss))  # 서브폴더 내 파일까지 접근
                # print("file_full_path:  ", full_path) # 예: M:\02_GENERAL_SERVICE\2023_KICT_AI_TASK\KWATER_DAM\DAM_API_DATA\강천\1007601_강천_2011.csv
                year = full_path[-8:-4]  # 년도만
                NUMBER = full_path[-19:-12]
                # print(ss)
                DAM_CODE = ss[0:7]  # 코드만

                # print("NUMBER: ", NUMBER)
                # print("year: ", year)
                Data = pd.read_csv(full_path, encoding='utf-8')
                # Data = pd.read_csv(full_path, encoding = 'cp949')
                # Data = open(full_path, 'rt', encoding = 'cp949')
                # Data = pd.read_csv(full_path) open('파일경로', 'rt', encoding='UTF8')
                TEST_FILE_1 = pd.DataFrame(Data)
                # print(TEST_FILE_1)

                NEW_DATA_1 = []
                # print("check_data_1.shape:", TEST_FILE_1.shape)
                # print(TEST_FILE_1.shape[0])
                check_data_1shape_0 = TEST_FILE_1.shape[0]

                # 데이터의 형식은 "유입량", "댐수위", "일시 (10-01 00시 10분","강우량", "저수량", "저수율", "총방류량" 으로 작성되어 있음.

                for j in range(check_data_1shape_0):  # 여기는 파일 내부
                    # data = (TEST_FILE_1.iloc[j,:]).str.contains('遺').tolist()
                    data = (TEST_FILE_1.iloc[j, :]).str.contains('분').tolist()
                    data_3 = (data.index(True))  # 날짜가 있는 위치값을 반환
                    # print("POSITION: ", data_3)
                    DATE = TEST_FILE_1.iloc[j, data_3]  # 각 행의 일시 값만 불러온다.
                    DATE_2 = str(year + DATE[0:2] + DATE[3:5] + DATE[6:8] + DATE[10:12])

                    # print()
                    # if (TEST_FILE_1.iloc[j, data_3 - 2] in TEST_FILE_1.columns) and (TEST_FILE_1.iloc[j, data_3 + 4] in TEST_FILE_1.columns):

                    # print(DATE_2, TEST_FILE_1.iloc[j, data_3 - 2], TEST_FILE_1.iloc[j, data_3 + 4]) # 날짜, 유입량, 총방류량 순으로 작성
                    data_list = [DATE_2, TEST_FILE_1.iloc[j, data_3 - 2], TEST_FILE_1.iloc[j, data_3 + 4]]
                    NEW_DATA_1.append(data_list)

                    # elif TEST_FILE_1.iloc[j, data_3 + 4] not in TEST_FILE_1.columns:
                    #    print(DATE_2, TEST_FILE_1.iloc[j, data_3 - 2])  # 날짜, 유입량, 총방류량 순으로 작성
                    #    data_list = [DATE_2, TEST_FILE_1.iloc[j, data_3 - 2]]
                    #    NEW_DATA_1.append(data_list)
                    # else:
                    #    pass

                NEW_DATA_4 = pd.DataFrame(NEW_DATA_1)
                # NEW_DATA_4.columns = ["timestamp", "values"]

                # if (NEW_DATA_4.iloc[:, 1].values in NEW_DATA_4.columns) and (NEW_DATA_4.iloc[:, 2].values in NEW_DATA_4.columns):
                # print(NEW_DATA_4)
                # print("NEW_DATA_4.shape:  ", NEW_DATA_4.shape)
                NEW_DATA_INFLOW = NEW_DATA_4.iloc[:, [0, 1]]
                NEW_DATA_OUTFLOW = NEW_DATA_4.iloc[:, [0, 2]]

                New_folder_path_in = os.path.join(new_file_folder, 'IN')
                New_folder_path_out = os.path.join(new_file_folder, 'OUT')

                New_folder_path_1 = os.path.join(New_folder_path_in, DAM_CODE)
                New_folder_path_2 = os.path.join(New_folder_path_out, DAM_CODE)

                INFLOW_PATH = os.path.join(New_folder_path_1, str(DAM_CODE + '_' + year + '_IN.csv'))
                OUTFLOW_PATH = os.path.join(New_folder_path_2, str(DAM_CODE + '_' + year + '_OUT.csv'))

                pd.DataFrame(NEW_DATA_INFLOW).to_csv((INFLOW_PATH), header=False, index=False)
                pd.DataFrame(NEW_DATA_OUTFLOW).to_csv((OUTFLOW_PATH), header=False, index=False)
                print("file_full_path:  ", full_path)

    # DATA 결합 (api data - 사용안함)
    def DATA_MERGE(self):
        print("merge_data - each year")

        file_folder = 'test\\control\\OUT'
        new_file_folder = 'test\\merge\\OUT'

        for j in os.listdir(file_folder):  # 서브폴더 접근
            full_path = os.path.join(file_folder, j)
            print(full_path)
            data_frames = []
            for k in os.listdir(full_path):  # 파일접근
                # data_frames = []
                full_file_path = os.path.join(full_path, k)
                print(full_file_path)

                Data = pd.read_csv(full_file_path, header=None)
                FILE_1 = pd.DataFrame(Data)
                print(FILE_1.info())

                print(FILE_1)
                print("check_data_1.shape:", FILE_1.shape)
                print(FILE_1.shape[0])
                check_data_1shape_0 = FILE_1.shape[0]

                data_frames.append(FILE_1)

            FILE_1 = pd.concat(data_frames, axis=0, ignore_index=True)
            print(FILE_1.info())
            # new_sub_folder = os.path.join(new_file_folder, j)
            FILE_MERGE = os.path.join(new_file_folder, (str(j) + '_OUT.csv'))
            # FILE_MERGE = os.path.join(new_file_folder, (str(j) + '_IN.csv'))
            pd.DataFrame(FILE_1).to_csv((FILE_MERGE), header=False, index=False)

    # DATA중 시간표기변경 (2400 to 0000)
    def TIME_EXPRESSION_MODIFY(self):

        Data = pd.read_csv(self.origin_file, header=None)
        FILE_1 = pd.DataFrame(Data)
        check_data_1shape_0 = FILE_1.shape[0]
        for i in range(check_data_1shape_0):  # 파일 내부 데이터의 이터레이션을 진행함.
            date_num = str(FILE_1.iloc[i, 0])

            if date_num[8:13] == str(2400):
                #print(date_num[8:13])
                date_num_0 = str(FILE_1.iloc[i, 0])  # 데이터는 string 타입임.
                date_num_1 = str(FILE_1.iloc[i - 1, 0])
                #print("IN_DATA_TIME - 10 min =", date_num_1)
                #print("IN_DATA_TIME          =", date_num_0)
                #print()

                current_time_1 = datetime.datetime(int(date_num_1[0:4]), int(date_num_1[4:6]),
                                                   int(date_num_1[6:8]),
                                                   int(date_num_1[8:10]), int(date_num_1[10:12]))
                #print("NEW_CURRENT_TIME - 10min =", current_time_1)
                #print("ORIGIN_CURRENT_TIME         =", date_num_0)  # 파이썬에서 시간은 24를 나타내지 못한다. 24일 경우 에러를 발생시킨다.
                #print()

                new_time = current_time_1 + time_step
                #print("NEW_TIME= ", new_time)
                year = new_time.strftime('%Y')
                month = new_time.strftime('%m')
                day = new_time.strftime('%d')
                hour = new_time.strftime('%H')
                minutes = new_time.strftime('%M')
                new_current_time = str(year + month + day + hour + minutes)
                #print('NEW_CURRENT_TIME=', new_current_time)
                #print()
                FILE_1.iloc[i, 0] = new_current_time

                print("TIME_EXPRESSION_CHANGE__!!!")

            #else:
                # print(date_num[8:13])
                #print("NOT_CHANGED")
                #print()

        return FILE_1

    # DATA 중 콤마제거
    def REMOVE_COMMA(self, pdData):
        RAW_DATA_1 = pdData
        RAW_DATA_LEN = RAW_DATA_1.shape[0]
        for i in range(RAW_DATA_LEN):
            RAW_DATA_1.iloc[i, 1] = str(RAW_DATA_1.iloc[i, 1]).replace(',', '')
        NEW_DATAFRAME = RAW_DATA_1

        return NEW_DATAFRAME

    # 날짜 누락 보간 (api data - 사용안함)
    def TIME_MODIFY(self, pdData):
        '''Vlookup_index_1 = r'VlookUp_Time.csv'  # 날짜_시간만 있는 파일

        #### 데이터 참조 내용 ####
        Vlookup_index = pd.read_csv(Vlookup_index_1, header=None)
        print()
        Vlookup_Table = pd.DataFrame(Vlookup_index)

        print('Vlookup_Table_2:         ...')
        print(Vlookup_Table)
        print('Vlookup_Table was CALLED !!')
        print()

        # =============================================== 가공 파일 접근 =====================================================
        #=================================== 경로는 작업 컴퓨터에 맞게 수정 필요 ===============================================

        # folder_path = r'M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\05_DAM_REMOVE_COMMA'
        # New_folder_path = r'M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\06_DAM_TIME_MODIFY'
        # Temporary_path = r'M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\DAM_TIME_TEMP'

        folder_path = r'test\\remove_comma'
        New_folder_path = r'test\\time_modify'
        Temporary_path = r'test\\time_temp'

        for i in os.listdir(folder_path):
            file_path = os.path.join(folder_path, i)
            New_file_path = os.path.join(New_folder_path, i)
            # M:\02_GENERAL_SERVICE\2023_YEAR\2023_KICT_AI_TASK_2nd_062323\DAM_TASK_RE_230704\04_DAM_2400_TO_0000_MODIFY\IN

            for k in os.listdir(file_path):
                file = k[0:7]
                current_file_name = os.path.join(file_path, k)  # 현재 파일
                print('Current_file_name:  ', current_file_name)  # 현재 파일 확인 체크

                New_File_Name = os.path.join(New_file_path, k)  # 저장 경로
                print('NEW_file_name:  ', New_File_Name)

                ### 데이터 호출 ###
                RAW_DATA = pd.read_csv(current_file_name, header=None)

                RAW_DATA_0 = pd.DataFrame(RAW_DATA)
                # RAW_DATA_0 = RAW_DATA_[1:]
                print(RAW_DATA_0)

                RAW_DATA_1 = RAW_DATA_0.astype({0: 'int64'})

                df = pd.merge(Vlookup_Table, RAW_DATA_1, how='left', left_on=0, right_on=0)
                # print(df)
                Merged_File_Name = os.path.join(Temporary_path, (str(file) + str(i) + '_Temp_merged.csv'))
                pd.DataFrame(df).to_csv(Merged_File_Name, header=False, index=False)  # 임시파일 저장

                ####### 임시파일에서 필요없는 열 삭제  #######
                Merged_File_Name_called = pd.read_csv(Merged_File_Name, header=None)
                Data_Frames_1 = pd.DataFrame(Merged_File_Name_called)

                print("RAW_DATA================")
                print(RAW_DATA)
                print(RAW_DATA.shape)
                print()

                print("Temporary_data ==== > Data_Frames_1")
                print(Data_Frames_1)
                Data_Frames_2 = Data_Frames_1.drop(1, axis=1)
                print()

                print("Data_Frames_2================")
                print(Data_Frames_2)
                print(Data_Frames_2.shape)
                print()

                ####### 최종 파일 저장장  ######
                pd.DataFrame(Data_Frames_2).to_csv((New_File_Name), header=False, index=False)
                print("DATA IS SAVED !!")'''

        Vlookup_Table = pd.date_range('')

        RAW_DATA_0 = pdData

        RAW_DATA_1 = RAW_DATA_0.astype({0: 'int64'})

        df = pd.merge(Vlookup_Table, RAW_DATA_1, how='left', left_on=0, right_on=0)
        # print(df)
        Merged_File_Name = os.path.join(Temporary_path, (str(file) + str(i) + '_Temp_merged.csv'))
        pd.DataFrame(df).to_csv(Merged_File_Name, header=False, index=False)  # 임시파일 저장

        ####### 임시파일에서 필요없는 열 삭제  #######
        Merged_File_Name_called = pd.read_csv(Merged_File_Name, header=None)
        Data_Frames_1 = pd.DataFrame(Merged_File_Name_called)

        print("RAW_DATA================")
        print(RAW_DATA)
        print(RAW_DATA.shape)
        print()

        print("Temporary_data ==== > Data_Frames_1")
        print(Data_Frames_1)
        Data_Frames_2 = Data_Frames_1.drop(1, axis=1)
        print()

        print("Data_Frames_2================")
        print(Data_Frames_2)
        print(Data_Frames_2.shape)
        print()

        ####### 최종 파일 저장장  ######
        pd.DataFrame(Data_Frames_2).to_csv((New_File_Name), header=False, index=False)
        print("DATA IS SAVED !!")

    # 중복 DATA 제거
    def REMOVE_DUPLICATE(self, pdData):
        DATA = pdData
        DATA.columns = ["DATE", "value"]
        DATA_2 = DATA.drop_duplicates("DATE")

        return DATA_2

    # 마이너스값을 0으로 변경 (수위제외, 유량/댐유입량/댐방류량/조위)
    def MINUS_TO_ZERO(self, pdData):
        TEST_FILE_2 = pdData
        #TEST_FILE_2.iloc[:, 1][float(TEST_FILE_2.iloc[:, 1]) < 0] = 0
        for i in range(TEST_FILE_2.shape[0]):
            if ((TEST_FILE_2.iloc[i, 1].strip() != '') and (float(TEST_FILE_2.iloc[i, 1].strip()) < 0)):
                TEST_FILE_2.iloc[i, 1] = 0

        return TEST_FILE_2

    # 3시간 선형 보간
    def THREEHR_INTERPOLATION(self, pdData):

        df = pdData
        # 데이터를 가공을 위한 DATAFRAME의 컬럼명 지정
        df.columns = ["timestamp", "values"]

        MATRIX_row_num = df.shape[0]
        #print("converted_MATRIX_2_row_num:", MATRIX_row_num)
        # 3시간 보간을 위한 방법으로 ROW의 갯수가 19개인 WINDOW_DATA를 설정하고, WINDOW_DATA 마다 데이터를 확인하도록 함.
        # WINDOW_DAT에서 모두 NULL일 경우 바로 원데이터에서 ROW 19개를 뛰어 넘도록 코딩.
        # WINDOW_DAT의 첫 ROW 및 마지막 ROW가 NULL이 아닐 경우 보간을 시행.

        start_idx = 0
        while (start_idx + 20) < MATRIX_row_num:
            # if start_idx + 20 < MATRIX_row_num:
            #print("=================   INNER_WHILE_START   ====================")
            #print("CURRENT_ROW_NUM:", start_idx)
            WHOLE_DATA_1 = df["values"]
            WINDOW_DATA_2 = WHOLE_DATA_1.iloc[start_idx: start_idx + 19]
            #print("CURRENT_ROW_LENGTH:", len(WINDOW_DATA_2))
            #print("WINDOW_DATA_2")
            #print(WINDOW_DATA_2)
            # WINDOW_DATA = pd.DataFrame(WINDOW_DATA_2)
            FIRST_VALUE = WINDOW_DATA_2.iloc[0]
            LAST_VALUE = WINDOW_DATA_2.iloc[-1]

            if start_idx == 0:
                # print("  1 - ELSE")
                last_numeric_index = None
                # 다음 구간으로 넘어가기 위한 데이터 프레임 순회 (마지막 수치데이터의 위치로 이동)
                for T in range(len(df.loc[start_idx: start_idx + 19, "values"])):
                    if pd.notnull(df.loc[start_idx + T, "values"]):
                        last_numeric_index = T
                    # print("T 1 :  ", T)
                    else:
                        last_numeric_index = 0
                    # print("T 2 :  ", T)

                #print("last_numeric_index: --> ", last_numeric_index)

                if last_numeric_index == 0:
                    start_idx = start_idx + 1
                else:
                    start_idx = start_idx + int(last_numeric_index)

                # print("  2 - ELSE")

            elif start_idx != 0:
                # print("  3 - ELSE")
                # if WINDOW_DATA_2.isnull().sum() <= 19 and WINDOW_DATA_2.isnull().sum() > 0: # 전체 WINDOW가 NULL
                # if WINDOW_DATA_2.isnull().sum() <= 19 and WINDOW_DATA_2.isnull().sum() >= 1:  # 전체 또는 일부가 WINDOW가 NULL
                if WINDOW_DATA_2.isnull().sum() == 19:  # 전체 또는 일부가 WINDOW가 NULL
                    # print("  4 - ELSE")
                    if np.isnan(WHOLE_DATA_1.iloc[start_idx - 1]) and np.isnan(
                            WHOLE_DATA_1.iloc[start_idx + 20]):  # 3시간만 null 이기 때문에 보간 시작
                        # print("  5 - ELSE")
                        #print("start_idx:", start_idx)
                        #print("INTERPOLATION 1ST - START >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
                        # missing_ranges.append(["INTERPOLATION STARTING POINT --> ", df.iloc[start_idx - 1, 0]])
                        # INTERPOLATION
                        # df["values"].iloc[start_idx - 1:start_idx + 19] = df["values"].iloc[start_idx - 1:start_idx + 19].interpolate(method = 'values', limit = None, inplace = False, limit_direction = 'forward', limit_area = None, downcast = None)
                        df.loc[start_idx - 1:start_idx + 19, "values"] = df.loc[start_idx - 1:start_idx + 19,
                                                                         "values"].interpolate(method='linear',
                                                                                               limit=None,
                                                                                               inplace=False,
                                                                                               limit_direction='forward',
                                                                                               limit_area='inside')

                        last_numeric_index = None
                        # 다음 구간으로 넘어가기 위한 데이터 프레임 순회 (마지막 수치데이터의 위치로 이동)
                        for T in range(len(df.loc[start_idx: start_idx + 19, "values"])):
                            if pd.notnull(df.loc[start_idx + T, "values"]):
                                last_numeric_index = T
                                # print("T 1 :  ", T)
                            else:
                                last_numeric_index = 0
                                # print("T 2 :  ", T)

                        #print("last_numeric_index: --> ", last_numeric_index)

                        if last_numeric_index == 0:
                            start_idx = start_idx + 1
                        else:
                            start_idx = start_idx + int(last_numeric_index)  # print("  4 - ELSE")

                    else:  # WINDOW 데이터 모두가 NULL이며 동시에 전 후 값이 NULL 경우
                        last_numeric_index = None
                        # 다음 구간으로 넘어가기 위한 데이터 프레임 순회 (마지막 수치데이터의 위치로 이동)
                        for T in range(len(df.loc[start_idx: start_idx + 19, "values"])):
                            if pd.notnull(df.loc[start_idx + T, "values"]):
                                last_numeric_index = T
                                # print("T 1 :  ", T)
                            else:
                                last_numeric_index = 0
                                # print("T 2 :  ", T)

                        #print("last_numeric_index: --> ", last_numeric_index)

                        if last_numeric_index == 0:
                            start_idx = start_idx + 1
                        else:
                            start_idx = start_idx + int(last_numeric_index)  # print("  5 - ELSE")


                elif WINDOW_DATA_2.isnull().sum() <= 0:  # 모든 값이 존재하지 않을 수 있음. 그래서 강제로 보간을 시행함.
                    # print("  6 - ELSE")
                    #print("start_idx:", start_idx)

                    #print("INTERPOLATION 1ST - START >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
                    # missing_ranges.append(["INTERPOLATION STARTING POINT --> ", df.iloc[start_idx - 1, 0]])
                    # INTERPOLATION
                    # df["values"].iloc[start_idx - 1:start_idx + 19] = df["values"].iloc[start_idx - 1:start_idx + 19].interpolate(method = 'values', limit = None, inplace = False, limit_direction = 'forward', limit_area = None, downcast = None)
                    df.loc[start_idx: start_idx + 19, "values"] = df.loc[start_idx:start_idx + 19,
                                                                  "values"].interpolate(
                        method='linear', limit=None, inplace=False, limit_direction='forward',
                        limit_area='inside')

                    last_numeric_index = None
                    # 다음 구간으로 넘어가기 위한 데이터 프레임 순회 (마지막 수치데이터의 위치로 이동)
                    for T in range(len(df.loc[start_idx: start_idx + 19, "values"])):
                        if pd.notnull(df.loc[start_idx + T, "values"]):
                            last_numeric_index = T  # print("T 1 :  ", T)
                        else:
                            last_numeric_index = 0  # print("T 2 :  ", T)

                    #print("last_numeric_index: --> ", last_numeric_index)

                    if last_numeric_index == 0:
                        start_idx = start_idx + 1
                    else:
                        start_idx = start_idx + int(last_numeric_index)
                    #print("  7 - ELSE")


                elif WINDOW_DATA_2.isnull().sum() > 0 and WINDOW_DATA_2.isnull().sum() < 19:  # 의심부분 !!!!!!!!!!!!!!!!!!!!!!!!
                    #print("  8 - ELSE")
                    #print("start_idx:", start_idx)
                    #print("INTERPOLATION 1ST - START >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
                    # missing_ranges.append(["INTERPOLATION STARTING POINT --> ", df.iloc[start_idx - 1, 0]])
                    # INTERPOLATION
                    # df["values"].iloc[start_idx - 1:start_idx + 19] = df["values"].iloc[start_idx - 1:start_idx + 19].interpolate(method = 'values', limit = None, inplace = False, limit_direction = 'forward', limit_area = None, downcast = None)
                    df.loc[start_idx: start_idx + 19, "values"] = df.loc[start_idx:start_idx + 19,
                                                                  "values"].interpolate(
                        method='linear', limit=None, inplace=False, limit_direction='forward',
                        limit_area='inside')

                    last_numeric_index = None
                    # 다음 구간으로 넘어가기 위한 데이터 프레임 순회 (마지막 수치데이터의 위치로 이동)
                    for T in range(len(df.loc[start_idx: start_idx + 19, "values"])):
                        if pd.notnull(df.loc[start_idx + T, "values"]):
                            last_numeric_index = T  # print("T 1 :  ", T)
                        else:
                            last_numeric_index = 0  # print("T 2 :  ", T)

                    #print("last_numeric_index: --> ", last_numeric_index)

                    if last_numeric_index == 0:
                        start_idx = start_idx + 1
                    else:
                        start_idx = start_idx + int(last_numeric_index)  # print("  9 - ELSE")

                else:
                    #print("start_idx:", start_idx)
                    start_idx = start_idx + 1  # print("  10 - ELSE")


            else:
                #print("start_idx:", start_idx)
                start_idx = start_idx + 1  # print("  11 - ELSE")
            # else:
            # pass

        return df

    # 이상치 제거
    def REMOVE_OUTLIER(self, pdData):

        nRowIndex = 0
        before_data = -999999999
        before_final = "none"
        before_WSE_remove_outlier = "none"
        WSE_remove_outlier = "none"

        pd_datafile = pdData
        len_datafile = pd_datafile.shape[0]

        listDates = []
        listOutliers = []

        for i in range(len_datafile):
            rowdata = pd_datafile.iloc[i,:].values.tolist()

            if (len(rowdata) == 2):
                origin_date = str(rowdata[0]).strip()
                origin_dt = str(rowdata[1]).strip()
                origin_data = -999999999
                if origin_dt != '':
                    origin_data = float(origin_dt)

                Outlier_final = ""
                WSE_remove_outlier = ""

                listDates.append(origin_date)

                if nRowIndex >= ((6 * 12) - 1):

                    myDatas = pd_datafile.iloc[nRowIndex - 72 + 1:nRowIndex, 1].values.tolist()
                    myData = [float(i.strip()) if i.strip()!='' else np.NAN for i in myDatas]

                    df = pd.DataFrame(myData)

                    # 이상치보정
                    # YYYYMMDDHHMI	HEIGHT	Q1(25%)	Q3(75%)	IQR(Q3-Q1)	lower_bound	upper_bound	기울기
                    # Outlier2	Outlier_final WSE_remove_outlier WSE_Outlier_final

                    Q1 = float(df.quantile(0.25))
                    Q3 = float(df.quantile(0.75))

                    IQR = Q3 - Q1
                    if IQR < 0.01:
                        IQR = 0.01

                    LOWER_BOUND = Q1 - IQR * 1.5
                    UPPER_BOUND = Q3 + IQR * 1.5
                    SLOPE = abs(origin_data - before_data)

                    # J열 : Outlier1 , =IF(OR(C74<G74,C74>H74)=TRUE,"Outlier","Normal")
                    Outlier1 = "Normal"
                    if (origin_data < LOWER_BOUND) or (origin_data > UPPER_BOUND):
                        Outlier1 = "Outlier"
                    else:
                        Outlier1 = "Normal"

                    # L열 : Outlier2,  =IF(K74>$L$1,"Outlier","Normal")
                    Outlier2 = "Normal"
                    if (SLOPE > 0.2):
                        Outlier2 = "Outlier"
                    else:
                        Outlier2 = "Normal"

                    # M열 : Outlier_final,  =IF(OR(AND(J74="Outlier",L74="Outlier"),AND(M73="Outlier",K74<=0.01)),"Outlier","Normal")
                    Outlier_final = "Normal"
                    if ((Outlier1 == "Outlier" and Outlier2 == "Outlier") or (
                            before_final == "Outlier" and SLOPE <= 0.01)):
                        Outlier_final = "Outlier"
                    else:
                        Outlier_final = "Normal"

                    # N열 : WSE_remove outlier,   =IF(M74="Normal",C74,N73)
                    WSE_remove_outlier = "Normal"
                    if (Outlier_final == "Normal"):
                        WSE_remove_outlier = origin_data
                    else:
                        WSE_remove_outlier = before_WSE_remove_outlier

                    # O열 : WSE_Outlier_final,   =IF(M74="Outlier",C74,-999)
                    WSE_Outlier_final = "Normal"
                    if (Outlier_final == "Outlier"):
                        WSE_Outlier_final = origin_data
                    else:
                        WSE_Outlier_final = -999

                    listOutliers.append(WSE_remove_outlier)

                else:
                    listOutliers.append(origin_dt)

                before_data = origin_data
                before_final = Outlier_final
                before_WSE_remove_outlier = WSE_remove_outlier

                nRowIndex += 1

        RESULT_OUTLIER = pd.DataFrame(zip(listDates, listOutliers))

        return RESULT_OUTLIER

    # NULL값 0으로 변경 (수위제외, 유량/댐유입량/댐방류량/조위)
    def NULL_TO_ZERO(self, pdData):

        TEST_FILE_2 = pdData
        NEW_DATA = TEST_FILE_2.fillna(0)

        return NEW_DATA

    # 최종데이터 결합 (DATE, DT_DATA, MI_DATA, OI_DATA)
    def COMBINE_DATA(self, pdData1, pdData2, pdData3):

        RAW_Data = pdData1
        INTER_Data = pdData2
        INTER_Data_VALUE = INTER_Data.iloc[:, 1]

        OUTLIER_Data = pdData3
        OUTLIER_Data_VALUE = OUTLIER_Data.iloc[:, 1]

        FIRST_COMBINE_DATA = pd.concat([RAW_Data, INTER_Data_VALUE], axis=1)
        SECOND_COMBINE_DATA = pd.concat([FIRST_COMBINE_DATA, OUTLIER_Data_VALUE], axis=1)

        return SECOND_COMBINE_DATA
